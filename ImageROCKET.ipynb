{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPBhITBJhp8TIzXbQc2lZkQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Felinchen76/ImageROCKET/blob/main/ImageROCKET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROCKET 1D -> 2D Pipeline — Quick Overview\n",
        "\n",
        "This notebook contains a complete ROCKET experiment pipeline for MNIST and CIFAR-10:\n",
        "- Load and explore datasets\n",
        "- Reproducible kernel generation (1D & 2D)  \n",
        "- Preprocessing banks (e.g., per-image norm, Sobel)\n",
        "- Feature extraction (PPV, Max, MPV, MIPV, LSPV) for 1D/2D kernels\n",
        "- Classification with Ridge (Alpha-Sweep) and simple CNN and SVM benchmarks  \n",
        "- Ablations (feature sets, padding, kernel configurations) and result exports\n",
        "\n",
        "Important notes:\n",
        "- If you want deterministic cuBLAS/cuDNN runs, set `CUBLAS_WORKSPACE_CONFIG` before importing `torch` (see first cells).  \n",
        "- All experiments use a central seed (see `config.SEED`). Changes to the seed or FEATURE/PREPROC constants require the feature caches to be recalculated.\n",
        "- Results are stored in `config.CACHE_DIR` (e.g., CSVs, feature caches, plots).\n",
        "\n",
        "In short: This notebook is structured so that you can execute individual sections (baselines, ablations, final pipeline) in a targeted manner. The central settings are bundled in `config.py` and the `utils/` modules."
      ],
      "metadata": {
        "id": "R6TEov1OF8OS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cuBLAS Env Variable"
      ],
      "metadata": {
        "id": "EdKpQyREwMJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Instruct cuBLAS to use a reproducible execution mode. It must be set before CUDA / PyTorch is initialized (i.e., before importing torch). If not done there it will have no effect. Deterministic modes may be slower and require more temporary memory, but they eliminate many causes of non-deterministic numerics in GPU runs."
      ],
      "metadata": {
        "id": "Y7TAg1lcFaqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"  # must be set before CUDA init"
      ],
      "metadata": {
        "id": "TVQBOV3t3kuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Record Environment"
      ],
      "metadata": {
        "id": "FhpAiLybk2cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, torch, torchvision, sklearn, numpy\n",
        "\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Torchvision: {torchvision.__version__}\")\n",
        "print(f\"scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"NumPy: {numpy.__version__}\")\n",
        "print(f\"CUDA: {torch.version.cuda}\")\n",
        "print(f\"cuDNN: {torch.backends.cudnn.version()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYz8bnCbk6V-",
        "outputId": "9a5b00de-d6d0-4f67-edc7-50482cc2bda6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch: 2.9.0+cu128\n",
            "Torchvision: 0.24.0+cu128\n",
            "scikit-learn: 1.6.1\n",
            "NumPy: 2.0.2\n",
            "CUDA: 12.8\n",
            "cuDNN: 91002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Explorations"
      ],
      "metadata": {
        "id": "b9WJVln0v-t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from collections import Counter\n",
        "\n",
        "# Training\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True)\n",
        "train_labels = mnist_train.targets.numpy() # labels are tensors, hence the convertion to numpy\n",
        "print('Training set size:', len(train_labels))\n",
        "print('Class distribution (training):')\n",
        "print(Counter(train_labels))\n",
        "\n",
        "# Test\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True)\n",
        "test_labels = mnist_test.targets.numpy()\n",
        "print('Test set size:', len(test_labels))\n",
        "print('Class distribution (test):')\n",
        "print(Counter(test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "co3nNlTPv6dh",
        "outputId": "03b8c908-3283-47b6-c1af-16947ea2e065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 60000\n",
            "Class distribution (training):\n",
            "Counter({np.int64(1): 6742, np.int64(7): 6265, np.int64(3): 6131, np.int64(2): 5958, np.int64(9): 5949, np.int64(0): 5923, np.int64(6): 5918, np.int64(8): 5851, np.int64(4): 5842, np.int64(5): 5421})\n",
            "Test set size: 10000\n",
            "Class distribution (test):\n",
            "Counter({np.int64(1): 1135, np.int64(2): 1032, np.int64(7): 1028, np.int64(3): 1010, np.int64(9): 1009, np.int64(4): 982, np.int64(0): 980, np.int64(8): 974, np.int64(6): 958, np.int64(5): 892})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from collections import Counter\n",
        "\n",
        "# Training\n",
        "cifar_train = datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "train_labels = cifar_train.targets\n",
        "print('Training set size:', len(train_labels))\n",
        "print('Class distribution (training):')\n",
        "print(Counter(train_labels))\n",
        "\n",
        "# Test\n",
        "cifar_test = datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "test_labels = cifar_test.targets\n",
        "print('Test set size:', len(test_labels))\n",
        "print('Class distribution (test):')\n",
        "print(Counter(test_labels))\n",
        "\n",
        "# print class labels\n",
        "print('\\nClass names:')\n",
        "for idx, name in enumerate(cifar_train.classes):\n",
        "    print(f\"{idx}: {name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-dBnOksv8YJ",
        "outputId": "fa15e2ab-8b56-418c-9db0-a6b8358baceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 50000\n",
            "Class distribution (training):\n",
            "Counter({6: 5000, 9: 5000, 4: 5000, 1: 5000, 2: 5000, 7: 5000, 8: 5000, 3: 5000, 5: 5000, 0: 5000})\n",
            "Test set size: 10000\n",
            "Class distribution (test):\n",
            "Counter({3: 1000, 8: 1000, 0: 1000, 6: 1000, 1: 1000, 9: 1000, 5: 1000, 7: 1000, 4: 1000, 2: 1000})\n",
            "\n",
            "Class names:\n",
            "0: airplane\n",
            "1: automobile\n",
            "2: bird\n",
            "3: cat\n",
            "4: deer\n",
            "5: dog\n",
            "6: frog\n",
            "7: horse\n",
            "8: ship\n",
            "9: truck\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Images from both Datasets"
      ],
      "metadata": {
        "id": "RH5BNmn7TdxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# classes\n",
        "cifar_classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "save_dir = \"./example_images\"\n",
        "os.makedirs(save_dir, exist_ok=True) # if folder already exists, overwrite\n",
        "\n",
        "# load data\n",
        "cifar = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# one example per CIFAR-10 class\n",
        "for cls_idx, cls_name in enumerate(cifar_classes):\n",
        "    for img, label in cifar:\n",
        "        if label == cls_idx:\n",
        "            img_np = img.permute(1,2,0).numpy() # convert channels to matplotlib format\n",
        "            plt.imsave(os.path.join(save_dir, f'cifar_{cls_name}.png'), img_np)\n",
        "            break\n",
        "\n",
        "# 4 MNIST examples\n",
        "for i in range(4):\n",
        "    img, label = mnist[i]\n",
        "    img_np = img.squeeze().numpy() # only h,w, since matplotlib doesnt require channels for grey scale images\n",
        "    plt.imsave(os.path.join(save_dir, f'mnist_{label}.png'), img_np, cmap='gray')\n",
        "\n",
        "print(f\"Images saved to {save_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbf3QSldTckk",
        "outputId": "e8135489-eb41-44de-925e-ce772d1d494a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images saved to ./example_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate means & standard deviations for datasets"
      ],
      "metadata": {
        "id": "WeD4DUAGmg9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# mnist\n",
        "train_mnist = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(train_mnist, batch_size=len(train_mnist), shuffle=False)\n",
        "data = next(iter(loader))[0]  # data loader to iterater; next -> get batch -> return only images, without label\n",
        "\n",
        "mnist_mean = data.mean().item() # calculate mean over all elements and return float\n",
        "mnist_std = data.std().item()   # calculate std over all elements and return float\n",
        "\n",
        "print(f\"MNIST mean: {mnist_mean:.4f}, std: {mnist_std:.4f}\")\n",
        "\n",
        "train_cifar = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(train_cifar, batch_size=len(train_cifar), shuffle=False)\n",
        "data = next(iter(loader))[0] # data loader to iterater; next -> get batch -> return only images, without label\n",
        "\n",
        "# calculate for each rgb channel\n",
        "# data.shape = [50000, 3, 32, 32]\n",
        "#               dim 0  1   2   3\n",
        "#                 ↓    ↓   ↓   ↓\n",
        "#              image chan. H   W\n",
        "cifar_mean = data.mean(dim=(0,2,3))\n",
        "cifar_std = data.std(dim=(0,2,3))\n",
        "\n",
        "print('CIFAR-10 mean:', [round(m.item(), 4) for m in cifar_mean])\n",
        "print('CIFAR-10 std:', [round(s.item(), 4) for s in cifar_std])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-LRdYofmcls",
        "outputId": "65a0d2fc-9617-49f7-f0e7-5e4462f2c379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:05<00:00, 1.76MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST mean: 0.1307, std: 0.3081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:15<00:00, 11.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 mean: [0.4914, 0.4822, 0.4465]\n",
            "CIFAR-10 std: [0.247, 0.2435, 0.2616]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Config"
      ],
      "metadata": {
        "id": "dP3jpNNnkNXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell generates the central configuration file for all experiments.\n",
        "Important tasks:\n",
        "\n",
        "\n",
        "-   define dataset-wide normalization values (used by transforms.Normalize),\n",
        "-   generate standardized DataLoader via get_loaders (including optional Quick-Subset function),\n",
        "- unify reproducibility flags using set_seed and set_deterministic (note references to CUBLAS_WORKSPACE_CONFIG in the early init cell), and\n",
        "- path/cache helper for result export. Changes here affect all experiments."
      ],
      "metadata": {
        "id": "w8FOeCpNJtSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# Central configuration module:\n",
        "# - experiment constants (means/stds, batch defaults)\n",
        "# - loader factory get_loaders(...) for MNIST / CIFAR10\n",
        "# - reproducibility helpers: set_seed(seed), set_deterministic()\n",
        "# - helper for building ridge classifier pipelines (build_ridge)\n",
        "# - cache/result path helpers (get_results_file)\n",
        "#\n",
        "# Keep all environment reads and defaults here so other modules only import from config.\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from typing import Tuple, Optional\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# sklearn helpers (for build_ridge)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "#\n",
        "# Basic experiment defaults\n",
        "#\n",
        "DEFAULT_SEED = 42\n",
        "\n",
        "# calculated normalization constants for mnist and cifar\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD  = (0.2470, 0.2435, 0.2610)\n",
        "MNIST_MEAN   = (0.1307,)\n",
        "MNIST_STD    = (0.3081,)\n",
        "\n",
        "#\n",
        "# Batch / loader defaults (ENV-overridable)\n",
        "#\n",
        "BATCH_SIZE_TRAIN = int(os.environ.get(\"BATCH_SIZE_TRAIN\", os.environ.get(\"BATCH_SIZE\", \"512\")))\n",
        "BATCH_SIZE_TEST  = int(os.environ.get(\"BATCH_SIZE_TEST\",  os.environ.get(\"BATCH_SIZE\", \"512\")))\n",
        "BATCH_SIZE_DEFAULT = int(os.environ.get(\"BATCH_SIZE\", str(BATCH_SIZE_TRAIN)))\n",
        "\n",
        "NUM_WORKERS = int(os.environ.get(\"NUM_WORKERS\", \"2\"))\n",
        "PIN_MEMORY  = os.environ.get(\"PIN_MEMORY\", \"1\").lower() not in (\"0\", \"false\", \"no\")\n",
        "\n",
        "def get_batch_config():\n",
        "    return {\n",
        "        \"batch_size_train\": BATCH_SIZE_TRAIN,\n",
        "        \"batch_size_test\":  BATCH_SIZE_TEST,\n",
        "        \"num_workers\":      NUM_WORKERS,\n",
        "        \"pin_memory\":       PIN_MEMORY,\n",
        "    }\n",
        "\n",
        "#\n",
        "# Seed & deterministic helpers\n",
        "#\n",
        "def set_seed(seed: int = DEFAULT_SEED):\n",
        "    \"\"\"\n",
        "    Set deterministic seeds for python, numpy and torch (and all CUDA devices).\n",
        "    Call this at the start of each experiment to ensure reproducible kernel sampling\n",
        "    and any RNG‑based behavior.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def set_deterministic():\n",
        "    \"\"\"\n",
        "    Enable PyTorch deterministic algorithms where possible.\n",
        "    Note: this can affect performance and does not guarantee full determinism\n",
        "    for all CUDA/cuBLAS/cuDNN kernels unless additional env vars are set before CUDA initialization.\n",
        "    \"\"\"\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # on cuda, this can lead to warnings/limitations\n",
        "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "#\n",
        "# Stride config (ENV-overridable)\n",
        "#\n",
        "STRIDE_1D = int(os.environ.get(\"STRIDE_1D\", \"1\"))\n",
        "STRIDE_2D = int(os.environ.get(\"STRIDE_2D\", \"1\"))\n",
        "\n",
        "def get_stride_config():\n",
        "    return {\"stride_1d\": STRIDE_1D, \"stride_2d\": STRIDE_2D}\n",
        "\n",
        "#\n",
        "# Alphas helper\n",
        "#\n",
        "def _parse_int_list(s: str) -> list:\n",
        "    return [int(x.strip()) for x in s.split(\",\") if x.strip() != \"\"]\n",
        "\n",
        "def get_alphas(default=None, env_key: str = \"ALPHAS\") -> list:\n",
        "    if default is None:\n",
        "        default = [1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400]\n",
        "    s = os.environ.get(env_key, None)\n",
        "    if s is None or s.strip() == \"\":\n",
        "        return default\n",
        "    try:\n",
        "        return _parse_int_list(s) if \",\" in s else [int(s)]\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "ALPHAS = get_alphas()\n",
        "\n",
        "#\n",
        "# Dataset loader helper\n",
        "#\n",
        "def _make_sel_idx(labels: np.ndarray, per_class: int, seed: int) -> np.ndarray:\n",
        "    rng = np.random.RandomState(seed)\n",
        "    sel = []\n",
        "    for c in np.unique(labels):\n",
        "        ids = np.where(labels == c)[0]\n",
        "        pick = rng.choice(ids, size=min(per_class, len(ids)), replace=False)\n",
        "        sel.extend(pick.tolist())\n",
        "    return np.array(sel, dtype=np.int64)\n",
        "\n",
        "def get_loaders(dataset: str,\n",
        "                batch_size_train: Optional[int] = None,\n",
        "                batch_size_test: Optional[int]  = None,\n",
        "                seed: int = DEFAULT_SEED,\n",
        "                quick_per_class: Optional[int] = None,\n",
        "                num_workers: Optional[int] = None,\n",
        "                pin_memory: Optional[bool] = None) -> Tuple[DataLoader, DataLoader, int, Tuple[int, int], int]:\n",
        "    \"\"\"\n",
        "    Provides: train_loader, test_loader, in_channels, (H,W), seq_len\n",
        "    All defaults come from config (no local ENV reads required).\n",
        "    \"\"\"\n",
        "\n",
        "    if dataset == \"mnist\":\n",
        "        tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize(MNIST_MEAN, MNIST_STD)])\n",
        "        # root is default for colab environment; tbd: configurable root\n",
        "        train_full = datasets.MNIST(root=\"/content\", train=True, download=True, transform=tf)\n",
        "        test_set   = datasets.MNIST(root=\"/content\", train=False, download=True, transform=tf)\n",
        "        in_channels, H, W = 1, 28, 28\n",
        "    elif dataset == \"cifar10\":\n",
        "        tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)])\n",
        "        # root is default for colab environment; tbd: configurable root\n",
        "        train_full = datasets.CIFAR10(root=\"/content\", train=True, download=True, transform=tf)\n",
        "        test_set   = datasets.CIFAR10(root=\"/content\", train=False, download=True, transform=tf)\n",
        "        in_channels, H, W = 3, 32, 32\n",
        "    else:\n",
        "        raise ValueError(\"unsupported dataset. use 'mnist' or 'cifar10'.\")\n",
        "\n",
        "    if quick_per_class is not None:\n",
        "        labels = np.array(train_full.targets)\n",
        "        sel_idx = _make_sel_idx(labels, quick_per_class, seed)\n",
        "        train_set = Subset(train_full, sel_idx)\n",
        "    else:\n",
        "        train_set = train_full\n",
        "\n",
        "    if batch_size_train is None: batch_size_train = BATCH_SIZE_TRAIN\n",
        "    if batch_size_test  is None: batch_size_test  = BATCH_SIZE_TEST\n",
        "    if num_workers      is None: num_workers      = NUM_WORKERS\n",
        "    if pin_memory       is None: pin_memory       = PIN_MEMORY\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size_train, shuffle=True,\n",
        "                              num_workers=num_workers, pin_memory=pin_memory, generator=torch.Generator().manual_seed(seed))\n",
        "    test_loader  = DataLoader(test_set, batch_size=batch_size_test, shuffle=False,\n",
        "                              num_workers=num_workers, pin_memory=pin_memory)\n",
        "    seq_len = H * W\n",
        "    return train_loader, test_loader, in_channels, (H, W), seq_len\n",
        "\n",
        "#\n",
        "# Classifier builder\n",
        "#\n",
        "def build_ridge(alpha: int, scale: bool = True):\n",
        "    \"\"\"\n",
        "    Build a simple sklearn pipeline: optional StandardScaler + RidgeClassifier.\n",
        "    Keep scaling as an option to allow comparing with raw/no-scale baselines.\n",
        "    \"\"\"\n",
        "    steps = []\n",
        "    if scale:\n",
        "        steps.append(StandardScaler(with_mean=True, with_std=True))\n",
        "    steps.append(RidgeClassifier(alpha=alpha))\n",
        "    return make_pipeline(*steps)\n",
        "\n",
        "#\n",
        "# Exports / convenience values (single source)\n",
        "#\n",
        "SEED = int(os.environ.get(\"SEED\", str(DEFAULT_SEED)))\n",
        "\n",
        "BATCH_CONFIG = get_batch_config()\n",
        "BATCH_SIZE_TRAIN = int(BATCH_CONFIG[\"batch_size_train\"])\n",
        "BATCH_SIZE_TEST  = int(BATCH_CONFIG[\"batch_size_test\"])\n",
        "NUM_WORKERS      = int(BATCH_CONFIG[\"num_workers\"])\n",
        "PIN_MEMORY       = bool(BATCH_CONFIG[\"pin_memory\"])\n",
        "\n",
        "STRIDE_CONFIG = get_stride_config()\n",
        "STRIDE_1D = int(STRIDE_CONFIG.get(\"stride_1d\", 1))\n",
        "STRIDE_2D = int(STRIDE_CONFIG.get(\"stride_2d\", 1))\n",
        "\n",
        "# dataset canonical\n",
        "_DATASET_ENV = os.environ.get(\"DATASET\", \"both\").lower()\n",
        "DATASET_LIST = [\"mnist\", \"cifar10\"] if _DATASET_ENV == \"both\" else [_DATASET_ENV]\n",
        "\n",
        "# device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# cache / results convenience\n",
        "CACHE_BASE = Path(os.environ.get(\"CACHE_DIR\", \"/content\"))\n",
        "CACHE_DIR = CACHE_BASE.joinpath(\"cache\")\n",
        "\n",
        "def get_results_file(name: str, ext: str = \"csv\", subfolder: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Function ensures that the target directory exists.\n",
        "    \"\"\"\n",
        "    base = CACHE_DIR if subfolder is None else CACHE_BASE.joinpath(subfolder)\n",
        "    base.mkdir(parents=True, exist_ok=True)\n",
        "    return str(base.joinpath(f\"{name}.{ext}\"))"
      ],
      "metadata": {
        "id": "XTWuHKwJ0naV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cac919b-5447-4c77-f97e-4e7559eb65f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "VQmO4nT4kS20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utils — Purpose and Content Overview\n",
        "\n",
        "The `utils` package combines reusable helper functions for all experiments: kernel generation, preprocessing, feature extraction (1D/2D), evaluation aids, path/cache utilities, and lightweight assertions.  \n",
        "Important note: Changes to FEATURE_TYPES_* or PREPROC_MODES affect the resulting feature dimension and require the feature caches to be recalculated (see notes in the code). For reproducibility, seeds, kernel_hashes, and deterministic CUDA flags are used consistently (see config.py and early init cell for CUBLAS_WORKSPACE_CONFIG).\n",
        "\n",
        "Overview of specific sections:\n",
        "- constants.py: Feature types and preprocessing modes\n",
        "- kernels.py: Random kernel sampling (1D & 2D) and kernel_hash\n",
        "- preproc.py: Per-image normalization / Sobel; heuristics (skip/force)\n",
        "- features.py     : PPV/Max/MPV/MIPV/LSPV calculations; 1D/2D extraction (padding modes)\n",
        "- eval.py         : Ridge sweep, per-class metrics, confusion matrices\n",
        "- sanity.py       : Light assertions / memory estimates\n",
        "- settings.py     : Cache/result path helpers\n",
        "\n",
        "Note: If FEATURE_TYPES_* or PREPROC_MODES are changed, invalidate feature caches,\n",
        "note new seed/kernel_hash, and re-run feature extraction."
      ],
      "metadata": {
        "id": "cOwWUvz6Ln5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# ensure that the utils directory exists and contains an __init__.py file.\n",
        "mkdir -p /content/utils\n",
        "if [ ! -f /content/utils/__init__.py ]; then\n",
        "  cat > /content/utils/__init__.py <<'PY'\n",
        "# utils package\n",
        "PY\n",
        "  echo \"Created /content/utils/__init__.py\"\n",
        "else\n",
        "  echo \"__init__.py already exists\"\n",
        "fi\n",
        "ls -la /content/utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0089_47P4eBe",
        "outputId": "e829e8b6-d76f-4765-8720-6eef49ef66f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created /content/utils/__init__.py\n",
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Feb 15 14:42 .\n",
            "drwxr-xr-x 1 root root 4096 Feb 15 14:42 ..\n",
            "-rw-r--r-- 1 root root   16 Feb 15 14:42 __init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constants"
      ],
      "metadata": {
        "id": "yaK_e6Fo1IMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Project-wide constants: which feature statistics are extracted and which preproc modes are available.\n",
        "# Changing this alters the feature dimension —> delete/invalidate caches after changing.\n",
        "\n",
        "%%writefile utils/constants.py\n",
        "# central strings\n",
        "\n",
        "FEATURE_TYPES_1D = [\"ppv\", \"max\", \"mpv\", \"mipv\", \"lspv\"]\n",
        "FEATURE_TYPES_2D = [\"ppv\", \"max\", \"mpv\", \"mipv_y\", \"mipv_x\", \"lspv\"]\n",
        "\n",
        "# preprocessing modes\n",
        "PREPROC_NONE = \"none\"\n",
        "PREPROC_IMAGE_NORM = \"per_image_norm\"\n",
        "PREPROC_SOBEL = \"sobel\"\n",
        "\n",
        "PREPROC_MODES = {PREPROC_NONE, PREPROC_IMAGE_NORM, PREPROC_SOBEL}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR-09AK31IfH",
        "outputId": "df25b6ff-a5ea-4eb8-d366-941276c02e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/constants.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Kernels"
      ],
      "metadata": {
        "id": "WPoNP-WAy0Ij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zO15iigtyrcm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce519088-7976-4029-c3ca-e2d378c4be65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/kernels.py\n"
          ]
        }
      ],
      "source": [
        "# Generate reproducible random kernels (1D & 2D).\n",
        "# - make_random_kernels_1d/2d produce an OrderedDict keyed by (k,d) with lists of {weight,bias}\n",
        "# - seed controls RNG -> use explicit seed for reproducibility\n",
        "# - kernel_hash(kernels) returns an md5 digest over weights/biases for traceability\n",
        "#\n",
        "# Ensure kernels are created with the correct in_channels for the preprocessing used\n",
        "\n",
        "%%writefile utils/kernels.py\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "import config\n",
        "\n",
        "def make_random_kernels_1d(n_kernels: int, in_channels: int, k_choices: List[int],\n",
        "                           seq_len: int, seed: Optional[int] = None, dilation_cap: Optional[int] = None) -> Dict[Tuple[int,int], List[dict]]:\n",
        "    if seed is None:\n",
        "        seed = config.DEFAULT_SEED\n",
        "    rng = np.random.RandomState(seed)\n",
        "    kernels_by_size = OrderedDict()\n",
        "    for _ in range(n_kernels):\n",
        "        k = int(rng.choice(k_choices))\n",
        "        if k == 1:\n",
        "            d_max = 1\n",
        "        else:\n",
        "            d_max = max(1, (seq_len - 1) // (k - 1))\n",
        "        if dilation_cap is not None:\n",
        "            d_max = min(d_max, dilation_cap)\n",
        "        d = int(rng.randint(1, d_max + 1))\n",
        "        key = (k, d)\n",
        "        fan_in = in_channels * k\n",
        "        std = math.sqrt(2.0 / max(1, fan_in))\n",
        "        w = rng.normal(0.0, std, size=(in_channels, k)).astype(np.float32)\n",
        "        b = float(rng.normal(0, 0.1))\n",
        "        kernels_by_size.setdefault(key, []).append({\"weight\": w, \"bias\": b})\n",
        "    return kernels_by_size\n",
        "\n",
        "def make_random_kernels_2d(n_kernels: int, in_channels: int, k_choices: List[int],\n",
        "                           d_choices: List[int], seed: Optional[int] = None) -> Dict[Tuple[int,int], List[dict]]:\n",
        "    if seed is None:\n",
        "        seed = config.DEFAULT_SEED\n",
        "    rng = np.random.RandomState(seed)\n",
        "    kernels_by_group = OrderedDict()\n",
        "    for _ in range(n_kernels):\n",
        "        k = int(rng.choice(k_choices))\n",
        "        d = int(rng.choice(d_choices))\n",
        "        key = (k, d)\n",
        "        fan_in = in_channels * (k**2)\n",
        "        std = math.sqrt(2.0 / max(1, fan_in))\n",
        "        w = rng.normal(0.0, std, size=(in_channels, k, k)).astype(np.float32)\n",
        "        b = float(rng.normal(0, 0.1))\n",
        "        kernels_by_group.setdefault(key, []).append({\"weight\": w, \"bias\": b})\n",
        "    return kernels_by_group\n",
        "\n",
        "def count_kernels(kernels: Dict[Tuple[int,int], List[dict]]) -> int:\n",
        "    return sum(len(lst) for lst in kernels.values()) if kernels is not None else 0\n",
        "\n",
        "def kernel_hash(kernels: Dict[Tuple[int,int], List[dict]]) -> Optional[str]:\n",
        "    import hashlib, numpy as _np\n",
        "    if kernels is None:\n",
        "        return None\n",
        "    h = hashlib.md5()\n",
        "    for (k,d), lst in kernels.items():\n",
        "        for km in lst:\n",
        "            h.update(km[\"weight\"].tobytes())\n",
        "            h.update(_np.array([km[\"bias\"]], dtype=_np.float32).tobytes())\n",
        "    return h.hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Preprocessing"
      ],
      "metadata": {
        "id": "HmjMyR8py3il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing helpers applied per batch of images.\n",
        "# Modes:\n",
        "#  - PREPROC_NONE: return imgs unchanged\n",
        "#  - PREPROC_IMAGE_NORM: standardize each image per-channel (mean 0, std 1) -> can be skipped by heuristic\n",
        "#  - PREPROC_SOBEL: compute channel-wise Sobel magnitude and average channels -> (B,1,H,W)\n",
        "#\n",
        "# Heuristics: skip per-image norm when batch statistics are already close to (mean~0,std~1).\n",
        "# Use force=True to override and always apply per-image normalization.\n",
        "#\n",
        "# Function preproc_output_channels(mode, in_channels) returns resulting channel count after preproc.\n",
        "\n",
        "%%writefile utils/preproc.py\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from typing import Optional\n",
        "from utils.constants import PREPROC_NONE, PREPROC_IMAGE_NORM, PREPROC_SOBEL\n",
        "\n",
        "# Conservative heuristics (tunable)\n",
        "_MEAN_SKIP_TOL = 1e-3\n",
        "_STD_SKIP_TOL = 1e-2\n",
        "_STD_EPS = 1e-6\n",
        "\n",
        "def apply_preprocessing(imgs: torch.Tensor, mode: Optional[str] = PREPROC_NONE, force: bool = False) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Preprocessing modes:\n",
        "      - PREPROC_NONE: leave images unchanged (DEFAULT)\n",
        "      - PREPROC_IMAGE_NORM: per-image, per-channel standardization (mean=0, std=1)\n",
        "      - PREPROC_SOBEL: compute channelwise Sobel magnitude and average channels -> (B,1,H,W); unused in current ablations\n",
        "\n",
        "    Keep in mind:\n",
        "      - If mode == PREPROC_IMAGE_NORM a heuristic can skip normalization when imgs already\n",
        "        appear dataset-normalized. Set force=True to override and always apply per-image norm!\n",
        "    \"\"\"\n",
        "    if mode is None or mode == PREPROC_NONE:\n",
        "        return imgs\n",
        "\n",
        "    device = imgs.device\n",
        "    dtype = imgs.dtype\n",
        "\n",
        "    if mode == PREPROC_IMAGE_NORM:\n",
        "        # Heuristic: skip if already approximately dataset-normalized across batch,\n",
        "        # unless force=True was requested.\n",
        "        if not force:\n",
        "            with torch.no_grad():\n",
        "                per_chan_mean = imgs.mean(dim=[0, 2, 3])       # shape (C,)\n",
        "                per_chan_std  = imgs.std(dim=[0, 2, 3], unbiased=False)\n",
        "            if torch.all(per_chan_mean.abs() < _MEAN_SKIP_TOL) and torch.all((per_chan_std - 1.0).abs() < _STD_SKIP_TOL):\n",
        "                return imgs\n",
        "\n",
        "        B, C, H, W = imgs.shape\n",
        "        x = imgs.view(B, C, -1)\n",
        "        mean = x.mean(dim=2, keepdim=True)\n",
        "        std = x.std(dim=2, keepdim=True, unbiased=False).clamp(min=_STD_EPS)\n",
        "        x = (x - mean) / std\n",
        "        return x.view(B, C, H, W)\n",
        "\n",
        "    if mode == PREPROC_SOBEL:\n",
        "        # Vectorized depthwise Sobel for all channels at once\n",
        "        B, C, H, W = imgs.shape\n",
        "        # base kernels\n",
        "        kx = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]], dtype=dtype, device=device).view(1, 1, 3, 3)\n",
        "        ky = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], dtype=dtype, device=device).view(1, 1, 3, 3)\n",
        "        kx_rep = kx.repeat(C, 1, 1, 1)  # (C,1,3,3)\n",
        "        ky_rep = ky.repeat(C, 1, 1, 1)\n",
        "        gx = F.conv2d(imgs, kx_rep, padding=1, groups=C)\n",
        "        gy = F.conv2d(imgs, ky_rep, padding=1, groups=C)\n",
        "        mag = torch.sqrt(gx * gx + gy * gy + 1e-8)\n",
        "        mag_mean = mag.mean(dim=1, keepdim=True)  # (B,1,H,W)\n",
        "        return mag_mean\n",
        "\n",
        "    raise ValueError(f\"Unknown preprocessing mode: {mode}\")\n",
        "\n",
        "\n",
        "def preproc_output_channels(mode: Optional[str], in_channels: int) -> int:\n",
        "    \"\"\"\n",
        "    Return number of channels after preprocessing.\n",
        "    PREPROC_SOBEL -> 1, PREPROC_NONE/PREPROC_IMAGE_NORM -> in_channels\n",
        "    \"\"\"\n",
        "    if mode == PREPROC_SOBEL:\n",
        "        return 1\n",
        "    return in_channels"
      ],
      "metadata": {
        "id": "TDsJX_UWy3yt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5159a697-fff5-48db-846c-195e11436e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/preproc.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Features"
      ],
      "metadata": {
        "id": "6GP2CNm_y-Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature computation and 1D/2D extraction:\n",
        "# - implements PPV, Max, MPV, MIPV, LSPV and supporting helpers\n",
        "# - extract_features_1d and extract_features_2d perform batched conv operations and reduce to fixed-size features\n",
        "#\n",
        "# Important invariants (documented here):\n",
        "#  - kernels_by_group[(k,d)] arrays use shape:\n",
        "#       1D: (n_kernels_group, in_channels, k)\n",
        "#       2D: (n_kernels_group, in_channels, k, k)\n",
        "#  - extractors assert kernel in_channels == input channels (or preproc output channels)\n",
        "#\n",
        "# Padding modes:\n",
        "#  - \"same\": symmetric padding so effective kernel output equals input size when possible\n",
        "#  - \"valid\": no padding; filters larger than input are skipped\n",
        "#  - \"random\": per-group randomly choose between \"same\" and \"valid\" (seeded)\n",
        "#\n",
        "# The _make_pad_map function deterministically generates the padding choice for each (k,d)\n",
        "# when padding_mode == \"random\".\n",
        "\n",
        "%%writefile utils/features.py\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from typing import List, Tuple, Optional\n",
        "from tqdm import tqdm\n",
        "from .preproc import apply_preprocessing\n",
        "import config\n",
        "from utils.constants import PREPROC_IMAGE_NORM, PREPROC_SOBEL, PREPROC_NONE\n",
        "\n",
        "def compute_mpv_1d(out: torch.Tensor) -> torch.Tensor:\n",
        "    mask = (out > 0.0).float()\n",
        "    return (out * mask).sum(dim=2) / mask.sum(dim=2).clamp(min=1.0)\n",
        "\n",
        "def compute_mipv_1d(out: torch.Tensor) -> torch.Tensor:\n",
        "    B, G, L = out.shape\n",
        "    mask = (out > 0.0).float()\n",
        "    pos_count = mask.sum(dim=2).clamp(min=1.0)\n",
        "    idx = torch.arange(L, device=out.device, dtype=torch.float32).view(1, 1, L)\n",
        "    mipv = (idx * mask).sum(dim=2) / pos_count\n",
        "    if L > 1:\n",
        "        mipv = mipv / (L - 1)\n",
        "    return mipv\n",
        "\n",
        "def compute_lspv_1d(out: torch.Tensor) -> torch.Tensor:\n",
        "    mask = (out > 0.0).int()\n",
        "    B, G, L = mask.shape\n",
        "    runs = torch.zeros_like(mask, dtype=torch.int32)\n",
        "    runs[:, :, 0] = mask[:, :, 0]\n",
        "    for i in range(1, L):\n",
        "        runs[:, :, i] = torch.where(mask[:, :, i] == 1, runs[:, :, i - 1] + 1, torch.zeros_like(runs[:, :, i]))\n",
        "    lspv = runs.max(dim=2).values.float()\n",
        "    return lspv\n",
        "\n",
        "def compute_mpv_2d(out: torch.Tensor) -> torch.Tensor:\n",
        "    mask = (out > 0.0).float()\n",
        "    return (out * mask).sum(dim=[2, 3]) / mask.sum(dim=[2, 3]).clamp(min=1.0)\n",
        "\n",
        "def compute_mipv_2d(out: torch.Tensor, normalize: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    B, G, H, W = out.shape\n",
        "    mask = (out > 0.0).float()\n",
        "    pos_counts = mask.sum(dim=[2, 3]).clamp(min=1.0)\n",
        "    yy = torch.arange(H, device=out.device, dtype=torch.float32).view(1, 1, H, 1)\n",
        "    xx = torch.arange(W, device=out.device, dtype=torch.float32).view(1, 1, 1, W)\n",
        "    my = (yy * mask).sum(dim=[2, 3]) / pos_counts\n",
        "    mx = (xx * mask).sum(dim=[2, 3]) / pos_counts\n",
        "    if normalize:\n",
        "        if H > 1: my = my / (H - 1)\n",
        "        if W > 1: mx = mx / (W - 1)\n",
        "    return my, mx\n",
        "\n",
        "def _make_pad_map(order, seq_or_hw, padding_mode: str, seed: int):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    pad_map = {}\n",
        "    for (k, d) in order:\n",
        "        same_pad = (d * (k - 1)) // 2\n",
        "        pad_map[(k, d)] = {\"same\": same_pad, \"valid\": 0, \"pick\": int(rng.randint(0, 2))}\n",
        "    return pad_map\n",
        "\n",
        "def extract_features_1d(loader, kernels_by_group, in_channels, seq_len, feature_types: List[str],\n",
        "                        stride: int = 1, padding_mode: str = \"random\", seed: Optional[int] = None, device: Optional[object] = None):\n",
        "    \"\"\"\n",
        "    1D extractor. Uses GPU concat per batch and returns (X, y) numpy arrays.\n",
        "    Defensive: checks that kernel in_channels match input channels.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        seed = config.DEFAULT_SEED\n",
        "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # kernels_by_group is expected as dict[(k,d)] -> list of {\"weight\",\"bias\"}\n",
        "    grouped_W, grouped_B, order = {}, {}, []\n",
        "    for (k, d), lst in kernels_by_group.items():\n",
        "        W = np.stack([km[\"weight\"] for km in lst], axis=0)\n",
        "        B = np.array([km[\"bias\"] for km in lst], dtype=np.float32)\n",
        "        grouped_W[(k, d)] = torch.from_numpy(W).to(device)\n",
        "        grouped_B[(k, d)] = torch.from_numpy(B).to(device)\n",
        "        order.append((k, d))\n",
        "\n",
        "    def eff_k(k, d): return (k - 1) * d + 1\n",
        "    order_filtered = [(k, d) for (k, d) in order if not (padding_mode == \"valid\" and eff_k(k, d) > seq_len)]\n",
        "    pad_map = _make_pad_map(order, seq_len, padding_mode, seed) if padding_mode == \"random\" else None\n",
        "\n",
        "    # ensure grouped_W in_channels match sequence channels\n",
        "    if grouped_W:\n",
        "        sample = next(iter(grouped_W.values()))\n",
        "        # sample shape: (n_kernels_group, in_channels, k) for 1D\n",
        "        expected_in_ch = sample.shape[1]\n",
        "        actual_seq_ch = in_channels\n",
        "        if expected_in_ch != actual_seq_ch:\n",
        "            raise ValueError(\n",
        "                f\"Channel mismatch between kernels (in_channels={expected_in_ch}) \"\n",
        "                f\"and provided sequence channels (in_channels={actual_seq_ch}). \"\n",
        "                \"Ensure, that kernels are created with the right in_channels.\"\n",
        "            )\n",
        "\n",
        "    X_parts, y_parts = [], []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for imgs, labels in tqdm(loader, desc=f\"Feature extraction (1D/{padding_mode})\", leave=False):\n",
        "            imgs = imgs.to(device)\n",
        "            Bsize = imgs.shape[0]\n",
        "            seq = imgs.view(Bsize, in_channels, seq_len)\n",
        "            group_feats_gpu = []\n",
        "            for (k, d) in order_filtered:\n",
        "                W = grouped_W[(k, d)]; Bv = grouped_B[(k, d)]\n",
        "                if padding_mode == \"same\":\n",
        "                    pad = (d * (k - 1)) // 2\n",
        "                elif padding_mode == \"valid\":\n",
        "                    pad = 0\n",
        "                else:  # random\n",
        "                    pad = int(pad_map[(k, d)][\"same\"]) if pad_map[(k, d)][\"pick\"] == 0 else 0\n",
        "                out = F.conv1d(seq, W, bias=Bv, stride=stride, padding=pad, dilation=d)\n",
        "                feats = []\n",
        "                if \"ppv\" in feature_types: feats.append((out > 0.0).float().mean(dim=2))\n",
        "                if \"max\" in feature_types: feats.append(out.amax(dim=2))\n",
        "                if \"mpv\" in feature_types: feats.append(compute_mpv_1d(out))\n",
        "                if \"mipv\" in feature_types: feats.append(compute_mipv_1d(out))\n",
        "                if \"lspv\" in feature_types: feats.append(compute_lspv_1d(out))\n",
        "                if feats:\n",
        "                    group_feats_gpu.append(torch.cat(feats, dim=1))\n",
        "            if group_feats_gpu:\n",
        "                batch_concat = torch.cat(group_feats_gpu, dim=1).cpu().numpy()\n",
        "            else:\n",
        "                batch_concat = np.zeros((imgs.shape[0], 0), dtype=np.float32)\n",
        "            X_parts.append(batch_concat)\n",
        "            y_parts.append(labels.cpu().numpy())\n",
        "    X = np.vstack(X_parts) if len(X_parts) > 0 else np.zeros((0, 0), dtype=np.float32)\n",
        "    y = np.concatenate(y_parts) if len(y_parts) > 0 else np.zeros((0,), dtype=np.int64)\n",
        "    return X, y\n",
        "\n",
        "def extract_features_2d(loader, kernels_by_group, feature_types: List[str], image_hw: Tuple[int, int],\n",
        "                        padding_mode: str = \"valid\", stride: int = 1, seed: Optional[int] = None,\n",
        "                        preproc_mode: str = PREPROC_NONE, device: Optional[object] = None,\n",
        "                        preproc_force: bool = False):\n",
        "    \"\"\"\n",
        "    2D extractor.\n",
        "\n",
        "    Notes / defaults:\n",
        "      - Default preproc_mode is PREPROC_NONE (no extra per-image preprocessing).\n",
        "      - To force per-image normalization even if the loader already applies dataset-wide normalization,\n",
        "        set preproc_force=True. This ensures the preproc bank actually performs per-image normalization.\n",
        "      - PREPROC_SOBEL is implemented for future tests, but not actually applied in this workflow.\n",
        "\n",
        "    Returns (X,y) as numpy arrays.\n",
        "    Defensive: checks that kernel in_channels match preprocessed image channels.\n",
        "    \"\"\"\n",
        "    if seed is None:\n",
        "        seed = config.DEFAULT_SEED\n",
        "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    grouped_W, grouped_B, order = {}, {}, []\n",
        "    for (k, d), lst in kernels_by_group.items():\n",
        "        W_np = np.stack([km[\"weight\"] for km in lst], axis=0)\n",
        "        B_np = np.array([km[\"bias\"] for km in lst], dtype=np.float32)\n",
        "        grouped_W[(k, d)] = torch.from_numpy(W_np).to(device)\n",
        "        grouped_B[(k, d)] = torch.from_numpy(B_np).to(device)\n",
        "        order.append((k, d))\n",
        "\n",
        "    H_img, W_img = image_hw\n",
        "    def eff_k(k, d): return (k - 1) * d + 1\n",
        "    order_filtered = [(k, d) for (k, d) in order if not (padding_mode == \"valid\" and (eff_k(k, d) > H_img or eff_k(k, d) > W_img))]\n",
        "    pad_map = _make_pad_map(order, (H_img, W_img), padding_mode, seed) if padding_mode == \"random\" else None\n",
        "\n",
        "    X_parts, y_parts = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(loader, desc=f\"Feature extraction (2D/{padding_mode})\", leave=False):\n",
        "            imgs = imgs.to(device)\n",
        "            # apply preprocessing with optional force override\n",
        "            imgs_used = apply_preprocessing(imgs, preproc_mode, force=preproc_force)\n",
        "\n",
        "            # Defensive channel check: ensure kernel in_channels match imgs_used channels\n",
        "            if grouped_W:\n",
        "                sample = next(iter(grouped_W.values()))\n",
        "                # sample shape: (n_kernels_group, in_channels, k, k) for 2D\n",
        "                expected_in_ch = sample.shape[1]\n",
        "                actual_in_ch = imgs_used.shape[1]\n",
        "                if expected_in_ch != actual_in_ch:\n",
        "                    raise ValueError(\n",
        "                        f\"Channel mismatch between kernels (in_channels={expected_in_ch}) \"\n",
        "                        f\"and preprocessed images (channels={actual_in_ch}). \"\n",
        "                        \"If PREPROC_SOBEL is used, build kernels with in_channels=1 \"\n",
        "                        \"or use preproc_mode='none' / 'per_image_norm'.\"\n",
        "                    )\n",
        "\n",
        "            group_feats_gpu = []\n",
        "            for (k, d) in order_filtered:\n",
        "                if padding_mode == \"same\":\n",
        "                    pad = ((k - 1) * d) // 2\n",
        "                elif padding_mode == \"valid\":\n",
        "                    pad = 0\n",
        "                else:\n",
        "                    effK = eff_k(k, d)\n",
        "                    if effK <= H_img and effK <= W_img:\n",
        "                        pad = pad_map[(k, d)][\"same\"] if pad_map[(k, d)][\"pick\"] == 0 else 0\n",
        "                    else:\n",
        "                        pad = pad_map[(k, d)][\"same\"]\n",
        "                out = F.conv2d(imgs_used, grouped_W[(k, d)], bias=grouped_B[(k, d)], stride=stride, padding=pad, dilation=d)\n",
        "                feats = []\n",
        "                if \"ppv\" in feature_types: feats.append((out > 0.0).float().mean(dim=[2, 3]))\n",
        "                if \"max\" in feature_types: feats.append(out.amax(dim=[2, 3]))\n",
        "                if \"mpv\" in feature_types: feats.append(compute_mpv_2d(out))\n",
        "                if \"mipv_y\" in feature_types or \"mipv_x\" in feature_types:\n",
        "                    my, mx = compute_mipv_2d(out, normalize=True)\n",
        "                    if \"mipv_y\" in feature_types: feats.append(my)\n",
        "                    if \"mipv_x\" in feature_types: feats.append(mx)\n",
        "                if feats:\n",
        "                    group_feats_gpu.append(torch.cat(feats, dim=1))\n",
        "            if group_feats_gpu:\n",
        "                batch_concat = torch.cat(group_feats_gpu, dim=1).cpu().numpy()\n",
        "            else:\n",
        "                batch_concat = np.zeros((imgs.shape[0], 0), dtype=np.float32)\n",
        "            X_parts.append(batch_concat)\n",
        "            y_parts.append(labels.cpu().numpy())\n",
        "    X = np.vstack(X_parts) if len(X_parts) > 0 else np.zeros((0, 0), dtype=np.float32)\n",
        "    y = np.concatenate(y_parts) if len(y_parts) > 0 else np.zeros((0,), dtype=np.int64)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "pG8m6u4wy8mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b38bf3-c45a-48f5-8fef-d465b97f6606",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/features.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "GGAo8_TxzDT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation helpers:\n",
        "# - train_and_sweep_alphas(X_train, y_train, X_test, y_test, alphas)\n",
        "#     Fit RidgeClassifier for each alpha, return best alpha & predictions.\n",
        "# - per_class_accuracy(y_true, y_pred)\n",
        "#     Return dict mapping class -> accuracy (handles empty class cases).\n",
        "# - evaluate_and_report(model_name, dataset, seed, y_true, y_pred, scores=None, train_time=None)\n",
        "#     Print accuracy, classification report and confusion matrix.\n",
        "#\n",
        "# These helpers assume X arrays are dense numpy arrays with shape (n_samples, feature_dim).\n",
        "\n",
        "%%writefile utils/eval.py\n",
        "\n",
        "import time\n",
        "from config import build_ridge\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "def train_and_sweep_alphas(X_train, y_train, X_test, y_test, alphas):\n",
        "    best_alpha, best_acc, best_time, best_pred = None, -1.0, None, None\n",
        "    for alpha in alphas:\n",
        "        pipe = build_ridge(alpha=alpha, scale=True)\n",
        "        t0 = time.time()\n",
        "        pipe.fit(X_train, y_train)\n",
        "        tt = time.time() - t0\n",
        "        ypred = pipe.predict(X_test)\n",
        "        acc = accuracy_score(y_test, ypred)\n",
        "        if acc > best_acc:\n",
        "            best_alpha, best_acc, best_time, best_pred = alpha, acc, tt, ypred\n",
        "    return best_alpha, best_acc, best_time, best_pred\n",
        "\n",
        "def per_class_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute per-class accuracy as a dict {class_label: accuracy}.\n",
        "    \"\"\"\n",
        "    classes = sorted(set(y_true))\n",
        "    return {\n",
        "        str(c): float((y_pred[y_true == c] == c).mean())\n",
        "        if (y_true == c).sum() > 0 else None\n",
        "        for c in classes\n",
        "    }\n",
        "\n",
        "def evaluate_and_report(model_name: str, dataset: str, seed: int, y_true, y_pred, scores=None, train_time: float = None):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    print(f\"[{model_name}][{dataset}][seed={seed}] acc={acc:.4f} | train_time={train_time if train_time is not None else '-'}s\")\n",
        "    try:\n",
        "        print(classification_report(y_true, y_pred, digits=4))\n",
        "    except Exception as e:\n",
        "        print(\"classification_report failed:\", e)\n",
        "    try:\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        print(\"Confusion matrix:\\n\", cm)\n",
        "    except Exception as e:\n",
        "        print(\"confusion_matrix failed:\", e)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "tldtSBNJzClj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc235431-94b8-4052-8078-81e62b833b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/eval.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity"
      ],
      "metadata": {
        "id": "xqlFvBzlzPQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity-check helpers:\n",
        "#  - assert_kernel_count(kernels, expected) -> assert total kernels == expected\n",
        "#  - assert_feature_dim(X_train, expected) -> assert feature dim matches expected\n",
        "#  - estimate_feature_bytes(n_samples, feature_dim, dtype_bytes=4) -> approximate memory\n",
        "\n",
        "%%writefile utils/sanity.py\n",
        "\n",
        "from typing import Dict, Tuple\n",
        "import numpy as _np\n",
        "\n",
        "def assert_kernel_count(kernels, expected):\n",
        "    total = sum(len(lst) for lst in kernels.values()) if kernels is not None else 0\n",
        "    assert total == expected, f\"Kernel count mismatch: expected {expected}, got {total}\"\n",
        "    return total\n",
        "\n",
        "def assert_feature_dim(X_train, expected):\n",
        "    got = 0\n",
        "    if X_train is None:\n",
        "        got = 0\n",
        "    else:\n",
        "        shape = getattr(X_train, \"shape\", None)\n",
        "        if shape is not None and len(shape) >= 2:\n",
        "            got = int(shape[1])\n",
        "        else:\n",
        "            got = 0\n",
        "    assert got == expected, f\"Feature dim mismatch: expected {expected}, got {got}\"\n",
        "    return got\n",
        "\n",
        "def estimate_feature_bytes(n_samples, feature_dim, dtype_bytes=4):\n",
        "    return n_samples * feature_dim * dtype_bytes"
      ],
      "metadata": {
        "id": "bVxJE0TizQJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b49422-4bdb-447f-f6dc-fec79e6de2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/sanity.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard Test Settings"
      ],
      "metadata": {
        "id": "mWz3xzKKzREp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Settings / cache helpers:\n",
        "# - get_cache_dir(subfolder=None): return Path for cache; create if missing\n",
        "# - get_results_file(...) delegates to config.get_results_file to keep single source of truth\n",
        "\n",
        "%%writefile utils/settings.py\n",
        "\n",
        "from pathlib import Path\n",
        "import config\n",
        "\n",
        "def get_cache_dir(subfolder: str = None) -> Path:\n",
        "    \"\"\"\n",
        "    returns Path to cache (standard: config.cache_dir)\n",
        "    optional: subfolder under cache_base (config.cache_base)\n",
        "    \"\"\"\n",
        "    # config.CACHE_DIR is a path; return it or the subfolder under CACHE_BASE.\n",
        "    if subfolder is None:\n",
        "        return Path(config.CACHE_DIR)\n",
        "    else:\n",
        "        p = Path(config.CACHE_BASE).joinpath(subfolder)\n",
        "        p.mkdir(parents=True, exist_ok=True)\n",
        "        return p\n",
        "\n",
        "def get_results_file(name: str, ext: str = \"csv\", subfolder: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Implementation found in config as single source of truth\n",
        "    \"\"\"\n",
        "    return config.get_results_file(name, ext=ext, subfolder=subfolder)"
      ],
      "metadata": {
        "id": "JAWGvUurzWui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2afc88-50c5-4987-d75b-a540c13f7e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils/settings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baselines"
      ],
      "metadata": {
        "id": "P6UnZLUx2OTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimal Rocket Adaption"
      ],
      "metadata": {
        "id": "yaELX3QZAUZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pure ROCKET 1D\n",
        "import os, time, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib, csv\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# central config/consts\n",
        "from config import (\n",
        "    set_seed, set_deterministic, get_loaders,\n",
        "    ALPHAS, STRIDE_1D, SEED, DEVICE,\n",
        "    BATCH_SIZE_TRAIN, BATCH_SIZE_TEST, DATASET_LIST\n",
        ")\n",
        "from config import build_ridge  # central pipeline factory\n",
        "from utils.constants import FEATURE_TYPES_1D\n",
        "from utils.kernels import make_random_kernels_1d\n",
        "from utils.features import extract_features_1d\n",
        "from utils.settings import get_cache_dir\n",
        "from utils.eval import per_class_accuracy\n",
        "\n",
        "# reproducibility\n",
        "set_seed(SEED)\n",
        "set_deterministic()\n",
        "\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# experiment-local choices (ENV ok if experiment-specific)\n",
        "PADDING_MODE_1D = os.environ.get(\"PADDING_MODE_1D\", \"random\").lower()\n",
        "MODE = \"pure_rocket_1d\"\n",
        "CLEAN_FEATURE_CACHE = True\n",
        "\n",
        "N_KERNELS = int(os.environ.get(\"N_KERNELS\", \"3024\")) # moderate kernel number - for faster evaluation\n",
        "KERNEL_SIZE_CANDIDATES = [7, 9, 11] # original ROCKET kernel sizes\n",
        "STRIDE = STRIDE_1D\n",
        "ALPHAS_LOCAL = list(ALPHAS)\n",
        "\n",
        "CACHE_DIR = get_cache_dir(\"rocket1d_cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_CSV = str(CACHE_DIR.joinpath(f\"rocket1d_results_{MODE}.csv\"))\n",
        "\n",
        "def run(dataset_tag, train_loader, test_loader, in_channels, seq_len, kernels, alphas):\n",
        "    print(f\"\\n=== Pure ROCKET 1D run on {dataset_tag} ===\")\n",
        "    feat_train_cache = str(CACHE_DIR.joinpath(f\"features_train_{dataset_tag}_{MODE}.pkl\"))\n",
        "    feat_test_cache  = str(CACHE_DIR.joinpath(f\"features_test_{dataset_tag}_{MODE}.pkl\"))\n",
        "\n",
        "    if os.path.exists(feat_train_cache) and os.path.exists(feat_test_cache):\n",
        "        saved_tr = joblib.load(feat_train_cache)\n",
        "        X_train, y_train = saved_tr[\"X\"], saved_tr[\"y\"]\n",
        "        saved_te = joblib.load(feat_test_cache)\n",
        "        X_test, y_test = saved_te[\"X\"], saved_te[\"y\"]\n",
        "    else:\n",
        "        X_train, y_train = extract_features_1d(train_loader, kernels, in_channels, seq_len,\n",
        "                                               feature_types=[\"ppv\", \"max\"], stride=STRIDE,\n",
        "                                               padding_mode=PADDING_MODE_1D, seed=SEED)\n",
        "        X_test, y_test = extract_features_1d(test_loader, kernels, in_channels, seq_len,\n",
        "                                             feature_types=[\"ppv\", \"max\"], stride=STRIDE,\n",
        "                                             padding_mode=PADDING_MODE_1D, seed=SEED)\n",
        "        joblib.dump({\"X\": X_train, \"y\": y_train}, feat_train_cache)\n",
        "        joblib.dump({\"X\": X_test,  \"y\": y_test}, feat_test_cache)\n",
        "\n",
        "    if X_train.shape[1] == 0:\n",
        "        print(f\"[{dataset_tag}] No features extracted -> skipping training\")\n",
        "        return []\n",
        "\n",
        "    results = []\n",
        "    for alpha in alphas:\n",
        "        pipe = build_ridge(alpha=alpha, scale=True)\n",
        "        t0 = time.time()\n",
        "        pipe.fit(X_train, y_train)\n",
        "        tt = time.time() - t0\n",
        "        ypred = pipe.predict(X_test)\n",
        "        acc = accuracy_score(y_test, ypred)\n",
        "\n",
        "        classes = np.unique(y_test)\n",
        "        per_class_acc = per_class_accuracy(y_test, ypred)\n",
        "\n",
        "        print(f\"[{dataset_tag}] ridge alpha={alpha} acc={acc:.4f} time={tt:.1f}s\")\n",
        "        print(\"Per-class acc:\", per_class_acc)\n",
        "\n",
        "        results.append({\n",
        "            \"dataset\": dataset_tag, \"classifier\": \"ridge\",\n",
        "            \"alpha\": alpha, \"acc\": acc, \"train_time\": tt,\n",
        "            \"n_kernels\": N_KERNELS, \"per_class_acc\": per_class_acc\n",
        "        })\n",
        "\n",
        "    # append to csv\n",
        "    if results:\n",
        "        with open(RESULTS_CSV, \"a\", newline=\"\") as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=results[0].keys())\n",
        "            if f.tell() == 0:\n",
        "                writer.writeheader()\n",
        "            for r in results:\n",
        "                writer.writerow(r)\n",
        "    return results\n",
        "\n",
        "# main\n",
        "all_results = []\n",
        "dataset_list = DATASET_LIST\n",
        "for dataset in dataset_list:\n",
        "    train_loader, test_loader, in_channels, (H, W), seq_len = get_loaders(dataset, seed=SEED, quick_per_class=None)\n",
        "    kernels = make_random_kernels_1d(N_KERNELS, in_channels, KERNEL_SIZE_CANDIDATES, seq_len, seed=SEED, dilation_cap=64)\n",
        "    res = run(dataset, train_loader, test_loader, in_channels, seq_len, kernels, ALPHAS_LOCAL)\n",
        "    all_results.extend(res)\n",
        "\n",
        "print(\"\\n=== Summary saved to:\", RESULTS_CSV, \"===\")\n",
        "if os.path.exists(RESULTS_CSV):\n",
        "    df = pd.read_csv(RESULTS_CSV)\n",
        "    print(df.sort_values([\"dataset\",\"acc\"], ascending=[True, False]).groupby(\"dataset\").head(5))\n",
        "else:\n",
        "    print(\"No results CSV written.\")"
      ],
      "metadata": {
        "id": "XwvPMGed2YeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97bcd48-c012-42b5-d2ef-9f843bce5782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config: SEED=42, datasets=['mnist', 'cifar10'], batch_train=512, device=cuda\n",
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.48MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.31MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Pure ROCKET 1D run on mnist ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist] ridge alpha=1000 acc=0.9858 time=13.3s\n",
            "Per-class acc: {'0': 0.9938775510204082, '1': 0.9911894273127754, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9867617107942973, '5': 0.9865470852017937, '6': 0.9843423799582464, '7': 0.9776264591439688, '8': 0.9897330595482546, '9': 0.9762140733399405}\n",
            "[mnist] ridge alpha=1200 acc=0.9855 time=13.2s\n",
            "Per-class acc: {'0': 0.9938775510204082, '1': 0.9903083700440528, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9867617107942973, '5': 0.9854260089686099, '6': 0.9843423799582464, '7': 0.9766536964980544, '8': 0.9897330595482546, '9': 0.9762140733399405}\n",
            "[mnist] ridge alpha=1400 acc=0.9851 time=13.3s\n",
            "Per-class acc: {'0': 0.9938775510204082, '1': 0.9903083700440528, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9857433808553971, '5': 0.984304932735426, '6': 0.9843423799582464, '7': 0.9766536964980544, '8': 0.9897330595482546, '9': 0.9742319127849356}\n",
            "[mnist] ridge alpha=1600 acc=0.9850 time=13.3s\n",
            "Per-class acc: {'0': 0.9938775510204082, '1': 0.9903083700440528, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9857433808553971, '5': 0.984304932735426, '6': 0.9843423799582464, '7': 0.9766536964980544, '8': 0.9897330595482546, '9': 0.9732408325074331}\n",
            "[mnist] ridge alpha=1800 acc=0.9850 time=13.4s\n",
            "Per-class acc: {'0': 0.9938775510204082, '1': 0.9903083700440528, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9857433808553971, '5': 0.984304932735426, '6': 0.9843423799582464, '7': 0.9766536964980544, '8': 0.9897330595482546, '9': 0.9732408325074331}\n",
            "[mnist] ridge alpha=2000 acc=0.9847 time=13.1s\n",
            "Per-class acc: {'0': 0.9918367346938776, '1': 0.9903083700440528, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9867617107942973, '5': 0.9831838565022422, '6': 0.9843423799582464, '7': 0.97568093385214, '8': 0.9897330595482546, '9': 0.9732408325074331}\n",
            "[mnist] ridge alpha=2200 acc=0.9845 time=13.4s\n",
            "Per-class acc: {'0': 0.9918367346938776, '1': 0.9903083700440528, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9867617107942973, '5': 0.9831838565022422, '6': 0.9843423799582464, '7': 0.97568093385214, '8': 0.9887063655030801, '9': 0.9722497522299306}\n",
            "[mnist] ridge alpha=2400 acc=0.9842 time=13.3s\n",
            "Per-class acc: {'0': 0.9918367346938776, '1': 0.9903083700440528, '2': 0.9864341085271318, '3': 0.9851485148514851, '4': 0.9867617107942973, '5': 0.9820627802690582, '6': 0.9843423799582464, '7': 0.9737354085603113, '8': 0.9887063655030801, '9': 0.9722497522299306}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Pure ROCKET 1D run on cifar10 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10] ridge alpha=1000 acc=0.6250 time=10.7s\n",
            "Per-class acc: {'0': 0.665, '1': 0.778, '2': 0.473, '3': 0.388, '4': 0.509, '5': 0.538, '6': 0.746, '7': 0.652, '8': 0.78, '9': 0.721}\n",
            "[cifar10] ridge alpha=1200 acc=0.6258 time=10.5s\n",
            "Per-class acc: {'0': 0.662, '1': 0.783, '2': 0.473, '3': 0.389, '4': 0.512, '5': 0.54, '6': 0.748, '7': 0.652, '8': 0.78, '9': 0.719}\n",
            "[cifar10] ridge alpha=1400 acc=0.6255 time=10.8s\n",
            "Per-class acc: {'0': 0.661, '1': 0.783, '2': 0.473, '3': 0.39, '4': 0.511, '5': 0.533, '6': 0.75, '7': 0.652, '8': 0.783, '9': 0.719}\n",
            "[cifar10] ridge alpha=1600 acc=0.6247 time=10.4s\n",
            "Per-class acc: {'0': 0.659, '1': 0.786, '2': 0.471, '3': 0.384, '4': 0.507, '5': 0.531, '6': 0.751, '7': 0.655, '8': 0.782, '9': 0.721}\n",
            "[cifar10] ridge alpha=1800 acc=0.6231 time=10.6s\n",
            "Per-class acc: {'0': 0.654, '1': 0.784, '2': 0.468, '3': 0.384, '4': 0.501, '5': 0.532, '6': 0.751, '7': 0.654, '8': 0.783, '9': 0.72}\n",
            "[cifar10] ridge alpha=2000 acc=0.6226 time=10.6s\n",
            "Per-class acc: {'0': 0.653, '1': 0.784, '2': 0.469, '3': 0.387, '4': 0.5, '5': 0.527, '6': 0.749, '7': 0.659, '8': 0.78, '9': 0.718}\n",
            "[cifar10] ridge alpha=2200 acc=0.6216 time=10.7s\n",
            "Per-class acc: {'0': 0.654, '1': 0.784, '2': 0.469, '3': 0.386, '4': 0.496, '5': 0.526, '6': 0.749, '7': 0.658, '8': 0.779, '9': 0.715}\n",
            "[cifar10] ridge alpha=2400 acc=0.6214 time=11.5s\n",
            "Per-class acc: {'0': 0.653, '1': 0.783, '2': 0.466, '3': 0.385, '4': 0.497, '5': 0.527, '6': 0.751, '7': 0.658, '8': 0.779, '9': 0.715}\n",
            "\n",
            "=== Summary saved to: /content/rocket1d_cache/rocket1d_results_pure_rocket_1d.csv ===\n",
            "    dataset classifier  alpha     acc  train_time  n_kernels  \\\n",
            "9   cifar10      ridge   1200  0.6258   10.466684       3024   \n",
            "10  cifar10      ridge   1400  0.6255   10.798477       3024   \n",
            "8   cifar10      ridge   1000  0.6250   10.677255       3024   \n",
            "11  cifar10      ridge   1600  0.6247   10.414703       3024   \n",
            "12  cifar10      ridge   1800  0.6231   10.573060       3024   \n",
            "0     mnist      ridge   1000  0.9858   13.284684       3024   \n",
            "1     mnist      ridge   1200  0.9855   13.217154       3024   \n",
            "2     mnist      ridge   1400  0.9851   13.267138       3024   \n",
            "3     mnist      ridge   1600  0.9850   13.296353       3024   \n",
            "4     mnist      ridge   1800  0.9850   13.371061       3024   \n",
            "\n",
            "                                        per_class_acc  \n",
            "9   {'0': 0.662, '1': 0.783, '2': 0.473, '3': 0.38...  \n",
            "10  {'0': 0.661, '1': 0.783, '2': 0.473, '3': 0.39...  \n",
            "8   {'0': 0.665, '1': 0.778, '2': 0.473, '3': 0.38...  \n",
            "11  {'0': 0.659, '1': 0.786, '2': 0.471, '3': 0.38...  \n",
            "12  {'0': 0.654, '1': 0.784, '2': 0.468, '3': 0.38...  \n",
            "0   {'0': 0.9938775510204082, '1': 0.9911894273127...  \n",
            "1   {'0': 0.9938775510204082, '1': 0.9903083700440...  \n",
            "2   {'0': 0.9938775510204082, '1': 0.9903083700440...  \n",
            "3   {'0': 0.9938775510204082, '1': 0.9903083700440...  \n",
            "4   {'0': 0.9938775510204082, '1': 0.9903083700440...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "XEZEsgwtAXne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM baseline using raw images\n",
        "import os, time\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import csv\n",
        "\n",
        "from config import set_seed, set_deterministic, get_loaders, SEED, DATASET_LIST as dataset_list\n",
        "\n",
        "# defaults (svm specific)\n",
        "C_grid = [0.1]\n",
        "rp_dim = 1024 * 2  # set to None to disable projection\n",
        "max_iter = 1000\n",
        "\n",
        "set_seed(SEED)\n",
        "set_deterministic()\n",
        "\n",
        "def loader_to_numpy(loader, flatten=True):\n",
        "    xs, ys = [], []\n",
        "    for xb, yb in loader:\n",
        "        x = xb.numpy()\n",
        "        if flatten:\n",
        "            x = x.reshape(x.shape[0], -1)\n",
        "        xs.append(x); ys.append(yb.numpy())\n",
        "    return np.concatenate(xs, axis=0), np.concatenate(ys, axis=0)\n",
        "\n",
        "all_results = []\n",
        "for dataset in dataset_list:\n",
        "    train_loader, test_loader, in_channels, (H, W), _ = get_loaders(dataset, seed=SEED, quick_per_class=None)\n",
        "    X_tr, y_tr = loader_to_numpy(train_loader, flatten=True)\n",
        "    X_te, y_te = loader_to_numpy(test_loader, flatten=True)\n",
        "\n",
        "    scaler = StandardScaler().fit(X_tr)\n",
        "    Xtr_s = scaler.transform(X_tr); Xte_s = scaler.transform(X_te)\n",
        "\n",
        "    if rp_dim is not None:\n",
        "        rp = GaussianRandomProjection(n_components=rp_dim, random_state=SEED)\n",
        "        Xtr_s = rp.fit_transform(Xtr_s); Xte_s = rp.transform(Xte_s)\n",
        "\n",
        "    best = {\"acc\": -1}\n",
        "    results = []\n",
        "    for C in C_grid:\n",
        "        t_start = time.time()\n",
        "        clf = LinearSVC(C=C, max_iter=max_iter, random_state=SEED)\n",
        "        clf.fit(Xtr_s, y_tr)\n",
        "        train_time_C = time.time() - t_start\n",
        "        y_pred = clf.predict(Xte_s)\n",
        "        acc = float((y_pred == y_te).mean())\n",
        "        conf = confusion_matrix(y_te, y_pred)\n",
        "        per_class_acc = (conf.diagonal() / conf.sum(axis=1)).tolist()\n",
        "        print(f\"[{dataset}][SVM-raw+RP] C={C} | acc={acc:.4f} | train_time={train_time_C:.2f}s\")\n",
        "        print(f\"Per-class accuracy: {np.round(per_class_acc,4)}\")\n",
        "        results.append({\"dataset\": dataset, \"classifier\": \"linear_svm_rp\", \"C\": C, \"acc\": acc, \"train_time\": train_time_C, \"feature_dim\": Xtr_s.shape[1], \"per_class_acc\": per_class_acc})\n",
        "        if acc > best[\"acc\"]:\n",
        "            best.update({\"acc\": acc, \"C\": C, \"ypred\": y_pred, \"train_time\": train_time_C, \"per_class_acc\": per_class_acc})\n",
        "    csv_name = f\"./svm_baseline_results_{dataset}.csv\"\n",
        "    with open(csv_name, \"w\", newline=\"\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=results[0].keys()); writer.writeheader()\n",
        "        for r in results: writer.writerow(r)\n",
        "    print(f\"Best SVM result for {dataset} saved to {csv_name}\")\n",
        "    all_results.append({\"dataset\": dataset, **best})\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "for res in all_results:\n",
        "    print(f\"{res['dataset'].upper()} avg acc: {res['acc']:.4f} | per-class: {np.round(res['per_class_acc'],4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhiMNYhkAZcg",
        "outputId": "387c751a-76da-4044-ce57-bf9f8be0e3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/random_projection.py:411: DataDimensionalityWarning: The number of components is higher than the number of features: n_features < n_components (784 < 2048).The dimensionality of the problem will not be reduced.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist][SVM-raw+RP] C=0.1 | acc=0.9166 | train_time=7816.64s\n",
            "Per-class accuracy: [0.9806 0.9797 0.8818 0.9099 0.9308 0.8565 0.9489 0.9202 0.8604 0.885 ]\n",
            "Best SVM result for mnist saved to ./svm_baseline_results_mnist.csv\n",
            "[cifar10][SVM-raw+RP] C=0.1 | acc=0.3790 | train_time=6890.06s\n",
            "Per-class accuracy: [0.471 0.459 0.235 0.168 0.252 0.3   0.475 0.431 0.542 0.457]\n",
            "Best SVM result for cifar10 saved to ./svm_baseline_results_cifar10.csv\n",
            "\n",
            "=== Summary ===\n",
            "MNIST avg acc: 0.9166 | per-class: [0.9806 0.9797 0.8818 0.9099 0.9308 0.8565 0.9489 0.9202 0.8604 0.885 ]\n",
            "CIFAR10 avg acc: 0.3790 | per-class: [0.471 0.459 0.235 0.168 0.252 0.3   0.475 0.431 0.542 0.457]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lightweight CNN"
      ],
      "metadata": {
        "id": "-k0_r3ePAZth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN benchmark\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "import pandas as pd\n",
        "\n",
        "from config import set_seed, set_deterministic, get_loaders, get_batch_config, get_stride_config, SEED, DATASET_LIST as dataset_list, DEVICE\n",
        "from utils.eval import evaluate_and_report\n",
        "\n",
        "set_seed(SEED); set_deterministic()\n",
        "device = DEVICE\n",
        "\n",
        "batch_cfg = get_batch_config()\n",
        "stride_cfg = get_stride_config()\n",
        "print(\"Using batch config:\", batch_cfg)\n",
        "print(\"Using stride config:\", stride_cfg)\n",
        "\n",
        "epochs = int(os.environ.get(\"EPOCHS\", \"10\"))\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, in_channels: int, img_size: int, num_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                                      nn.MaxPool2d(2), nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(inplace=True),\n",
        "                                      nn.MaxPool2d(2))\n",
        "        feat = img_size // 4\n",
        "        self.classifier = nn.Sequential(nn.Flatten(), nn.Linear(64*feat*feat,128), nn.ReLU(inplace=True), nn.Linear(128,num_classes))\n",
        "\n",
        "    def forward(self, x): return self.classifier(self.features(x))\n",
        "\n",
        "def eval_loader(model, loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    logits_list, y_list = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "        logits_list.append(logits.detach().cpu().numpy()); y_list.append(yb.detach().cpu().numpy())\n",
        "    logits = np.concatenate(logits_list, axis=0) if logits_list else np.zeros((0,10))\n",
        "    y_true = np.concatenate(y_list, axis=0) if y_list else np.zeros((0,), dtype=int)\n",
        "    y_pred = logits.argmax(axis=1) if logits_list else np.zeros((0,), dtype=int)\n",
        "    return (correct/total if total>0 else 0.0), y_true, y_pred, logits\n",
        "\n",
        "results = []\n",
        "for dataset in dataset_list:\n",
        "    print(f\"\\n=== Training CNN on {dataset} ===\")\n",
        "    train_loader, test_loader, in_channels, (img_sz,_), _ = get_loaders(dataset, batch_size_train=batch_cfg[\"batch_size_train\"], batch_size_test=batch_cfg[\"batch_size_test\"], seed=SEED, quick_per_class=None)\n",
        "    model = SmallCNN(in_channels, img_sz).to(device)\n",
        "    opt = optim.Adam(model.parameters(), lr=1e-3); crit = nn.CrossEntropyLoss()\n",
        "    t0 = time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad(); loss = crit(model(xb), yb); loss.backward(); opt.step()\n",
        "        acc_val, _, _, _ = eval_loader(model, test_loader, device)\n",
        "        print(f\"[{dataset}][CNN] epoch {ep:02d} | test acc {acc_val:.4f}\")\n",
        "    train_time = time.time() - t0\n",
        "    acc, y_true, y_pred, logits = eval_loader(model, test_loader, device)\n",
        "    evaluate_and_report(f\"cnn_small_full_{dataset}\", dataset, SEED, y_true, y_pred, scores=logits, train_time=train_time)\n",
        "    results.append({\"dataset\": dataset, \"model\": \"cnn_small\", \"seed\": SEED, \"accuracy\": acc, \"train_time\": train_time, \"feature_dim\": img_sz*img_sz*in_channels})\n",
        "\n",
        "CACHE_DIR = os.path.join(os.environ.get(\"CACHE_DIR\", \"/content\"), \"cnn_cache\")\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "RESULTS_CSV = os.path.join(CACHE_DIR, \"cnn_results.csv\")\n",
        "pd.DataFrame(results).to_csv(RESULTS_CSV, index=False)\n",
        "print(f\"CNN results saved to: {RESULTS_CSV}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQLruFWvAbVD",
        "outputId": "6ee139df-c71c-4eac-a1e5-c193bcc8c846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batch config: {'batch_size_train': 512, 'batch_size_test': 512, 'num_workers': 2, 'pin_memory': True}\n",
            "Using stride config: {'stride_1d': 1, 'stride_2d': 1}\n",
            "\n",
            "=== Training CNN on mnist ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:841: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:315.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist][CNN] epoch 01 | test acc 0.9755\n",
            "[mnist][CNN] epoch 02 | test acc 0.9816\n",
            "[mnist][CNN] epoch 03 | test acc 0.9866\n",
            "[mnist][CNN] epoch 04 | test acc 0.9870\n",
            "[mnist][CNN] epoch 05 | test acc 0.9881\n",
            "[mnist][CNN] epoch 06 | test acc 0.9890\n",
            "[mnist][CNN] epoch 07 | test acc 0.9879\n",
            "[mnist][CNN] epoch 08 | test acc 0.9909\n",
            "[mnist][CNN] epoch 09 | test acc 0.9913\n",
            "[mnist][CNN] epoch 10 | test acc 0.9906\n",
            "[cnn_small_full_mnist][mnist][seed=42] acc=0.9906 | train_time=77.82592439651489s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9899    0.9969    0.9934       980\n",
            "           1     0.9956    0.9965    0.9960      1135\n",
            "           2     0.9875    0.9942    0.9908      1032\n",
            "           3     0.9901    0.9931    0.9916      1010\n",
            "           4     0.9909    0.9939    0.9924       982\n",
            "           5     0.9899    0.9922    0.9910       892\n",
            "           6     0.9968    0.9823    0.9895       958\n",
            "           7     0.9941    0.9844    0.9892      1028\n",
            "           8     0.9797    0.9887    0.9842       974\n",
            "           9     0.9910    0.9832    0.9871      1009\n",
            "\n",
            "    accuracy                         0.9906     10000\n",
            "   macro avg     0.9905    0.9905    0.9905     10000\n",
            "weighted avg     0.9906    0.9906    0.9906     10000\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 977    0    0    1    0    0    1    0    1    0]\n",
            " [   0 1131    1    1    0    1    0    0    1    0]\n",
            " [   1    1 1026    1    1    0    0    1    1    0]\n",
            " [   0    0    0 1003    0    3    0    0    4    0]\n",
            " [   0    0    0    0  976    0    1    0    1    4]\n",
            " [   2    0    0    4    0  885    1    0    0    0]\n",
            " [   4    2    0    0    2    2  941    0    7    0]\n",
            " [   0    2    8    2    0    0    0 1012    2    2]\n",
            " [   3    0    3    1    0    1    0    0  963    3]\n",
            " [   0    0    1    0    6    2    0    5    3  992]]\n",
            "\n",
            "=== Training CNN on cifar10 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:841: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:315.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10][CNN] epoch 01 | test acc 0.5271\n",
            "[cifar10][CNN] epoch 02 | test acc 0.5892\n",
            "[cifar10][CNN] epoch 03 | test acc 0.6216\n",
            "[cifar10][CNN] epoch 04 | test acc 0.6650\n",
            "[cifar10][CNN] epoch 05 | test acc 0.6740\n",
            "[cifar10][CNN] epoch 06 | test acc 0.6872\n",
            "[cifar10][CNN] epoch 07 | test acc 0.6931\n",
            "[cifar10][CNN] epoch 08 | test acc 0.7059\n",
            "[cifar10][CNN] epoch 09 | test acc 0.7053\n",
            "[cifar10][CNN] epoch 10 | test acc 0.6962\n",
            "[cnn_small_full_cifar10][cifar10][seed=42] acc=0.6962 | train_time=79.27637791633606s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7417    0.7120    0.7265      1000\n",
            "           1     0.7858    0.8440    0.8139      1000\n",
            "           2     0.4910    0.7080    0.5799      1000\n",
            "           3     0.5981    0.4480    0.5123      1000\n",
            "           4     0.8160    0.4390    0.5709      1000\n",
            "           5     0.5345    0.7130    0.6110      1000\n",
            "           6     0.7375    0.8120    0.7730      1000\n",
            "           7     0.7718    0.7710    0.7714      1000\n",
            "           8     0.8705    0.7660    0.8149      1000\n",
            "           9     0.8115    0.7490    0.7790      1000\n",
            "\n",
            "    accuracy                         0.6962     10000\n",
            "   macro avg     0.7158    0.6962    0.6953     10000\n",
            "weighted avg     0.7158    0.6962    0.6953     10000\n",
            "\n",
            "Confusion matrix:\n",
            " [[712  29  95  22   9  12  14  15  47  45]\n",
            " [ 26 844  23   5   0  11   9   5  14  63]\n",
            " [ 45   4 708  38  25  74  57  33   7   9]\n",
            " [ 13  10 131 448  20 264  72  27   5  10]\n",
            " [ 31   4 208  52 439  91  87  77   9   2]\n",
            " [  9   3  85 103  15 713  24  40   5   3]\n",
            " [  2   4  81  35   5  51 812   3   5   2]\n",
            " [ 17   2  66  21  20  94   5 771   1   3]\n",
            " [ 72  57  23  11   4  12  12   6 766  37]\n",
            " [ 33 117  22  14   1  12   9  22  21 749]]\n",
            "CNN results saved to: /content/cnn_cache/cnn_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablations"
      ],
      "metadata": {
        "id": "pfH3pISI2ShZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ablation Overview**\n",
        "\n",
        "This section presents targeted ablation studies that evaluate design decisions made for the ROCKET pipeline:\n",
        "- Feature ablation (1D): Which feature types (“ppv,” “max,” “mpv,” “mipv,” “lspv”) are necessary?  \n",
        "- 1D vs. 2D: Comparison of 1D and 2D kernels with the same feature sets.\n",
        "- Padding ablation (2D): Effect of different padding modes (random, same, valid).  \n",
        "- Preproc-bank ablation: Comparison of RGB/Grey kernels on dataset wide normalization vs. preproc-bank (per-image norm) and mixtures.\n",
        "- Kernel configuration ablation: Selection of k/d configurations and scalability with K.\n",
        "\n",
        "Important for reproducibility:\n",
        "- Always use `set_seed(SEED)` and `set_deterministic()` (see config.py).\n",
        "- Note and save kernel_hash, seed, and the resulting CSV paths (see `get_cache_dir(...)`).  \n",
        "- If FEATURE_TYPES or PREPROC_MODES are changed, invalidate feature caches and note the change (see utils notes)."
      ],
      "metadata": {
        "id": "7r5lGq2ZRZAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Ablation Test in 1D"
      ],
      "metadata": {
        "id": "Suwk6pR_2ato"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Feature Ablation (1D)\n",
        "Purpose: Investigate which combinations of feature statistics (ppv, max, mpv, mipv, lspv)\n",
        "have the greatest influence on accuracy/feature costs.\n",
        "\n",
        "Important parameters: N_KERNELS, K_CHOICES, DILATION_CAP, PADDING_MODE_1D, FEATURE_VARIANTS.\n",
        "Outputs: feature_ablation_summary.csv (CACHE_DIR), possibly per-variant feature_dim and train_time.\n",
        "\"\"\"\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from config import set_seed, set_deterministic, get_loaders, build_ridge, ALPHAS, SEED, STRIDE_1D, DATASET_LIST as dataset_list\n",
        "from utils.kernels import make_random_kernels_1d\n",
        "from utils.features import extract_features_1d\n",
        "from utils.settings import get_cache_dir\n",
        "\n",
        "# reproducibility\n",
        "set_seed(SEED)\n",
        "set_deterministic()\n",
        "\n",
        "# settings (ENV-overrides allowed via config only)\n",
        "MODE = \"pure_rocket_1d_featabl\"\n",
        "N_KERNELS = int(os.environ.get(\"N_KERNELS\", \"3024\"))\n",
        "KERNEL_SIZE_CANDIDATES = [int(k) for k in os.environ.get(\"K_CHOICES\", \"7,9,11\").split(\",\")]\n",
        "DILATION_CAP = int(os.environ.get(\"DILATION_CAP\", \"64\"))\n",
        "PADDING_MODE_1D = os.environ.get(\"PADDING_MODE_1D\", \"random\").lower()\n",
        "\n",
        "FEATURE_VARIANTS = [\n",
        "    {\"name\":\"F1_ppv_max\",               \"features\":[\"ppv\",\"max\"]},\n",
        "    {\"name\":\"F2_ppv_max_mpv\",           \"features\":[\"ppv\",\"max\",\"mpv\"]},\n",
        "    {\"name\":\"F3_ppv_max_mipv\",          \"features\":[\"ppv\",\"max\",\"mipv\"]},\n",
        "    {\"name\":\"F4_ppv_max_lspv\",          \"features\":[\"ppv\",\"max\",\"lspv\"]},\n",
        "    {\"name\":\"F5_ppv_max_mpv_mipv\",      \"features\":[\"ppv\",\"max\",\"mpv\",\"mipv\"]},\n",
        "    {\"name\":\"F6_ppv_max_mpv_lspv\",      \"features\":[\"ppv\",\"max\",\"mpv\",\"lspv\"]},\n",
        "    {\"name\":\"F7_ppv_max_mipv_lspv\",     \"features\":[\"ppv\",\"max\",\"mipv\",\"lspv\"]},\n",
        "    {\"name\":\"F8_ppv_max_mpv_mipv_lspv\", \"features\":[\"ppv\",\"max\",\"mpv\",\"mipv\",\"lspv\"]},\n",
        "]\n",
        "\n",
        "CACHE_DIR = get_cache_dir(\"rocket1d_cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_SUMMARY_CSV = str(CACHE_DIR.joinpath(\"feature_ablation_summary.csv\"))\n",
        "\n",
        "def main():\n",
        "    set_seed(SEED); set_deterministic()\n",
        "    print(\"ALPHAS:\", ALPHAS, \"PADDING_1D:\", PADDING_MODE_1D)\n",
        "\n",
        "    rows = []\n",
        "    for dataset_name in dataset_list:\n",
        "        train_loader, test_loader, in_channels, (H, W), seq_len = get_loaders(dataset_name, seed=SEED, quick_per_class=None)\n",
        "        print(f\"\\nDataset={dataset_name} in_channels={in_channels} seq_len={seq_len} train={len(train_loader.dataset)} test={len(test_loader.dataset)}\")\n",
        "\n",
        "        kernels = make_random_kernels_1d(N_KERNELS, in_channels, KERNEL_SIZE_CANDIDATES, seq_len, seed=SEED, dilation_cap=DILATION_CAP)\n",
        "\n",
        "        for variant in FEATURE_VARIANTS:\n",
        "            print(f\"\\n--- {dataset_name} / {variant['name']} ---\")\n",
        "            X_train, y_train = extract_features_1d(train_loader, kernels, in_channels, seq_len,\n",
        "                                                   feature_types=variant[\"features\"], stride=STRIDE_1D,\n",
        "                                                   padding_mode=PADDING_MODE_1D, seed=SEED)\n",
        "            X_test, y_test = extract_features_1d(test_loader, kernels, in_channels, seq_len,\n",
        "                                                 feature_types=variant[\"features\"], stride=STRIDE_1D,\n",
        "                                                 padding_mode=PADDING_MODE_1D, seed=SEED)\n",
        "            print(\"feature_dim:\", X_train.shape[1])\n",
        "\n",
        "            best_alpha, best_acc, best_time = None, -1.0, None\n",
        "            for alpha in ALPHAS:\n",
        "                pipe = build_ridge(alpha=alpha, scale=True)\n",
        "                t0 = time.time()\n",
        "                pipe.fit(X_train, y_train)\n",
        "                tt = time.time() - t0\n",
        "                y_pred = pipe.predict(X_test)\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "                print(f\"alpha={alpha} acc={acc:.4f} time={tt:.1f}s\")\n",
        "                if acc > best_acc:\n",
        "                    best_alpha, best_acc, best_time = alpha, acc, tt\n",
        "\n",
        "            rows.append({\n",
        "                \"dataset\": dataset_name,\n",
        "                \"variant\": variant[\"name\"],\n",
        "                \"features\": \"|\".join(variant[\"features\"]),\n",
        "                \"feature_dim\": int(X_train.shape[1]),\n",
        "                \"best_alpha\": int(best_alpha) if best_alpha is not None else None,\n",
        "                \"acc\": float(best_acc),\n",
        "                \"train_time\": float(best_time) if best_time is not None else None,\n",
        "                \"n_kernels\": int(N_KERNELS),\n",
        "                \"k_choices\": \"|\".join(map(str,KERNEL_SIZE_CANDIDATES)),\n",
        "                \"dilation_cap\": int(DILATION_CAP),\n",
        "                \"stride_1d\": int(STRIDE_1D),\n",
        "                \"padding_1d\": PADDING_MODE_1D,\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(RESULTS_SUMMARY_CSV, index=False)\n",
        "    print(\"\\nSaved:\", RESULTS_SUMMARY_CSV)\n",
        "    print(df.sort_values(\"acc\", ascending=False)[[\"dataset\",\"variant\",\"features\",\"acc\",\"feature_dim\"]].to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Pwzht4zQ2aAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb4ccb2-795d-4adc-b816-5a5cf0ea7fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALPHAS: [1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400] PADDING_1D: random\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.68MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 130kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.3MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset=mnist in_channels=1 seq_len=784 train=60000 test=10000\n",
            "\n",
            "--- mnist / F1_ppv_max ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_dim: 6048\n",
            "alpha=1000 acc=0.9858 time=13.2s\n",
            "alpha=1200 acc=0.9855 time=13.0s\n",
            "alpha=1400 acc=0.9851 time=13.0s\n",
            "alpha=1600 acc=0.9850 time=13.1s\n",
            "alpha=1800 acc=0.9850 time=13.0s\n",
            "alpha=2000 acc=0.9847 time=13.1s\n",
            "alpha=2200 acc=0.9845 time=12.9s\n",
            "alpha=2400 acc=0.9842 time=13.0s\n",
            "\n",
            "--- mnist / F2_ppv_max_mpv ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_dim: 9072\n",
            "alpha=1000 acc=0.9879 time=20.1s\n",
            "alpha=1200 acc=0.9879 time=22.7s\n",
            "alpha=1400 acc=0.9875 time=21.1s\n",
            "alpha=1600 acc=0.9871 time=21.2s\n",
            "alpha=1800 acc=0.9868 time=21.1s\n",
            "alpha=2000 acc=0.9866 time=20.2s\n",
            "alpha=2200 acc=0.9865 time=21.1s\n",
            "alpha=2400 acc=0.9864 time=21.1s\n",
            "\n",
            "--- mnist / F3_ppv_max_mipv ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_dim: 9072\n",
            "alpha=1000 acc=0.9887 time=20.9s\n",
            "alpha=1200 acc=0.9887 time=20.2s\n",
            "alpha=1400 acc=0.9887 time=20.9s\n",
            "alpha=1600 acc=0.9883 time=21.2s\n",
            "alpha=1800 acc=0.9885 time=21.2s\n",
            "alpha=2000 acc=0.9884 time=21.4s\n",
            "alpha=2200 acc=0.9884 time=23.9s\n",
            "alpha=2400 acc=0.9884 time=24.4s\n",
            "\n",
            "--- mnist / F4_ppv_max_lspv ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_dim: 9072\n",
            "alpha=1000 acc=0.9882 time=22.7s\n",
            "alpha=1200 acc=0.9881 time=21.8s\n",
            "alpha=1400 acc=0.9880 time=21.3s\n",
            "alpha=1600 acc=0.9882 time=22.4s\n",
            "alpha=1800 acc=0.9881 time=20.7s\n",
            "alpha=2000 acc=0.9881 time=21.3s\n",
            "alpha=2200 acc=0.9881 time=21.0s\n",
            "alpha=2400 acc=0.9880 time=20.6s\n",
            "\n",
            "--- mnist / F5_ppv_max_mpv_mipv ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_dim: 12096\n",
            "alpha=1000 acc=0.9901 time=33.0s\n",
            "alpha=1200 acc=0.9900 time=32.4s\n",
            "alpha=1400 acc=0.9896 time=32.4s\n",
            "alpha=1600 acc=0.9895 time=32.6s\n",
            "alpha=1800 acc=0.9894 time=33.8s\n",
            "alpha=2000 acc=0.9895 time=32.3s\n",
            "alpha=2200 acc=0.9895 time=32.3s\n",
            "alpha=2400 acc=0.9895 time=33.5s\n",
            "\n",
            "--- mnist / F6_ppv_max_mpv_lspv ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_dim: 12096\n",
            "alpha=1000 acc=0.9891 time=32.5s\n",
            "alpha=1200 acc=0.9890 time=33.0s\n",
            "alpha=1400 acc=0.9891 time=32.3s\n",
            "alpha=1600 acc=0.9887 time=32.5s\n",
            "alpha=1800 acc=0.9887 time=32.5s\n",
            "alpha=2000 acc=0.9886 time=32.2s\n",
            "alpha=2200 acc=0.9885 time=32.3s\n",
            "alpha=2400 acc=0.9886 time=32.6s\n",
            "\n",
            "--- mnist / F7_ppv_max_mipv_lspv ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature_dim: 12096\n",
            "alpha=1000 acc=0.9899 time=32.4s\n",
            "alpha=1200 acc=0.9898 time=32.3s\n",
            "alpha=1400 acc=0.9899 time=32.3s\n",
            "alpha=1600 acc=0.9899 time=32.4s\n",
            "alpha=1800 acc=0.9896 time=33.5s\n",
            "alpha=2000 acc=0.9896 time=32.5s\n",
            "alpha=2200 acc=0.9894 time=32.3s\n",
            "alpha=2400 acc=0.9894 time=32.7s\n",
            "\n",
            "--- mnist / F8_ppv_max_mpv_mipv_lspv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 15120\n",
            "alpha=1000 acc=0.9902 time=44.8s\n",
            "alpha=1200 acc=0.9901 time=44.2s\n",
            "alpha=1400 acc=0.9901 time=43.7s\n",
            "alpha=1600 acc=0.9898 time=44.7s\n",
            "alpha=1800 acc=0.9898 time=44.1s\n",
            "alpha=2000 acc=0.9897 time=43.9s\n",
            "alpha=2200 acc=0.9895 time=44.1s\n",
            "alpha=2400 acc=0.9895 time=44.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset=cifar10 in_channels=3 seq_len=1024 train=50000 test=10000\n",
            "\n",
            "--- cifar10 / F1_ppv_max ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 6048\n",
            "alpha=1000 acc=0.6250 time=10.9s\n",
            "alpha=1200 acc=0.6258 time=11.0s\n",
            "alpha=1400 acc=0.6255 time=10.9s\n",
            "alpha=1600 acc=0.6247 time=10.2s\n",
            "alpha=1800 acc=0.6231 time=10.1s\n",
            "alpha=2000 acc=0.6226 time=10.2s\n",
            "alpha=2200 acc=0.6216 time=10.2s\n",
            "alpha=2400 acc=0.6214 time=10.1s\n",
            "\n",
            "--- cifar10 / F2_ppv_max_mpv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 9072\n",
            "alpha=1000 acc=0.6512 time=17.8s\n",
            "alpha=1200 acc=0.6499 time=17.1s\n",
            "alpha=1400 acc=0.6492 time=18.0s\n",
            "alpha=1600 acc=0.6493 time=17.1s\n",
            "alpha=1800 acc=0.6490 time=17.9s\n",
            "alpha=2000 acc=0.6486 time=17.1s\n",
            "alpha=2200 acc=0.6481 time=17.9s\n",
            "alpha=2400 acc=0.6487 time=17.1s\n",
            "\n",
            "--- cifar10 / F3_ppv_max_mipv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 9072\n",
            "alpha=1000 acc=0.6354 time=20.4s\n",
            "alpha=1200 acc=0.6355 time=20.1s\n",
            "alpha=1400 acc=0.6358 time=19.2s\n",
            "alpha=1600 acc=0.6357 time=19.3s\n",
            "alpha=1800 acc=0.6358 time=19.5s\n",
            "alpha=2000 acc=0.6358 time=18.8s\n",
            "alpha=2200 acc=0.6367 time=19.3s\n",
            "alpha=2400 acc=0.6367 time=18.9s\n",
            "\n",
            "--- cifar10 / F4_ppv_max_lspv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 9072\n",
            "alpha=1000 acc=0.6333 time=17.7s\n",
            "alpha=1200 acc=0.6343 time=18.0s\n",
            "alpha=1400 acc=0.6351 time=17.6s\n",
            "alpha=1600 acc=0.6343 time=17.8s\n",
            "alpha=1800 acc=0.6355 time=17.6s\n",
            "alpha=2000 acc=0.6353 time=17.4s\n",
            "alpha=2200 acc=0.6352 time=17.6s\n",
            "alpha=2400 acc=0.6345 time=17.3s\n",
            "\n",
            "--- cifar10 / F5_ppv_max_mpv_mipv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 12096\n",
            "alpha=1000 acc=0.6559 time=27.9s\n",
            "alpha=1200 acc=0.6567 time=27.8s\n",
            "alpha=1400 acc=0.6557 time=27.5s\n",
            "alpha=1600 acc=0.6568 time=27.8s\n",
            "alpha=1800 acc=0.6553 time=29.1s\n",
            "alpha=2000 acc=0.6551 time=27.7s\n",
            "alpha=2200 acc=0.6545 time=27.9s\n",
            "alpha=2400 acc=0.6544 time=28.2s\n",
            "\n",
            "--- cifar10 / F6_ppv_max_mpv_lspv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 12096\n",
            "alpha=1000 acc=0.6524 time=33.1s\n",
            "alpha=1200 acc=0.6528 time=31.3s\n",
            "alpha=1400 acc=0.6536 time=31.4s\n",
            "alpha=1600 acc=0.6536 time=32.2s\n",
            "alpha=1800 acc=0.6540 time=31.5s\n",
            "alpha=2000 acc=0.6541 time=31.2s\n",
            "alpha=2200 acc=0.6545 time=31.5s\n",
            "alpha=2400 acc=0.6543 time=31.5s\n",
            "\n",
            "--- cifar10 / F7_ppv_max_mipv_lspv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 12096\n",
            "alpha=1000 acc=0.6424 time=31.2s\n",
            "alpha=1200 acc=0.6433 time=30.8s\n",
            "alpha=1400 acc=0.6443 time=30.3s\n",
            "alpha=1600 acc=0.6447 time=29.5s\n",
            "alpha=1800 acc=0.6448 time=31.0s\n",
            "alpha=2000 acc=0.6452 time=29.6s\n",
            "alpha=2200 acc=0.6450 time=30.6s\n",
            "alpha=2400 acc=0.6451 time=28.8s\n",
            "\n",
            "--- cifar10 / F8_ppv_max_mpv_mipv_lspv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature_dim: 15120\n",
            "alpha=1000 acc=0.6563 time=46.4s\n",
            "alpha=1200 acc=0.6583 time=46.0s\n",
            "alpha=1400 acc=0.6589 time=46.1s\n",
            "alpha=1600 acc=0.6587 time=46.0s\n",
            "alpha=1800 acc=0.6592 time=46.4s\n",
            "alpha=2000 acc=0.6589 time=46.1s\n",
            "alpha=2200 acc=0.6586 time=45.9s\n",
            "alpha=2400 acc=0.6582 time=46.1s\n",
            "\n",
            "Saved: /content/rocket1d_cache/feature_ablation_summary.csv\n",
            "dataset                  variant              features    acc  feature_dim\n",
            "  mnist F8_ppv_max_mpv_mipv_lspv ppv|max|mpv|mipv|lspv 0.9902        15120\n",
            "  mnist      F5_ppv_max_mpv_mipv      ppv|max|mpv|mipv 0.9901        12096\n",
            "  mnist     F7_ppv_max_mipv_lspv     ppv|max|mipv|lspv 0.9899        12096\n",
            "  mnist      F6_ppv_max_mpv_lspv      ppv|max|mpv|lspv 0.9891        12096\n",
            "  mnist          F3_ppv_max_mipv          ppv|max|mipv 0.9887         9072\n",
            "  mnist          F4_ppv_max_lspv          ppv|max|lspv 0.9882         9072\n",
            "  mnist           F2_ppv_max_mpv           ppv|max|mpv 0.9879         9072\n",
            "  mnist               F1_ppv_max               ppv|max 0.9858         6048\n",
            "cifar10 F8_ppv_max_mpv_mipv_lspv ppv|max|mpv|mipv|lspv 0.6592        15120\n",
            "cifar10      F5_ppv_max_mpv_mipv      ppv|max|mpv|mipv 0.6568        12096\n",
            "cifar10      F6_ppv_max_mpv_lspv      ppv|max|mpv|lspv 0.6545        12096\n",
            "cifar10           F2_ppv_max_mpv           ppv|max|mpv 0.6512         9072\n",
            "cifar10     F7_ppv_max_mipv_lspv     ppv|max|mipv|lspv 0.6452        12096\n",
            "cifar10          F3_ppv_max_mipv          ppv|max|mipv 0.6367         9072\n",
            "cifar10          F4_ppv_max_lspv          ppv|max|lspv 0.6355         9072\n",
            "cifar10               F1_ppv_max               ppv|max 0.6258         6048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1D vs. 2D Kernels"
      ],
      "metadata": {
        "id": "Xfy6WUlV2lx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1D vs. 2D kernels\n",
        "Purpose: Direct comparison of identical feature sets on 1D and 2D kernels (same K, D, N).\n",
        "Important: Use IMAGE_HW for 2D. Identical seed/kernels not possible (different sampling), so document.\n",
        "           Dilation is set to [1,2,3] for 2D to keep computation costs accountable.\n",
        "Outputs: dim_feature_runs.csv\n",
        "\"\"\"\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Tuple\n",
        "from pathlib import Path\n",
        "\n",
        "from config import set_seed, set_deterministic, get_loaders, build_ridge, ALPHAS, SEED, STRIDE_1D, STRIDE_2D, DATASET_LIST as dataset_list\n",
        "from utils.kernels import make_random_kernels_1d, make_random_kernels_2d\n",
        "from utils.features import extract_features_1d, extract_features_2d\n",
        "from utils.settings import get_cache_dir\n",
        "from utils.constants import FEATURE_TYPES_1D, FEATURE_TYPES_2D, PREPROC_NONE\n",
        "\n",
        "set_seed(SEED); set_deterministic()\n",
        "\n",
        "# Experiment defaults (experiment-specific ENV allowed)\n",
        "N_KERNELS_1D = int(os.environ.get(\"N_KERNELS_1D\", \"3024\"))\n",
        "K_CHOICES_1D = list(map(int, os.environ.get(\"K_CHOICES_1D\", \"7,9,11\").split(\",\")))\n",
        "DILATION_CAP_1D = int(os.environ.get(\"DILATION_CAP_1D\", \"64\"))\n",
        "PADDING_MODE_1D = os.environ.get(\"PADDING_MODE_1D\", \"random\").lower()\n",
        "\n",
        "N_KERNELS_2D = int(os.environ.get(\"N_KERNELS_2D\", \"3024\"))\n",
        "K_CHOICES_2D = list(map(int, os.environ.get(\"K_CHOICES_2D\", \"7,9,11\").split(\",\")))\n",
        "D_CHOICES_2D = list(map(int, os.environ.get(\"D_CHOICES_2D\", \"1,2,3\").split(\",\")))\n",
        "PADDING_MODE_2D = os.environ.get(\"PADDING_MODE_2D\", \"random\").lower()\n",
        "\n",
        "# feature set mapping\n",
        "FEATURE_SETS = {\n",
        "    \"ablation_best\": {\n",
        "        \"1d\": [\"ppv\", \"max\", \"mpv\", \"mipv\"],\n",
        "        \"2d\": [\"ppv\", \"max\", \"mpv\", \"mipv_y\", \"mipv_x\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# cache/results\n",
        "CACHE_DIR = get_cache_dir(\"rocket_dim_feature_cont\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_CSV = str(Path(CACHE_DIR).joinpath(\"dim_feature_runs.csv\"))\n",
        "\n",
        "def run_one(dataset_tag, train_loader, test_loader, in_channels, H, W, seq_len, kernel_dim, feature_set_key):\n",
        "    ft_1d = FEATURE_SETS[feature_set_key][\"1d\"]\n",
        "    ft_2d = FEATURE_SETS[feature_set_key][\"2d\"]\n",
        "    padding_tag = PADDING_MODE_2D if kernel_dim == \"2d\" else PADDING_MODE_1D\n",
        "    tag = f\"{dataset_tag}_{kernel_dim}_{feature_set_key}_{padding_tag}\"\n",
        "\n",
        "    if kernel_dim == \"1d\":\n",
        "        kernels_1d = make_random_kernels_1d(N_KERNELS_1D, in_channels, K_CHOICES_1D, seq_len, seed=SEED, dilation_cap=DILATION_CAP_1D)\n",
        "        X_train, y_train = extract_features_1d(train_loader, kernels_1d, in_channels, seq_len, ft_1d, stride=STRIDE_1D, padding_mode=PADDING_MODE_1D, seed=SEED)\n",
        "        X_test,  y_test  = extract_features_1d(test_loader,  kernels_1d, in_channels, seq_len, ft_1d, stride=STRIDE_1D, padding_mode=PADDING_MODE_1D, seed=SEED)\n",
        "    else:\n",
        "        kernels_2d = make_random_kernels_2d(N_KERNELS_2D, in_channels, K_CHOICES_2D, D_CHOICES_2D, seed=SEED)\n",
        "        # use actual image size (H,W) for image_hw\n",
        "        X_train, y_train = extract_features_2d(train_loader, kernels_2d, ft_2d, image_hw=(H, W), padding_mode=PADDING_MODE_2D, stride=STRIDE_2D, seed=SEED)\n",
        "        X_test,  y_test  = extract_features_2d(test_loader,  kernels_2d, ft_2d, image_hw=(H, W), padding_mode=PADDING_MODE_2D, stride=STRIDE_2D, seed=SEED)\n",
        "\n",
        "    print(f\"[{tag}] X_train {X_train.shape} X_test {X_test.shape}\")\n",
        "\n",
        "    best_alpha, best_acc, best_time = None, -1.0, None\n",
        "    for alpha in ALPHAS:\n",
        "        pipe = build_ridge(alpha=alpha, scale=True)\n",
        "        t0 = time.time()\n",
        "        pipe.fit(X_train, y_train)\n",
        "        tt = time.time() - t0\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        acc = float((y_pred == y_test).mean())\n",
        "        print(f\"[{tag}] alpha={alpha} acc={acc:.4f} time={tt:.1f}s\")\n",
        "        if acc > best_acc:\n",
        "            best_alpha, best_acc, best_time = alpha, acc, tt\n",
        "\n",
        "    return {\n",
        "        \"dataset\": dataset_tag,\n",
        "        \"kernel_dim\": kernel_dim,\n",
        "        \"features\": \"|\".join(ft_2d if kernel_dim == \"2d\" else ft_1d),\n",
        "        \"feature_dim\": int(X_train.shape[1]) if X_train.size else 0,\n",
        "        \"best_alpha\": int(best_alpha) if best_alpha is not None else None,\n",
        "        \"acc\": float(best_acc),\n",
        "        \"train_time\": float(best_time) if best_time is not None else None,\n",
        "        \"n_kernels\": int(N_KERNELS_2D if kernel_dim == \"2d\" else N_KERNELS_1D),\n",
        "        \"stride_1d\": int(STRIDE_1D),\n",
        "        \"stride_2d\": int(STRIDE_2D)\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    set_seed(SEED); set_deterministic()\n",
        "    rows = []\n",
        "    for dataset_name in dataset_list:\n",
        "        train_loader, test_loader, in_channels, (H, W), seq_len = get_loaders(dataset_name, seed=SEED, quick_per_class=None)\n",
        "        print(f\"\\nDataset={dataset_name} in_channels={in_channels} seq_len={seq_len}\")\n",
        "        # 1d run\n",
        "        rows.append(run_one(dataset_name, train_loader, test_loader, in_channels, H, W, seq_len, \"1d\", \"ablation_best\"))\n",
        "        # 2d run (with actual image hw)\n",
        "        rows.append(run_one(dataset_name, train_loader, test_loader, in_channels, H, W, seq_len, \"2d\", \"ablation_best\"))\n",
        "\n",
        "    pd.DataFrame(rows).to_csv(RESULTS_CSV, index=False)\n",
        "    print(\"\\nSaved:\", RESULTS_CSV)\n",
        "    print(pd.DataFrame(rows).sort_values(\"acc\", ascending=False)[[\"dataset\",\"kernel_dim\",\"features\",\"acc\",\"feature_dim\"]].to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "kxyrv-Qd2pkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec346282-8162-4259-db3e-3edcbfb38c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset=mnist in_channels=1 seq_len=784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist_1d_ablation_best_random] X_train (60000, 12096) X_test (10000, 12096)\n",
            "[mnist_1d_ablation_best_random] alpha=1000 acc=0.9901 time=36.2s\n",
            "[mnist_1d_ablation_best_random] alpha=1200 acc=0.9900 time=35.4s\n",
            "[mnist_1d_ablation_best_random] alpha=1400 acc=0.9896 time=35.2s\n",
            "[mnist_1d_ablation_best_random] alpha=1600 acc=0.9895 time=35.1s\n",
            "[mnist_1d_ablation_best_random] alpha=1800 acc=0.9894 time=34.9s\n",
            "[mnist_1d_ablation_best_random] alpha=2000 acc=0.9895 time=35.2s\n",
            "[mnist_1d_ablation_best_random] alpha=2200 acc=0.9895 time=35.1s\n",
            "[mnist_1d_ablation_best_random] alpha=2400 acc=0.9895 time=35.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist_2d_ablation_best_random] X_train (60000, 15120) X_test (10000, 15120)\n",
            "[mnist_2d_ablation_best_random] alpha=1000 acc=0.9912 time=44.4s\n",
            "[mnist_2d_ablation_best_random] alpha=1200 acc=0.9913 time=44.5s\n",
            "[mnist_2d_ablation_best_random] alpha=1400 acc=0.9912 time=44.3s\n",
            "[mnist_2d_ablation_best_random] alpha=1600 acc=0.9913 time=45.1s\n",
            "[mnist_2d_ablation_best_random] alpha=1800 acc=0.9913 time=44.1s\n",
            "[mnist_2d_ablation_best_random] alpha=2000 acc=0.9914 time=43.4s\n",
            "[mnist_2d_ablation_best_random] alpha=2200 acc=0.9914 time=44.9s\n",
            "[mnist_2d_ablation_best_random] alpha=2400 acc=0.9913 time=44.4s\n",
            "\n",
            "Dataset=cifar10 in_channels=3 seq_len=1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10_1d_ablation_best_random] X_train (50000, 12096) X_test (10000, 12096)\n",
            "[cifar10_1d_ablation_best_random] alpha=1000 acc=0.6560 time=28.2s\n",
            "[cifar10_1d_ablation_best_random] alpha=1200 acc=0.6566 time=29.2s\n",
            "[cifar10_1d_ablation_best_random] alpha=1400 acc=0.6559 time=27.8s\n",
            "[cifar10_1d_ablation_best_random] alpha=1600 acc=0.6568 time=28.1s\n",
            "[cifar10_1d_ablation_best_random] alpha=1800 acc=0.6552 time=29.4s\n",
            "[cifar10_1d_ablation_best_random] alpha=2000 acc=0.6551 time=28.1s\n",
            "[cifar10_1d_ablation_best_random] alpha=2200 acc=0.6545 time=27.9s\n",
            "[cifar10_1d_ablation_best_random] alpha=2400 acc=0.6544 time=29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10_2d_ablation_best_random] X_train (50000, 15120) X_test (10000, 15120)\n",
            "[cifar10_2d_ablation_best_random] alpha=1000 acc=0.6667 time=38.0s\n",
            "[cifar10_2d_ablation_best_random] alpha=1200 acc=0.6673 time=37.5s\n",
            "[cifar10_2d_ablation_best_random] alpha=1400 acc=0.6679 time=37.2s\n",
            "[cifar10_2d_ablation_best_random] alpha=1600 acc=0.6680 time=38.9s\n",
            "[cifar10_2d_ablation_best_random] alpha=1800 acc=0.6671 time=37.7s\n",
            "[cifar10_2d_ablation_best_random] alpha=2000 acc=0.6670 time=37.5s\n",
            "[cifar10_2d_ablation_best_random] alpha=2200 acc=0.6664 time=38.0s\n",
            "[cifar10_2d_ablation_best_random] alpha=2400 acc=0.6650 time=38.1s\n",
            "\n",
            "Saved: /content/rocket_dim_feature_cont/dim_feature_runs.csv\n",
            "dataset kernel_dim                  features    acc  feature_dim\n",
            "  mnist         2d ppv|max|mpv|mipv_y|mipv_x 0.9914        15120\n",
            "  mnist         1d          ppv|max|mpv|mipv 0.9901        12096\n",
            "cifar10         2d ppv|max|mpv|mipv_y|mipv_x 0.6680        15120\n",
            "cifar10         1d          ppv|max|mpv|mipv 0.6568        12096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding Ablation"
      ],
      "metadata": {
        "id": "wMRgCCXD2qcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Padding Ablation (2D)\n",
        "Purpose: Measure the effect of padding_mode ∈ {random,same,valid} on feature dimension and accuracy.\n",
        "Important: PADDING_MODES_2D, FEATURE_SET, based on ablations before.\n",
        "Outputs: padding_check_results.csv\n",
        "\"\"\"\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from config import set_seed, set_deterministic, get_loaders, ALPHAS, SEED, STRIDE_2D, DATASET_LIST as dataset_list\n",
        "from utils.kernels import make_random_kernels_2d\n",
        "from utils.features import extract_features_2d\n",
        "from utils.settings import get_cache_dir\n",
        "from utils.constants import PREPROC_IMAGE_NORM\n",
        "\n",
        "set_seed(SEED); set_deterministic()\n",
        "\n",
        "# experiment-level settings (can be ENV-overridden)\n",
        "N_KERNELS_2D = int(os.environ.get(\"N_KERNELS_2D\", \"3024\"))\n",
        "K_CHOICES_2D = list(map(int, os.environ.get(\"K_CHOICES_2D\", \"7,9,11\").split(\",\")))\n",
        "D_CHOICES_2D = list(map(int, os.environ.get(\"D_CHOICES_2D\", \"1,2,3\").split(\",\")))\n",
        "PADDING_MODES_2D = [m.strip() for m in os.environ.get(\"PADDING_MODES_2D\", \"random,same,valid\").split(\",\")]\n",
        "\n",
        "FEATURE_SET = \"ablation_best\"\n",
        "FEATURE_SETS = {\"ablation_best\": [\"ppv\",\"max\",\"mpv\",\"mipv_y\",\"mipv_x\"]}\n",
        "\n",
        "CACHE_DIR = get_cache_dir(\"rocket_2d_padding_check_cache\")\n",
        "RESULTS_CSV = str(Path(CACHE_DIR).joinpath(\"padding_check_results.csv\"))\n",
        "\n",
        "def run_padding(dataset_tag, train_loader, test_loader, in_channels, image_hw, padding_mode_2d, feature_set_key):\n",
        "    ft_2d = FEATURE_SETS[feature_set_key]\n",
        "    tag = f\"{dataset_tag}_2d_{feature_set_key}_{padding_mode_2d}\"\n",
        "    kernels_2d = make_random_kernels_2d(N_KERNELS_2D, in_channels, K_CHOICES_2D, D_CHOICES_2D, seed=SEED)\n",
        "\n",
        "    X_train, y_train = extract_features_2d(train_loader, kernels_2d, ft_2d, image_hw=image_hw, padding_mode=padding_mode_2d, stride=STRIDE_2D, seed=SEED)\n",
        "    X_test,  y_test  = extract_features_2d(test_loader,  kernels_2d, ft_2d, image_hw=image_hw, padding_mode=padding_mode_2d, stride=STRIDE_2D, seed=SEED)\n",
        "    print(f\"[{tag}] X_train {X_train.shape} X_test {X_test.shape}\")\n",
        "\n",
        "    best_alpha, best_acc, best_time = None, -1.0, None\n",
        "    for alpha in ALPHAS:\n",
        "        from config import build_ridge\n",
        "        pipe = build_ridge(alpha=alpha, scale=True)\n",
        "        t0 = time.time(); pipe.fit(X_train, y_train); tt = time.time() - t0\n",
        "        y_pred = pipe.predict(X_test); acc = float((y_pred == y_test).mean())\n",
        "        print(f\"[{tag}] alpha={alpha} acc={acc:.4f} time={tt:.1f}s\")\n",
        "        if acc > best_acc:\n",
        "            best_alpha, best_acc, best_time = alpha, acc, tt\n",
        "\n",
        "    return {\n",
        "        \"dataset\": dataset_tag,\n",
        "        \"padding_2d\": padding_mode_2d,\n",
        "        \"features\": \"|\".join(ft_2d),\n",
        "        \"feature_dim\": int(X_train.shape[1]) if X_train.size else 0,\n",
        "        \"best_alpha\": int(best_alpha) if best_alpha is not None else None,\n",
        "        \"acc\": float(best_acc),\n",
        "        \"train_time\": float(best_time) if best_time is not None else None,\n",
        "        \"n_kernels\": int(N_KERNELS_2D),\n",
        "        \"k_choices\": \"|\".join(map(str, K_CHOICES_2D)),\n",
        "        \"d_choices\": \"|\".join(map(str, D_CHOICES_2D)),\n",
        "        \"stride_2d\": int(STRIDE_2D)\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    set_seed(SEED); set_deterministic()\n",
        "    rows = []\n",
        "    for dataset_name in dataset_list:\n",
        "        train_loader, test_loader, in_channels, (H,W), _ = get_loaders(dataset_name, seed=SEED, quick_per_class=None)\n",
        "        print(f\"\\nDataset={dataset_name} in_channels={in_channels} HxW={H}x{W}\")\n",
        "        for pad in PADDING_MODES_2D:\n",
        "            print(f\"Running pad={pad} on {dataset_name}\")\n",
        "            rows.append(run_padding(dataset_name, train_loader, test_loader, in_channels, (H,W), pad, FEATURE_SET))\n",
        "    pd.DataFrame(rows).to_csv(RESULTS_CSV, index=False)\n",
        "    print(\"\\nSaved:\", RESULTS_CSV)\n",
        "    print(pd.DataFrame(rows).sort_values([\"dataset\",\"padding_2d\",\"acc\"], ascending=[True,True,False])[[\"dataset\",\"padding_2d\",\"features\",\"acc\",\"feature_dim\"]].to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "rICHd2ib2t2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ea025a-1f01-467b-ce2e-10c0e60a6573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset=mnist in_channels=1 HxW=28x28\n",
            "Running pad=random on mnist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist_2d_ablation_best_random] X_train (60000, 15120) X_test (10000, 15120)\n",
            "[mnist_2d_ablation_best_random] alpha=1000 acc=0.9912 time=45.1s\n",
            "[mnist_2d_ablation_best_random] alpha=1200 acc=0.9913 time=44.2s\n",
            "[mnist_2d_ablation_best_random] alpha=1400 acc=0.9912 time=43.8s\n",
            "[mnist_2d_ablation_best_random] alpha=1600 acc=0.9913 time=45.0s\n",
            "[mnist_2d_ablation_best_random] alpha=1800 acc=0.9913 time=44.6s\n",
            "[mnist_2d_ablation_best_random] alpha=2000 acc=0.9914 time=44.0s\n",
            "[mnist_2d_ablation_best_random] alpha=2200 acc=0.9913 time=44.9s\n",
            "[mnist_2d_ablation_best_random] alpha=2400 acc=0.9913 time=44.2s\n",
            "Running pad=same on mnist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist_2d_ablation_best_same] X_train (60000, 15120) X_test (10000, 15120)\n",
            "[mnist_2d_ablation_best_same] alpha=1000 acc=0.9918 time=44.3s\n",
            "[mnist_2d_ablation_best_same] alpha=1200 acc=0.9918 time=44.3s\n",
            "[mnist_2d_ablation_best_same] alpha=1400 acc=0.9920 time=44.8s\n",
            "[mnist_2d_ablation_best_same] alpha=1600 acc=0.9920 time=44.4s\n",
            "[mnist_2d_ablation_best_same] alpha=1800 acc=0.9920 time=44.2s\n",
            "[mnist_2d_ablation_best_same] alpha=2000 acc=0.9919 time=45.0s\n",
            "[mnist_2d_ablation_best_same] alpha=2200 acc=0.9919 time=44.5s\n",
            "[mnist_2d_ablation_best_same] alpha=2400 acc=0.9917 time=43.7s\n",
            "Running pad=valid on mnist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mnist_2d_ablation_best_valid] X_train (60000, 13385) X_test (10000, 13385)\n",
            "[mnist_2d_ablation_best_valid] alpha=1000 acc=0.9919 time=37.1s\n",
            "[mnist_2d_ablation_best_valid] alpha=1200 acc=0.9917 time=37.2s\n",
            "[mnist_2d_ablation_best_valid] alpha=1400 acc=0.9913 time=37.2s\n",
            "[mnist_2d_ablation_best_valid] alpha=1600 acc=0.9911 time=37.7s\n",
            "[mnist_2d_ablation_best_valid] alpha=1800 acc=0.9911 time=37.5s\n",
            "[mnist_2d_ablation_best_valid] alpha=2000 acc=0.9911 time=37.2s\n",
            "[mnist_2d_ablation_best_valid] alpha=2200 acc=0.9910 time=36.8s\n",
            "[mnist_2d_ablation_best_valid] alpha=2400 acc=0.9909 time=36.7s\n",
            "\n",
            "Dataset=cifar10 in_channels=3 HxW=32x32\n",
            "Running pad=random on cifar10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10_2d_ablation_best_random] X_train (50000, 15120) X_test (10000, 15120)\n",
            "[cifar10_2d_ablation_best_random] alpha=1000 acc=0.6668 time=37.6s\n",
            "[cifar10_2d_ablation_best_random] alpha=1200 acc=0.6674 time=37.9s\n",
            "[cifar10_2d_ablation_best_random] alpha=1400 acc=0.6678 time=38.2s\n",
            "[cifar10_2d_ablation_best_random] alpha=1600 acc=0.6679 time=37.8s\n",
            "[cifar10_2d_ablation_best_random] alpha=1800 acc=0.6671 time=37.4s\n",
            "[cifar10_2d_ablation_best_random] alpha=2000 acc=0.6670 time=39.1s\n",
            "[cifar10_2d_ablation_best_random] alpha=2200 acc=0.6664 time=38.8s\n",
            "[cifar10_2d_ablation_best_random] alpha=2400 acc=0.6650 time=37.3s\n",
            "Running pad=same on cifar10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10_2d_ablation_best_same] X_train (50000, 15120) X_test (10000, 15120)\n",
            "[cifar10_2d_ablation_best_same] alpha=1000 acc=0.6685 time=37.4s\n",
            "[cifar10_2d_ablation_best_same] alpha=1200 acc=0.6699 time=37.4s\n",
            "[cifar10_2d_ablation_best_same] alpha=1400 acc=0.6696 time=37.8s\n",
            "[cifar10_2d_ablation_best_same] alpha=1600 acc=0.6689 time=38.2s\n",
            "[cifar10_2d_ablation_best_same] alpha=1800 acc=0.6688 time=37.7s\n",
            "[cifar10_2d_ablation_best_same] alpha=2000 acc=0.6696 time=37.1s\n",
            "[cifar10_2d_ablation_best_same] alpha=2200 acc=0.6697 time=39.0s\n",
            "[cifar10_2d_ablation_best_same] alpha=2400 acc=0.6687 time=38.8s\n",
            "Running pad=valid on cifar10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10_2d_ablation_best_valid] X_train (50000, 15120) X_test (10000, 15120)\n",
            "[cifar10_2d_ablation_best_valid] alpha=1000 acc=0.6685 time=38.4s\n",
            "[cifar10_2d_ablation_best_valid] alpha=1200 acc=0.6707 time=37.3s\n",
            "[cifar10_2d_ablation_best_valid] alpha=1400 acc=0.6710 time=37.9s\n",
            "[cifar10_2d_ablation_best_valid] alpha=1600 acc=0.6705 time=38.3s\n",
            "[cifar10_2d_ablation_best_valid] alpha=1800 acc=0.6715 time=37.8s\n",
            "[cifar10_2d_ablation_best_valid] alpha=2000 acc=0.6710 time=37.7s\n",
            "[cifar10_2d_ablation_best_valid] alpha=2200 acc=0.6710 time=37.4s\n",
            "[cifar10_2d_ablation_best_valid] alpha=2400 acc=0.6706 time=38.8s\n",
            "\n",
            "Saved: /content/rocket_2d_padding_check_cache/padding_check_results.csv\n",
            "dataset padding_2d                  features    acc  feature_dim\n",
            "cifar10     random ppv|max|mpv|mipv_y|mipv_x 0.6679        15120\n",
            "cifar10       same ppv|max|mpv|mipv_y|mipv_x 0.6699        15120\n",
            "cifar10      valid ppv|max|mpv|mipv_y|mipv_x 0.6715        15120\n",
            "  mnist     random ppv|max|mpv|mipv_y|mipv_x 0.9914        15120\n",
            "  mnist       same ppv|max|mpv|mipv_y|mipv_x 0.9920        15120\n",
            "  mnist      valid ppv|max|mpv|mipv_y|mipv_x 0.9919        13385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepoc Bank Ablation"
      ],
      "metadata": {
        "id": "d-5jbG1J2wDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preproc Bank Ablation\n",
        "Purpose: Compares pure RGB/Grey kernels with dataset wide norm, pure preproc kernels (per_image_norm), and mixtures.\n",
        "Important: PREPROC_MODE, PREPROC_CHANNELS, RUN_SPECS (n_rgb/n_preproc).\n",
        "Outputs: rgb_preproc_banks_3024_results.csv\n",
        "Note: PREPROC_SOBEL is implemented for future investigations, but not evaluated yet.\n",
        "\"\"\"\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from config import set_seed, set_deterministic, get_loaders, ALPHAS, SEED, DATASET_LIST as dataset_list, STRIDE_2D\n",
        "from utils.kernels import make_random_kernels_2d\n",
        "from utils.features import extract_features_2d\n",
        "from utils.preproc import preproc_output_channels\n",
        "from utils.settings import get_cache_dir\n",
        "from utils.constants import PREPROC_IMAGE_NORM, PREPROC_NONE\n",
        "\n",
        "set_seed(SEED); set_deterministic()\n",
        "\n",
        "# experiment-level spec (ENV-overrides ok)\n",
        "N_TOTAL = int(os.environ.get(\"N_TOTAL\", \"3024\"))\n",
        "N_PREPROC_ONLY = int(os.environ.get(\"N_PREPROC_ONLY\", str(N_TOTAL)))\n",
        "K_CHOICES_2D = list(map(int, os.environ.get(\"K_CHOICES_2D\", \"7,9,11\").split(\",\")))\n",
        "D_CHOICES_2D = list(map(int, os.environ.get(\"D_CHOICES_2D\", \"1,2,3\").split(\",\")))\n",
        "PADDING_MODE_2D = os.environ.get(\"PADDING_MODE_2D\", \"valid\").lower()\n",
        "PREPROC_MODE = os.environ.get(\"PREPROC_MODE\", PREPROC_IMAGE_NORM).lower()\n",
        "PREPROC_CHANNELS_ENV = os.environ.get(\"PREPROC_CHANNELS\", None)\n",
        "\n",
        "FEATURE_SET = \"ablation_best\"\n",
        "FEATURE_SETS = {\"ablation_best\": [\"ppv\",\"max\",\"mpv\",\"mipv_y\",\"mipv_x\"]}\n",
        "\n",
        "# Run specs: list of dicts specifying number of rgb and preproc kernels\n",
        "RUN_SPECS = [\n",
        "    {\"name\":\"preproc_only\",\"n_rgb\":0,\"n_preproc\":N_PREPROC_ONLY},\n",
        "    {\"name\":\"rgb_only\",\"n_rgb\":N_TOTAL,\"n_preproc\":0},\n",
        "    {\"name\":\"mixed_half\",\"n_rgb\":N_TOTAL//2,\"n_preproc\":N_TOTAL//2},\n",
        "]\n",
        "\n",
        "CACHE_DIR = get_cache_dir(\"rocket_2d_rgb_preproc_banks_3024_cache\")\n",
        "RESULTS_CSV = str(Path(CACHE_DIR).joinpath(\"rgb_preproc_banks_3024_results.csv\"))\n",
        "\n",
        "def run_spec(dataset_tag, train_loader, test_loader, in_channels_img, image_hw, spec, feature_set_key, padding_mode_2d):\n",
        "    ft = FEATURE_SETS[feature_set_key]\n",
        "    tag = f\"{dataset_tag}_2d_{feature_set_key}_{spec['name']}_{padding_mode_2d}_PRE{PREPROC_MODE}\"\n",
        "\n",
        "    preproc_channels_used = int(PREPROC_CHANNELS_ENV) if PREPROC_CHANNELS_ENV is not None else (1 if PREPROC_MODE == \"sobel\" else in_channels_img)\n",
        "\n",
        "    kernels_rgb     = make_random_kernels_2d(spec[\"n_rgb\"],     in_channels_img,      K_CHOICES_2D, D_CHOICES_2D, seed=SEED) if spec[\"n_rgb\"]>0 else None\n",
        "    kernels_preproc = make_random_kernels_2d(spec[\"n_preproc\"], preproc_channels_used, K_CHOICES_2D, D_CHOICES_2D, seed=SEED) if spec[\"n_preproc\"]>0 else None\n",
        "\n",
        "    X_train_parts=[]\n",
        "    X_test_parts=[]\n",
        "    y_train=y_test=None\n",
        "\n",
        "    if kernels_rgb is not None:\n",
        "        X_tr_rgb, y_tr = extract_features_2d(train_loader, kernels_rgb, ft, image_hw=image_hw, padding_mode=padding_mode_2d, stride=STRIDE_2D, seed=SEED)\n",
        "        X_te_rgb, y_te = extract_features_2d(test_loader,  kernels_rgb, ft, image_hw=image_hw, padding_mode=padding_mode_2d, stride=STRIDE_2D, seed=SEED)\n",
        "        X_train_parts.append(X_tr_rgb); X_test_parts.append(X_te_rgb); y_train=y_tr; y_test=y_te\n",
        "\n",
        "    if kernels_preproc is not None:\n",
        "        X_tr_p, y_tr2 = extract_features_2d(train_loader, kernels_preproc, ft, image_hw=image_hw, padding_mode=padding_mode_2d, stride=STRIDE_2D, seed=SEED, preproc_mode=PREPROC_MODE)\n",
        "        X_te_p, y_te2 = extract_features_2d(test_loader,  kernels_preproc, ft, image_hw=image_hw, padding_mode=padding_mode_2d, stride=STRIDE_2D, seed=SEED, preproc_mode=PREPROC_MODE)\n",
        "        X_train_parts.append(X_tr_p); X_test_parts.append(X_te_p)\n",
        "        if y_train is None: y_train = y_tr2\n",
        "        y_test = y_te2\n",
        "\n",
        "    if len(X_train_parts) == 0:\n",
        "        print(f\"[{tag}] No features -> skip\")\n",
        "        return {\"dataset\":dataset_tag,\"spec\":spec[\"name\"],\"feature_set\":feature_set_key,\"padding_2d\":padding_mode_2d,\"preproc_mode\":PREPROC_MODE,\"feature_dim\":0,\"acc\":float(\"nan\")}\n",
        "\n",
        "    X_train = np.concatenate(X_train_parts, axis=1)\n",
        "    X_test  = np.concatenate(X_test_parts, axis=1)\n",
        "    print(f\"[{tag}] X_train {X_train.shape} X_test {X_test.shape}\")\n",
        "\n",
        "    best_alpha, best_acc, best_time = None, -1.0, None\n",
        "    for alpha in ALPHAS:\n",
        "        from config import build_ridge\n",
        "        pipe = build_ridge(alpha=alpha, scale=True)\n",
        "        t0 = time.time(); pipe.fit(X_train, y_train); tt = time.time() - t0\n",
        "        y_pred = pipe.predict(X_test); acc = float((y_pred == y_test).mean())\n",
        "        print(f\"[{tag}] alpha={alpha} acc={acc:.4f} time={tt:.1f}s\")\n",
        "        if acc > best_acc:\n",
        "            best_alpha, best_acc, best_time = alpha, acc, tt\n",
        "\n",
        "    total_kernels = spec[\"n_rgb\"] + spec[\"n_preproc\"]\n",
        "    return {\n",
        "        \"dataset\":dataset_tag, \"spec\":spec[\"name\"], \"feature_set\":feature_set_key, \"padding_2d\":padding_mode_2d,\n",
        "        \"preproc_mode\":PREPROC_MODE, \"preproc_channels\":int(preproc_channels_used), \"features\":\"|\".join(ft),\n",
        "        \"feature_dim\":int(X_train.shape[1]), \"best_alpha\":int(best_alpha) if best_alpha else None, \"acc\":float(best_acc),\n",
        "        \"train_time\":float(best_time) if best_time else None, \"n_kernels_rgb\":int(spec[\"n_rgb\"]), \"n_kernels_preproc\":int(spec[\"n_preproc\"]),\n",
        "        \"n_kernels_total\":int(total_kernels), \"k_choices\":\"|\".join(map(str,K_CHOICES_2D)), \"d_choices\":\"|\".join(map(str,D_CHOICES_2D)),\n",
        "        \"stride_2d\":int(STRIDE_2D)\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    set_seed(SEED); set_deterministic()\n",
        "    rows=[]\n",
        "    for dataset_name in dataset_list:\n",
        "        train_loader, test_loader, in_channels_img, (H_img, W_img), _ = get_loaders(dataset_name, seed=SEED, quick_per_class=None)\n",
        "        print(f\"\\nDataset={dataset_name} in_channels={in_channels_img} HxW={H_img}x{W_img}\")\n",
        "        for spec in RUN_SPECS:\n",
        "            print(f\"Running spec={spec['name']} on {dataset_name}\")\n",
        "            rows.append(run_spec(dataset_name, train_loader, test_loader, in_channels_img, (H_img,W_img), spec, FEATURE_SET, PADDING_MODE_2D))\n",
        "    pd.DataFrame(rows).to_csv(RESULTS_CSV, index=False)\n",
        "    print(\"\\nSaved:\", RESULTS_CSV)\n",
        "    print(pd.DataFrame(rows).sort_values([\"dataset\",\"spec\",\"acc\"], ascending=[True,True,False]).to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "VYJDrmwQ2yK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "356318c2-16bd-456b-ae1c-baeaf417cc35"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset=mnist in_channels=1 HxW=28x28\n",
            "Running spec=preproc_only on mnist\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] X_train (60000, 13385) X_test (10000, 13385)\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1000 acc=0.9917 time=37.6s\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1200 acc=0.9913 time=37.5s\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1400 acc=0.9913 time=37.3s\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1600 acc=0.9913 time=37.1s\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1800 acc=0.9913 time=37.1s\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=2000 acc=0.9913 time=36.9s\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=2200 acc=0.9913 time=38.1s\n",
            "[mnist_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=2400 acc=0.9912 time=38.1s\n",
            "Running spec=rgb_only on mnist\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] X_train (60000, 13385) X_test (10000, 13385)\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1000 acc=0.9919 time=36.9s\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1200 acc=0.9917 time=37.2s\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1400 acc=0.9913 time=36.8s\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1600 acc=0.9911 time=37.4s\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1800 acc=0.9911 time=37.4s\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=2000 acc=0.9911 time=37.6s\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=2200 acc=0.9910 time=36.8s\n",
            "[mnist_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=2400 acc=0.9909 time=37.0s\n",
            "Running spec=mixed_half on mnist\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] X_train (60000, 13470) X_test (10000, 13470)\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1000 acc=0.9900 time=37.8s\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1200 acc=0.9900 time=37.2s\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1400 acc=0.9898 time=37.2s\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1600 acc=0.9898 time=37.0s\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1800 acc=0.9898 time=39.0s\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=2000 acc=0.9897 time=37.9s\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=2200 acc=0.9896 time=37.0s\n",
            "[mnist_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=2400 acc=0.9895 time=37.6s\n",
            "\n",
            "Dataset=cifar10 in_channels=3 HxW=32x32\n",
            "Running spec=preproc_only on cifar10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] X_train (50000, 15120) X_test (10000, 15120)\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1000 acc=0.6502 time=38.0s\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1200 acc=0.6516 time=37.3s\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1400 acc=0.6528 time=39.1s\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1600 acc=0.6525 time=44.7s\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=1800 acc=0.6524 time=37.5s\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=2000 acc=0.6531 time=39.1s\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=2200 acc=0.6526 time=37.6s\n",
            "[cifar10_2d_ablation_best_preproc_only_valid_PREper_image_norm] alpha=2400 acc=0.6521 time=37.6s\n",
            "Running spec=rgb_only on cifar10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] X_train (50000, 15120) X_test (10000, 15120)\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1000 acc=0.6687 time=38.3s\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1200 acc=0.6706 time=37.7s\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1400 acc=0.6710 time=37.5s\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1600 acc=0.6704 time=37.3s\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=1800 acc=0.6715 time=38.7s\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=2000 acc=0.6710 time=38.2s\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=2200 acc=0.6710 time=37.4s\n",
            "[cifar10_2d_ablation_best_rgb_only_valid_PREper_image_norm] alpha=2400 acc=0.6705 time=37.7s\n",
            "Running spec=mixed_half on cifar10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] X_train (50000, 15120) X_test (10000, 15120)\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1000 acc=0.6193 time=38.0s\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1200 acc=0.6208 time=38.1s\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1400 acc=0.6226 time=37.8s\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1600 acc=0.6230 time=37.3s\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=1800 acc=0.6233 time=38.9s\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=2000 acc=0.6227 time=37.6s\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=2200 acc=0.6225 time=37.8s\n",
            "[cifar10_2d_ablation_best_mixed_half_valid_PREper_image_norm] alpha=2400 acc=0.6222 time=38.1s\n",
            "\n",
            "Saved: /content/rocket_2d_rgb_preproc_banks_3024_cache/rgb_preproc_banks_3024_results.csv\n",
            "dataset         spec   feature_set padding_2d   preproc_mode  preproc_channels                  features  feature_dim  best_alpha    acc  train_time  n_kernels_rgb  n_kernels_preproc  n_kernels_total k_choices d_choices  stride_2d\n",
            "cifar10   mixed_half ablation_best      valid per_image_norm                 3 ppv|max|mpv|mipv_y|mipv_x        15120        1800 0.6233   38.931529           1512               1512             3024    7|9|11     1|2|3          1\n",
            "cifar10 preproc_only ablation_best      valid per_image_norm                 3 ppv|max|mpv|mipv_y|mipv_x        15120        2000 0.6531   39.084631              0               3024             3024    7|9|11     1|2|3          1\n",
            "cifar10     rgb_only ablation_best      valid per_image_norm                 3 ppv|max|mpv|mipv_y|mipv_x        15120        1800 0.6715   38.671321           3024                  0             3024    7|9|11     1|2|3          1\n",
            "  mnist   mixed_half ablation_best      valid per_image_norm                 1 ppv|max|mpv|mipv_y|mipv_x        13470        1000 0.9900   37.780781           1512               1512             3024    7|9|11     1|2|3          1\n",
            "  mnist preproc_only ablation_best      valid per_image_norm                 1 ppv|max|mpv|mipv_y|mipv_x        13385        1000 0.9917   37.632939              0               3024             3024    7|9|11     1|2|3          1\n",
            "  mnist     rgb_only ablation_best      valid per_image_norm                 1 ppv|max|mpv|mipv_y|mipv_x        13385        1000 0.9919   36.884400           3024                  0             3024    7|9|11     1|2|3          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kernel Configuration Ablation"
      ],
      "metadata": {
        "id": "Q9HXfdvx201_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Kernel Configuration & Count Ablation\n",
        "Purpose: Search for robust K/D configurations (Phase 1) and investigate scalability with N_KERNELS (Phase 2).\n",
        "Important: PHASE_1_CONFIGS, PHASE_2_N_KERNELS, RUN_PHASE_1/2 flags.\n",
        "Outputs: kernel_ablation_results.csv\n",
        "\"\"\"\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from config import set_seed, set_deterministic, get_loaders, ALPHAS, SEED, STRIDE_2D, DATASET_LIST as dataset_list\n",
        "from utils.kernels import make_random_kernels_2d\n",
        "from utils.features import extract_features_2d\n",
        "from utils.settings import get_cache_dir\n",
        "\n",
        "set_seed(SEED); set_deterministic()\n",
        "\n",
        "CACHE_DIR = get_cache_dir(\"rocket_kernel_ablation_cache\")\n",
        "RESULTS_CSV = str(Path(CACHE_DIR).joinpath(\"kernel_ablation_results.csv\"))\n",
        "\n",
        "# configs for phase 1 (experiment-level)\n",
        "FEATURE_TYPES = [\"ppv\",\"max\",\"mpv\",\"mipv_y\",\"mipv_x\"]\n",
        "PHASE_1_N_KERNELS = int(os.environ.get(\"PHASE_1_N_KERNELS\", \"3024\"))\n",
        "PHASE_1_CONFIGS = [\n",
        "    {\"name\":\"original_rocket\",\"k_choices\":[7,9,11],\"d_choices\":[1],\"description\":\"original rocket\"},\n",
        "    {\"name\":\"original_rocket_dilated\",\"k_choices\":[7,9,11],\"d_choices\":[1,2,4],\"description\":\"rocket dilated\"},\n",
        "    {\"name\":\"small_dilated\",\"k_choices\":[1,3,5],\"d_choices\":[1,2,3,4],\"description\":\"small dilated\"},\n",
        "    {\"name\":\"wide_dilated\",\"k_choices\":[1,3,7,12],\"d_choices\":[1,2,3],\"description\":\"wide dilated\"},\n",
        "    {\"name\":\"mixed_moderate\",\"k_choices\":[3,5,7,9],\"d_choices\":[1,2],\"description\":\"mixed moderate\"},\n",
        "]\n",
        "PHASE_2_N_KERNELS = list(map(int, os.environ.get(\"PHASE_2_N_KERNELS\", \"1000,2000,3024,5000,7000\").split(\",\")))\n",
        "RUN_PHASE_1 = os.environ.get(\"RUN_PHASE_1\", \"1\").lower() in (\"1\",\"true\",\"yes\")\n",
        "RUN_PHASE_2 = os.environ.get(\"RUN_PHASE_2\", \"1\").lower() in (\"1\",\"true\",\"yes\")\n",
        "PHASE_2_CONFIG_NAME = os.environ.get(\"PHASE_2_CONFIG\", None)\n",
        "\n",
        "def run_single_experiment(dataset_tag, train_loader, test_loader, n_kernels, kernel_config, phase, image_hw, preproc_channels):\n",
        "    cfg_name = kernel_config[\"name\"]; k_choices = kernel_config[\"k_choices\"]; d_choices = kernel_config[\"d_choices\"]\n",
        "    print(f\"\\n[{phase}] dataset={dataset_tag} N_KERNELS={n_kernels} config={cfg_name} K={k_choices} D={d_choices}\")\n",
        "    kernels = make_random_kernels_2d(n_kernels, preproc_channels, k_choices, d_choices, seed=SEED)\n",
        "\n",
        "    t0 = time.time()\n",
        "    #preproc mode noch anpassen\n",
        "    X_train, y_train = extract_features_2d(train_loader, kernels, FEATURE_TYPES, image_hw=image_hw, padding_mode=os.environ.get(\"PADDING_MODE_2D\",\"valid\"), stride=STRIDE_2D, seed=SEED)\n",
        "    X_test,  y_test  = extract_features_2d(test_loader,  kernels, FEATURE_TYPES, image_hw=image_hw, padding_mode=os.environ.get(\"PADDING_MODE_2D\",\"valid\"), stride=STRIDE_2D, seed=SEED)\n",
        "    print(\"extraction time:\", time.time()-t0, \"shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "    if X_train.shape[1] == 0:\n",
        "        print(\"No features -> skip\"); return []\n",
        "\n",
        "    results = []\n",
        "    for alpha in ALPHAS:\n",
        "        from config import build_ridge\n",
        "        pipe = build_ridge(alpha=alpha, scale=True)\n",
        "        t0 = time.time(); pipe.fit(X_train, y_train); train_time = time.time() - t0\n",
        "        y_pred = pipe.predict(X_test); acc = float((y_pred == y_test).mean())\n",
        "        print(f\"alpha={alpha} acc={acc:.4f} train_time={train_time:.1f}s\")\n",
        "        results.append({\n",
        "            \"phase\": phase, \"dataset\": dataset_tag, \"n_kernels\": int(n_kernels), \"config_name\": cfg_name,\n",
        "            \"k_choices\": \"|\".join(map(str,k_choices)), \"d_choices\":\"|\".join(map(str,d_choices)),\n",
        "            \"feature_dim\": int(X_train.shape[1]), \"accuracy\": float(acc), \"train_time\": float(train_time), \"alpha\": int(alpha),\n",
        "            \"features\": \"|\".join(FEATURE_TYPES)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    set_seed(SEED)\n",
        "    set_deterministic()\n",
        "    all_results = []\n",
        "    for dataset_name in dataset_list:\n",
        "        train_loader, test_loader, in_channels, (H_img, W_img), _ = get_loaders(dataset_name, seed=SEED, quick_per_class=None)\n",
        "        preproc_channels = in_channels\n",
        "        if RUN_PHASE_1:\n",
        "            phase1_results = []\n",
        "            for cfg in PHASE_1_CONFIGS:\n",
        "                try:\n",
        "                    res = run_single_experiment(dataset_name, train_loader, test_loader, PHASE_1_N_KERNELS, cfg, \"Phase1\", (H_img,W_img), preproc_channels)\n",
        "                    all_results.extend(res); phase1_results.extend(res)\n",
        "                    pd.DataFrame(all_results).to_csv(RESULTS_CSV, index=False)\n",
        "                except Exception as e:\n",
        "                    print(\"failed:\", e); import traceback; traceback.print_exc(); continue\n",
        "            if len(phase1_results) == 0:\n",
        "                print(\"ERROR: Phase1 no valid results\"); return\n",
        "            df_p1 = pd.DataFrame(phase1_results).sort_values(\"accuracy\", ascending=False)\n",
        "            best_cfg = df_p1.iloc[0][\"config_name\"]\n",
        "            selected_cfg_name = best_cfg if PHASE_2_CONFIG_NAME is None else PHASE_2_CONFIG_NAME\n",
        "            selected_cfg = next(c for c in PHASE_1_CONFIGS if c[\"name\"] == selected_cfg_name)\n",
        "        else:\n",
        "            if PHASE_2_CONFIG_NAME is None:\n",
        "                print(\"ERROR: set PHASE_2_CONFIG\"); return\n",
        "            selected_cfg = next(c for c in PHASE_1_CONFIGS if c[\"name\"] == PHASE_2_CONFIG_NAME)\n",
        "\n",
        "        if RUN_PHASE_2:\n",
        "            for n_k in PHASE_2_N_KERNELS:\n",
        "                try:\n",
        "                    res = run_single_experiment(dataset_name, train_loader, test_loader, n_k, selected_cfg, \"Phase2\", (H_img,W_img), preproc_channels)\n",
        "                    all_results.extend(res); pd.DataFrame(all_results).to_csv(RESULTS_CSV, index=False)\n",
        "                except Exception as e:\n",
        "                    print(\"failed:\", e); import traceback; traceback.print_exc(); continue\n",
        "\n",
        "    pd.DataFrame(all_results).to_csv(RESULTS_CSV, index=False)\n",
        "    print(\"Saved:\", RESULTS_CSV)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "RcNXANix23Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994f13c0-ef96-4b75-d2b9-92ca6ac2c224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Phase1] dataset=mnist N_KERNELS=3024 config=original_rocket K=[7, 9, 11] D=[1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 11.220944166183472 shapes: (60000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.9926 train_time=44.7s\n",
            "alpha=1200 acc=0.9926 train_time=44.5s\n",
            "alpha=1400 acc=0.9926 train_time=44.1s\n",
            "alpha=1600 acc=0.9927 train_time=43.9s\n",
            "alpha=1800 acc=0.9927 train_time=44.9s\n",
            "alpha=2000 acc=0.9927 train_time=44.3s\n",
            "alpha=2200 acc=0.9926 train_time=43.2s\n",
            "alpha=2400 acc=0.9926 train_time=45.3s\n",
            "\n",
            "[Phase1] dataset=mnist N_KERNELS=3024 config=original_rocket_dilated K=[7, 9, 11] D=[1, 2, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 10.203556060791016 shapes: (60000, 11545) (10000, 11545)\n",
            "alpha=1000 acc=0.9916 train_time=33.9s\n",
            "alpha=1200 acc=0.9914 train_time=33.7s\n",
            "alpha=1400 acc=0.9914 train_time=33.4s\n",
            "alpha=1600 acc=0.9914 train_time=33.8s\n",
            "alpha=1800 acc=0.9914 train_time=33.5s\n",
            "alpha=2000 acc=0.9916 train_time=35.4s\n",
            "alpha=2200 acc=0.9916 train_time=33.5s\n",
            "alpha=2400 acc=0.9915 train_time=33.8s\n",
            "\n",
            "[Phase1] dataset=mnist N_KERNELS=3024 config=small_dilated K=[1, 3, 5] D=[1, 2, 3, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 12.84687614440918 shapes: (60000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.9920 train_time=43.8s\n",
            "alpha=1200 acc=0.9918 train_time=44.8s\n",
            "alpha=1400 acc=0.9918 train_time=44.2s\n",
            "alpha=1600 acc=0.9917 train_time=44.2s\n",
            "alpha=1800 acc=0.9917 train_time=45.0s\n",
            "alpha=2000 acc=0.9917 train_time=44.6s\n",
            "alpha=2200 acc=0.9918 train_time=43.8s\n",
            "alpha=2400 acc=0.9917 train_time=45.1s\n",
            "\n",
            "[Phase1] dataset=mnist N_KERNELS=3024 config=wide_dilated K=[1, 3, 7, 12] D=[1, 2, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 11.005111455917358 shapes: (60000, 13790) (10000, 13790)\n",
            "alpha=1000 acc=0.9913 train_time=38.6s\n",
            "alpha=1200 acc=0.9913 train_time=39.6s\n",
            "alpha=1400 acc=0.9913 train_time=38.6s\n",
            "alpha=1600 acc=0.9912 train_time=39.9s\n",
            "alpha=1800 acc=0.9912 train_time=38.6s\n",
            "alpha=2000 acc=0.9909 train_time=38.9s\n",
            "alpha=2200 acc=0.9910 train_time=38.9s\n",
            "alpha=2400 acc=0.9910 train_time=38.4s\n",
            "\n",
            "[Phase1] dataset=mnist N_KERNELS=3024 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 11.178226470947266 shapes: (60000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.9934 train_time=44.2s\n",
            "alpha=1200 acc=0.9932 train_time=44.9s\n",
            "alpha=1400 acc=0.9930 train_time=44.4s\n",
            "alpha=1600 acc=0.9931 train_time=44.2s\n",
            "alpha=1800 acc=0.9931 train_time=44.9s\n",
            "alpha=2000 acc=0.9931 train_time=44.6s\n",
            "alpha=2200 acc=0.9930 train_time=44.0s\n",
            "alpha=2400 acc=0.9929 train_time=45.0s\n",
            "\n",
            "[Phase2] dataset=mnist N_KERNELS=1000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 9.560847282409668 shapes: (60000, 5000) (10000, 5000)\n",
            "alpha=1000 acc=0.9899 train_time=10.0s\n",
            "alpha=1200 acc=0.9899 train_time=9.8s\n",
            "alpha=1400 acc=0.9898 train_time=9.8s\n",
            "alpha=1600 acc=0.9896 train_time=9.8s\n",
            "alpha=1800 acc=0.9897 train_time=9.8s\n",
            "alpha=2000 acc=0.9895 train_time=10.1s\n",
            "alpha=2200 acc=0.9892 train_time=10.7s\n",
            "alpha=2400 acc=0.9892 train_time=10.4s\n",
            "\n",
            "[Phase2] dataset=mnist N_KERNELS=2000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 10.082068920135498 shapes: (60000, 10000) (10000, 10000)\n",
            "alpha=1000 acc=0.9931 train_time=23.5s\n",
            "alpha=1200 acc=0.9930 train_time=23.5s\n",
            "alpha=1400 acc=0.9929 train_time=23.3s\n",
            "alpha=1600 acc=0.9927 train_time=23.4s\n",
            "alpha=1800 acc=0.9926 train_time=24.5s\n",
            "alpha=2000 acc=0.9924 train_time=23.8s\n",
            "alpha=2200 acc=0.9924 train_time=23.7s\n",
            "alpha=2400 acc=0.9923 train_time=23.8s\n",
            "\n",
            "[Phase2] dataset=mnist N_KERNELS=3024 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 11.450764179229736 shapes: (60000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.9934 train_time=44.4s\n",
            "alpha=1200 acc=0.9932 train_time=43.9s\n",
            "alpha=1400 acc=0.9930 train_time=44.9s\n",
            "alpha=1600 acc=0.9931 train_time=44.5s\n",
            "alpha=1800 acc=0.9931 train_time=43.9s\n",
            "alpha=2000 acc=0.9931 train_time=45.2s\n",
            "alpha=2200 acc=0.9930 train_time=44.2s\n",
            "alpha=2400 acc=0.9929 train_time=43.6s\n",
            "\n",
            "[Phase2] dataset=mnist N_KERNELS=5000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 17.293052434921265 shapes: (60000, 25000) (10000, 25000)\n",
            "alpha=1000 acc=0.9940 train_time=103.1s\n",
            "alpha=1200 acc=0.9941 train_time=102.9s\n",
            "alpha=1400 acc=0.9940 train_time=102.5s\n",
            "alpha=1600 acc=0.9941 train_time=102.4s\n",
            "alpha=1800 acc=0.9940 train_time=103.4s\n",
            "alpha=2000 acc=0.9938 train_time=103.2s\n",
            "alpha=2200 acc=0.9938 train_time=102.2s\n",
            "alpha=2400 acc=0.9937 train_time=102.6s\n",
            "\n",
            "[Phase2] dataset=mnist N_KERNELS=7000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 23.618408203125 shapes: (60000, 35000) (10000, 35000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=3.66507e-08): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha=1000 acc=0.9951 train_time=198.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=4.75309e-08): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha=1200 acc=0.9951 train_time=186.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=5.70363e-08): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha=1400 acc=0.9948 train_time=186.7s\n",
            "alpha=1600 acc=0.9947 train_time=187.0s\n",
            "alpha=1800 acc=0.9947 train_time=187.5s\n",
            "alpha=2000 acc=0.9947 train_time=188.1s\n",
            "alpha=2200 acc=0.9947 train_time=187.7s\n",
            "alpha=2400 acc=0.9946 train_time=188.5s\n",
            "\n",
            "[Phase1] dataset=cifar10 N_KERNELS=3024 config=original_rocket K=[7, 9, 11] D=[1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 13.293541193008423 shapes: (50000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.6981 train_time=42.1s\n",
            "alpha=1200 acc=0.6990 train_time=37.3s\n",
            "alpha=1400 acc=0.6991 train_time=37.9s\n",
            "alpha=1600 acc=0.6986 train_time=38.1s\n",
            "alpha=1800 acc=0.6977 train_time=37.9s\n",
            "alpha=2000 acc=0.6972 train_time=37.8s\n",
            "alpha=2200 acc=0.6977 train_time=37.2s\n",
            "alpha=2400 acc=0.6983 train_time=37.3s\n",
            "\n",
            "[Phase1] dataset=cifar10 N_KERNELS=3024 config=original_rocket_dilated K=[7, 9, 11] D=[1, 2, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 10.3573157787323 shapes: (50000, 11835) (10000, 11835)\n",
            "alpha=1000 acc=0.6717 train_time=27.5s\n",
            "alpha=1200 acc=0.6735 train_time=26.6s\n",
            "alpha=1400 acc=0.6743 train_time=26.4s\n",
            "alpha=1600 acc=0.6750 train_time=26.3s\n",
            "alpha=1800 acc=0.6746 train_time=27.9s\n",
            "alpha=2000 acc=0.6730 train_time=26.3s\n",
            "alpha=2200 acc=0.6733 train_time=26.6s\n",
            "alpha=2400 acc=0.6734 train_time=27.3s\n",
            "\n",
            "[Phase1] dataset=cifar10 N_KERNELS=3024 config=small_dilated K=[1, 3, 5] D=[1, 2, 3, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 13.960407733917236 shapes: (50000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.7018 train_time=38.8s\n",
            "alpha=1200 acc=0.7026 train_time=37.5s\n",
            "alpha=1400 acc=0.7027 train_time=37.6s\n",
            "alpha=1600 acc=0.7025 train_time=41.7s\n",
            "alpha=1800 acc=0.7012 train_time=39.0s\n",
            "alpha=2000 acc=0.6997 train_time=42.4s\n",
            "alpha=2200 acc=0.7000 train_time=39.7s\n",
            "alpha=2400 acc=0.7003 train_time=39.0s\n",
            "\n",
            "[Phase1] dataset=cifar10 N_KERNELS=3024 config=wide_dilated K=[1, 3, 7, 12] D=[1, 2, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 12.454806089401245 shapes: (50000, 13705) (10000, 13705)\n",
            "alpha=1000 acc=0.6971 train_time=33.5s\n",
            "alpha=1200 acc=0.6967 train_time=32.8s\n",
            "alpha=1400 acc=0.6964 train_time=33.1s\n",
            "alpha=1600 acc=0.6966 train_time=33.2s\n",
            "alpha=1800 acc=0.6982 train_time=34.0s\n",
            "alpha=2000 acc=0.6989 train_time=32.9s\n",
            "alpha=2200 acc=0.6987 train_time=33.0s\n",
            "alpha=2400 acc=0.6976 train_time=33.0s\n",
            "\n",
            "[Phase1] dataset=cifar10 N_KERNELS=3024 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 12.746634721755981 shapes: (50000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.7189 train_time=38.3s\n",
            "alpha=1200 acc=0.7177 train_time=38.0s\n",
            "alpha=1400 acc=0.7175 train_time=37.5s\n",
            "alpha=1600 acc=0.7164 train_time=37.6s\n",
            "alpha=1800 acc=0.7159 train_time=38.7s\n",
            "alpha=2000 acc=0.7154 train_time=37.6s\n",
            "alpha=2200 acc=0.7153 train_time=37.8s\n",
            "alpha=2400 acc=0.7156 train_time=38.1s\n",
            "\n",
            "[Phase2] dataset=cifar10 N_KERNELS=1000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 9.765497922897339 shapes: (50000, 5000) (10000, 5000)\n",
            "alpha=1000 acc=0.6683 train_time=9.3s\n",
            "alpha=1200 acc=0.6672 train_time=8.4s\n",
            "alpha=1400 acc=0.6664 train_time=8.4s\n",
            "alpha=1600 acc=0.6652 train_time=8.4s\n",
            "alpha=1800 acc=0.6634 train_time=9.2s\n",
            "alpha=2000 acc=0.6630 train_time=8.3s\n",
            "alpha=2200 acc=0.6628 train_time=8.3s\n",
            "alpha=2400 acc=0.6622 train_time=8.4s\n",
            "\n",
            "[Phase2] dataset=cifar10 N_KERNELS=2000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 10.534636497497559 shapes: (50000, 10000) (10000, 10000)\n",
            "alpha=1000 acc=0.7011 train_time=20.9s\n",
            "alpha=1200 acc=0.7000 train_time=20.0s\n",
            "alpha=1400 acc=0.6997 train_time=20.5s\n",
            "alpha=1600 acc=0.6992 train_time=20.5s\n",
            "alpha=1800 acc=0.6989 train_time=19.5s\n",
            "alpha=2000 acc=0.6984 train_time=20.5s\n",
            "alpha=2200 acc=0.6978 train_time=20.6s\n",
            "alpha=2400 acc=0.6968 train_time=20.4s\n",
            "\n",
            "[Phase2] dataset=cifar10 N_KERNELS=3024 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 12.669709205627441 shapes: (50000, 15120) (10000, 15120)\n",
            "alpha=1000 acc=0.7189 train_time=37.2s\n",
            "alpha=1200 acc=0.7177 train_time=37.9s\n",
            "alpha=1400 acc=0.7175 train_time=37.9s\n",
            "alpha=1600 acc=0.7164 train_time=38.0s\n",
            "alpha=1800 acc=0.7159 train_time=37.5s\n",
            "alpha=2000 acc=0.7154 train_time=37.5s\n",
            "alpha=2200 acc=0.7153 train_time=39.1s\n",
            "alpha=2400 acc=0.7156 train_time=38.2s\n",
            "\n",
            "[Phase2] dataset=cifar10 N_KERNELS=5000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 19.61394190788269 shapes: (50000, 25000) (10000, 25000)\n",
            "alpha=1000 acc=0.7295 train_time=88.5s\n",
            "alpha=1200 acc=0.7318 train_time=89.1s\n",
            "alpha=1400 acc=0.7324 train_time=88.6s\n",
            "alpha=1600 acc=0.7327 train_time=89.2s\n",
            "alpha=1800 acc=0.7323 train_time=88.7s\n",
            "alpha=2000 acc=0.7328 train_time=88.1s\n",
            "alpha=2200 acc=0.7340 train_time=89.2s\n",
            "alpha=2400 acc=0.7342 train_time=89.2s\n",
            "\n",
            "[Phase2] dataset=cifar10 N_KERNELS=7000 config=mixed_moderate K=[3, 5, 7, 9] D=[1, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraction time: 27.02815818786621 shapes: (50000, 35000) (10000, 35000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=5.72781e-08): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha=1000 acc=0.7253 train_time=177.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=5.81549e-08): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha=1200 acc=0.7284 train_time=171.0s\n",
            "alpha=1400 acc=0.7308 train_time=170.7s\n",
            "alpha=1600 acc=0.7330 train_time=165.1s\n",
            "alpha=1800 acc=0.7344 train_time=164.6s\n",
            "alpha=2000 acc=0.7350 train_time=164.7s\n",
            "alpha=2200 acc=0.7363 train_time=164.6s\n",
            "alpha=2400 acc=0.7372 train_time=164.3s\n",
            "Saved: /content/rocket_kernel_ablation_cache/kernel_ablation_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Pipeline"
      ],
      "metadata": {
        "id": "39FDKD4GzdBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Pipeline**\n",
        "\n",
        "This script performs the final ROCKET runs (N_KERNELS_FINAL, feature extraction, Ridge sweep).\n",
        "Important: The script saves kernel_hash + seed + Config snapshot alongside the results for reproducibility.\n",
        "\n",
        "**Final Pipeline — Settings and Origin**\n",
        "\n",
        "The settings used in this final pipeline were selected based on the previous ablation studies (feature ablation, kernel dimension, padding, preprocessing and kernel configuration ablations).\n",
        "\n",
        "Current pipeline core settings (default/values used)\n",
        "- Number of kernels: N_KERNELS_FINAL = 5000 (can be overwritten via ENV `N_KERNELS_FINAL`)  \n",
        "- Kernel configuration (per dataset): BEST_CONFIGS:\n",
        "  - cifar10 / mnist: config = “mixed_moderate” with k_choices = [3, 5, 7, 9], d_choices = [1, 2]\n",
        "- Feature types: FEATURE_TYPES = FEATURE_TYPES_2D (`[“ppv”,“max”,“mpv”,“mipv_y”,‘mipv_x’]`)  \n",
        "- Padding: `padding_mode=“valid”`\n",
        "- Stride: STRIDE_2D (default: 1)  \n",
        "- Alpha grid (ridge): ALPHAS (default grid from config -> [1000,1200,...,2400])\n",
        "- Reproducibility: seed = SEED (from config), as well as set_seed(SEED) and set_deterministic() are used; CUBLAS_WORKSPACE_CONFIG must be set before CUDA init if deterministic cuBLAS is required.\n",
        "- Output / artifacts: Features and results are stored in CACHE_DIR (`/content/rocket_final_cache` by default)."
      ],
      "metadata": {
        "id": "5wyOVfuEUjdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final Pipeline\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from config import get_alphas, get_loaders, ALPHAS, SEED, STRIDE_2D, DATASET_LIST as dataset_list\n",
        "from utils.kernels import make_random_kernels_2d, count_kernels, kernel_hash\n",
        "from utils.features import extract_features_2d\n",
        "from utils.eval import per_class_accuracy\n",
        "from utils.sanity import estimate_feature_bytes\n",
        "from utils.settings import get_cache_dir\n",
        "from utils.constants import FEATURE_TYPES_2D as FEATURE_TYPES, PREPROC_IMAGE_NORM\n",
        "\n",
        "# experiment-level defaults\n",
        "N_KERNELS_FINAL = int(os.environ.get(\"N_KERNELS_FINAL\", \"5000\"))\n",
        "BEST_CONFIGS = {\n",
        "    \"cifar10\": {\"name\":\"mixed_moderate\",\"k_choices\":[3,5,7,9],\"d_choices\":[1,2],\"description\":\"mixed moderate\"},\n",
        "    \"mnist\":   {\"name\":\"mixed_moderate\",\"k_choices\":[3,5,7,9],\"d_choices\":[1,2],\"description\":\"mixed moderate\"}\n",
        "}\n",
        "BEST_CONFIG_FALLBACK = {\"name\":\"current_best\",\"k_choices\":[3,5,7,9],\"d_choices\":[1,2],\"description\":\"fallback\"}\n",
        "\n",
        "CACHE_DIR = get_cache_dir(\"rocket_final_cache\")\n",
        "RESULTS_CSV = str(Path(CACHE_DIR).joinpath(\"final_kernel_results.csv\"))\n",
        "\n",
        "def run(dataset_name):\n",
        "    train_loader, test_loader, in_channels, (H_img, W_img), seq_len = get_loaders(dataset_name, seed=SEED)\n",
        "    cfg = BEST_CONFIGS.get(dataset_name, BEST_CONFIG_FALLBACK)\n",
        "\n",
        "    print(f\"Dataset={dataset_name} N_KERNELS={N_KERNELS_FINAL} config={cfg['name']}\")\n",
        "\n",
        "    kernels = make_random_kernels_2d(\n",
        "        N_KERNELS_FINAL, in_channels,\n",
        "        cfg[\"k_choices\"], cfg[\"d_choices\"],\n",
        "        seed=SEED\n",
        "    )\n",
        "\n",
        "    print(\"kernel hash:\", kernel_hash(kernels), \"count:\", count_kernels(kernels))\n",
        "\n",
        "    X_train, y_train = extract_features_2d(\n",
        "        train_loader, kernels, FEATURE_TYPES,\n",
        "        (H_img, W_img),\n",
        "        padding_mode=\"valid\",\n",
        "        stride=STRIDE_2D,\n",
        "        seed=SEED\n",
        "    )\n",
        "\n",
        "    X_test, y_test = extract_features_2d(\n",
        "        test_loader, kernels, FEATURE_TYPES,\n",
        "        (H_img, W_img),\n",
        "        padding_mode=\"valid\",\n",
        "        stride=STRIDE_2D,\n",
        "        seed=SEED\n",
        "    )\n",
        "\n",
        "    print(f\"Features: train={X_train.shape} test={X_test.shape}\")\n",
        "\n",
        "    if X_train.shape[1] == 0:\n",
        "        print(\"No features -> skip\")\n",
        "        return []\n",
        "\n",
        "    print(\n",
        "        \"Estimated feature size (GiB):\",\n",
        "        estimate_feature_bytes(len(train_loader.dataset), X_train.shape[1]) / (1024**3)\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for alpha in ALPHAS:\n",
        "        from config import build_ridge\n",
        "        from sklearn.metrics import accuracy_score\n",
        "\n",
        "        pipe = build_ridge(alpha=alpha, scale=True)\n",
        "\n",
        "        t0 = time.time()\n",
        "        pipe.fit(X_train, y_train)\n",
        "        tt = time.time() - t0\n",
        "\n",
        "        ypred = pipe.predict(X_test)\n",
        "        acc = accuracy_score(y_test, ypred)\n",
        "\n",
        "        per_class_acc = per_class_accuracy(y_test, ypred)\n",
        "\n",
        "        print(f\"[{dataset_name}] ridge alpha={alpha} acc={acc:.4f} time={tt:.1f}s\")\n",
        "        print(\"Per-class acc:\", per_class_acc)\n",
        "\n",
        "        results.append({\n",
        "            \"dataset\": dataset_name,\n",
        "            \"classifier\": \"ridge\",\n",
        "            \"alpha\": alpha,\n",
        "            \"acc\": acc,\n",
        "            \"train_time\": tt,\n",
        "            \"feature_dim\": X_train.shape[1],\n",
        "            \"n_kernels\": N_KERNELS_FINAL,\n",
        "            \"per_class_acc\": per_class_acc\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "def main():\n",
        "    all_results = []\n",
        "    for ds in dataset_list:\n",
        "        try:\n",
        "            res = run(ds)\n",
        "            all_results.extend(res)\n",
        "        except Exception as e:\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            print(\"Failed\", e)\n",
        "\n",
        "    pd.DataFrame(all_results).to_csv(RESULTS_CSV, index=False)\n",
        "    print(\"Saved:\", RESULTS_CSV)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "sAc7TZj-zZ9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c277c2-0d56-43cd-ce8e-c333d1bbd9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset=mnist N_KERNELS=5000 config=mixed_moderate\n",
            "kernel hash: bce6afe94f6fc60da8617ccf777c3e5f count: 5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: train=(60000, 25000) test=(10000, 25000)\n",
            "Estimated feature size (GiB): 5.587935447692871\n",
            "[mnist] ridge alpha=1000 acc=0.9940 time=103.9s\n",
            "Per-class acc: {'0': 0.9979591836734694, '1': 0.9982378854625551, '2': 0.9951550387596899, '3': 0.9930693069306931, '4': 0.994908350305499, '5': 0.9943946188340808, '6': 0.9916492693110647, '7': 0.9931906614785992, '8': 0.9948665297741273, '9': 0.9861248761149654}\n",
            "[mnist] ridge alpha=1200 acc=0.9941 time=103.9s\n",
            "Per-class acc: {'0': 0.9979591836734694, '1': 0.9982378854625551, '2': 0.9951550387596899, '3': 0.9930693069306931, '4': 0.994908350305499, '5': 0.9943946188340808, '6': 0.9916492693110647, '7': 0.9941634241245136, '8': 0.9948665297741273, '9': 0.9861248761149654}\n",
            "[mnist] ridge alpha=1400 acc=0.9940 time=104.1s\n",
            "Per-class acc: {'0': 0.9979591836734694, '1': 0.9982378854625551, '2': 0.9951550387596899, '3': 0.9930693069306931, '4': 0.994908350305499, '5': 0.9932735426008968, '6': 0.9916492693110647, '7': 0.9941634241245136, '8': 0.9948665297741273, '9': 0.9861248761149654}\n",
            "[mnist] ridge alpha=1600 acc=0.9940 time=121.3s\n",
            "Per-class acc: {'0': 0.9979591836734694, '1': 0.9982378854625551, '2': 0.9951550387596899, '3': 0.9930693069306931, '4': 0.9959266802443992, '5': 0.9932735426008968, '6': 0.9906054279749478, '7': 0.9941634241245136, '8': 0.9948665297741273, '9': 0.9861248761149654}\n",
            "[mnist] ridge alpha=1800 acc=0.9940 time=124.7s\n",
            "Per-class acc: {'0': 0.996938775510204, '1': 0.9982378854625551, '2': 0.9951550387596899, '3': 0.9930693069306931, '4': 0.9959266802443992, '5': 0.9932735426008968, '6': 0.9906054279749478, '7': 0.9941634241245136, '8': 0.9958932238193019, '9': 0.9861248761149654}\n",
            "[mnist] ridge alpha=2000 acc=0.9938 time=120.0s\n",
            "Per-class acc: {'0': 0.996938775510204, '1': 0.9982378854625551, '2': 0.9951550387596899, '3': 0.9920792079207921, '4': 0.994908350305499, '5': 0.9932735426008968, '6': 0.9906054279749478, '7': 0.9941634241245136, '8': 0.9958932238193019, '9': 0.9861248761149654}\n",
            "[mnist] ridge alpha=2200 acc=0.9938 time=104.3s\n",
            "Per-class acc: {'0': 0.996938775510204, '1': 0.9982378854625551, '2': 0.9951550387596899, '3': 0.9920792079207921, '4': 0.994908350305499, '5': 0.9932735426008968, '6': 0.9906054279749478, '7': 0.9941634241245136, '8': 0.9958932238193019, '9': 0.9861248761149654}\n",
            "[mnist] ridge alpha=2400 acc=0.9937 time=104.7s\n",
            "Per-class acc: {'0': 0.996938775510204, '1': 0.9982378854625551, '2': 0.9961240310077519, '3': 0.9920792079207921, '4': 0.9928716904276986, '5': 0.9932735426008968, '6': 0.9906054279749478, '7': 0.9941634241245136, '8': 0.9958932238193019, '9': 0.9861248761149654}\n",
            "Dataset=cifar10 N_KERNELS=5000 config=mixed_moderate\n",
            "kernel hash: 88ad1c5a88dbd9fc3faadcaaa42ee03b count: 5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: train=(50000, 25000) test=(10000, 25000)\n",
            "Estimated feature size (GiB): 4.656612873077393\n",
            "[cifar10] ridge alpha=1000 acc=0.7295 time=90.0s\n",
            "Per-class acc: {'0': 0.736, '1': 0.847, '2': 0.606, '3': 0.528, '4': 0.626, '5': 0.642, '6': 0.832, '7': 0.786, '8': 0.842, '9': 0.85}\n",
            "[cifar10] ridge alpha=1200 acc=0.7319 time=106.3s\n",
            "Per-class acc: {'0': 0.735, '1': 0.851, '2': 0.61, '3': 0.533, '4': 0.628, '5': 0.646, '6': 0.835, '7': 0.789, '8': 0.843, '9': 0.849}\n",
            "[cifar10] ridge alpha=1400 acc=0.7324 time=92.4s\n",
            "Per-class acc: {'0': 0.737, '1': 0.854, '2': 0.606, '3': 0.53, '4': 0.628, '5': 0.648, '6': 0.841, '7': 0.793, '8': 0.839, '9': 0.848}\n",
            "[cifar10] ridge alpha=1600 acc=0.7326 time=90.4s\n",
            "Per-class acc: {'0': 0.74, '1': 0.856, '2': 0.603, '3': 0.53, '4': 0.631, '5': 0.648, '6': 0.843, '7': 0.791, '8': 0.839, '9': 0.845}\n",
            "[cifar10] ridge alpha=1800 acc=0.7322 time=90.8s\n",
            "Per-class acc: {'0': 0.74, '1': 0.855, '2': 0.602, '3': 0.529, '4': 0.636, '5': 0.645, '6': 0.844, '7': 0.791, '8': 0.838, '9': 0.842}\n",
            "[cifar10] ridge alpha=2000 acc=0.7328 time=91.1s\n",
            "Per-class acc: {'0': 0.744, '1': 0.856, '2': 0.599, '3': 0.525, '4': 0.639, '5': 0.643, '6': 0.848, '7': 0.792, '8': 0.841, '9': 0.841}\n",
            "[cifar10] ridge alpha=2200 acc=0.7340 time=90.7s\n",
            "Per-class acc: {'0': 0.75, '1': 0.857, '2': 0.597, '3': 0.526, '4': 0.638, '5': 0.644, '6': 0.85, '7': 0.794, '8': 0.841, '9': 0.843}\n",
            "[cifar10] ridge alpha=2400 acc=0.7343 time=90.2s\n",
            "Per-class acc: {'0': 0.749, '1': 0.858, '2': 0.596, '3': 0.527, '4': 0.639, '5': 0.646, '6': 0.852, '7': 0.797, '8': 0.841, '9': 0.838}\n",
            "Saved: /content/rocket_final_cache/final_kernel_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Visualizations of Models general Architecture"
      ],
      "metadata": {
        "id": "YI35ZsB6GwdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Model Visual"
      ],
      "metadata": {
        "id": "HnIl4tdFf-5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "plt.rcParams.update({\n",
        "    \"font.size\": 11,\n",
        "    \"axes.spines.top\": False,\n",
        "    \"axes.spines.right\": False,\n",
        "    \"grid.alpha\": 0\n",
        "})\n",
        "\n",
        "np.random.seed(4)\n",
        "X_class0 = np.random.randn(16, 2) + np.array([2, 2])\n",
        "X_class1 = np.random.randn(16, 2) + np.array([7, 6])\n",
        "X = np.vstack([X_class0, X_class1])\n",
        "y = np.array([0]*16 + [1]*16)\n",
        "\n",
        "clf = svm.SVC(kernel='linear', C=10000)\n",
        "clf.fit(X, y)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "\n",
        "# Data points\n",
        "ax.scatter(X[y==0,0], X[y==0,1],\n",
        "           s=70, color=\"#3B82F6\", edgecolors=\"white\", linewidth=0.8)\n",
        "ax.scatter(X[y==1,0], X[y==1,1],\n",
        "           s=70, color=\"#F97316\", edgecolors=\"white\", linewidth=0.8)\n",
        "\n",
        "# Decision surface\n",
        "xx = np.linspace(X[:,0].min()-0.5, X[:,0].max()+0.5, 300)\n",
        "yy = np.linspace(X[:,1].min()-0.5, X[:,1].max()+0.5, 300)\n",
        "YY, XX = np.meshgrid(yy, xx)\n",
        "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "Z = clf.decision_function(xy).reshape(XX.shape)\n",
        "\n",
        "ax.contour(XX, YY, Z,\n",
        "           levels=[-1, 0, 1],\n",
        "           colors=[ \"#B0B0B0\", \"#111827\", \"#B0B0B0\"],\n",
        "           linewidths=[1, 1.5, 1],\n",
        "           linestyles=[\"--\", \"-\", \"--\"])\n",
        "\n",
        "# Support vectors\n",
        "ax.scatter(clf.support_vectors_[:,0],\n",
        "           clf.support_vectors_[:,1],\n",
        "           s=160,\n",
        "           facecolors=\"none\",\n",
        "           edgecolors=\"#111827\",\n",
        "           linewidths=1)\n",
        "\n",
        "ax.set_xlabel(r\"$x_1$\")\n",
        "ax.set_ylabel(r\"$x_2$\")\n",
        "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "\n",
        "# Minimal legend\n",
        "legend_elements = [\n",
        "    Line2D([0],[0], marker='o', color='none',\n",
        "           markerfacecolor=\"#3B82F6\", markeredgecolor=\"white\",\n",
        "           markersize=8, label=\"Class 0\"),\n",
        "    Line2D([0],[0], marker='o', color='none',\n",
        "           markerfacecolor=\"#F97316\", markeredgecolor=\"white\",\n",
        "           markersize=8, label=\"Class 1\"),\n",
        "    Line2D([0],[0], color=\"#111827\", lw=2, label=\"Hyperplane\"),\n",
        "    Line2D([0],[0], color=\"#B0B0B0\", lw=1, linestyle='--', label=\"Margin\")\n",
        "]\n",
        "\n",
        "ax.legend(handles=legend_elements, frameon=False, loc=\"upper left\", fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"svm_linear_plot.pdf\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cQHTp0xhFaHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Model Visual"
      ],
      "metadata": {
        "id": "bu3qS0ybf7b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle, Circle\n",
        "import numpy as np\n",
        "from matplotlib.colors import to_rgba, LinearSegmentedColormap\n",
        "\n",
        "def pastel(color, alpha=0.22):\n",
        "    basecolor = [\n",
        "        '#3B82F6',  # Input blue\n",
        "        '#F97316',  # Conv orange\n",
        "        '#a1d99b',  # Pool green\n",
        "        '#fcbead',  # FC pale red\n",
        "        '#cccccc'   # Out grey\n",
        "    ]\n",
        "    c = to_rgba(basecolor[color])\n",
        "    return (c[0], c[1], c[2], alpha)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 5.5))\n",
        "ax.set_facecolor(\"white\")\n",
        "y_center = 2.8\n",
        "\n",
        "x_input = 1.0\n",
        "x_conv = 3.0\n",
        "x_pool = 5.2\n",
        "x_fc   = 7.5\n",
        "x_out  = 8.8\n",
        "\n",
        "boxh = 1.45\n",
        "boxw_input = 1.1\n",
        "boxw_conv = 1.3\n",
        "boxw_pool = 1.1\n",
        "\n",
        "# Input box\n",
        "ax.add_patch(Rectangle((x_input-boxw_input/2, y_center-boxh/2), boxw_input, boxh,\n",
        "               facecolor=pastel(0, 0.29), edgecolor=None, lw=2))\n",
        "\n",
        "# Conv stack (5 maps)\n",
        "for i in range(5):\n",
        "    ax.add_patch(Rectangle((x_conv-boxw_conv/2+0.18*i, y_center-boxh/2+0.13*i), boxw_conv, boxh,\n",
        "        facecolor=pastel(1, 0.24), edgecolor=None, lw=1.66, zorder=10+i))\n",
        "# Pool stack (5 maps, smaller & offset)\n",
        "for i in range(5):\n",
        "    ax.add_patch(Rectangle((x_pool-boxw_pool/2+0.13*i, y_center-0.38+0.10*i), boxw_pool, 0.75,\n",
        "        facecolor=pastel(2, 0.21), edgecolor=None, lw=1.5, zorder=20+i))\n",
        "\n",
        "# FC circles (5), centered\n",
        "fc_n = 5\n",
        "fc_spacing = 0.5\n",
        "fc_radius = 0.19\n",
        "fc_ys = np.linspace(y_center-fc_spacing*2, y_center+fc_spacing*2, fc_n)\n",
        "for y in fc_ys:\n",
        "    circ = Circle((x_fc, y), fc_radius, facecolor=pastel(3, 0.33), edgecolor=None, lw=1.4, zorder=40)\n",
        "    ax.add_patch(circ)\n",
        "# Output circles (3, symmetric)\n",
        "out_n = 3\n",
        "out_spacing = 0.43\n",
        "out_ys = np.linspace(y_center-out_spacing, y_center+out_spacing, out_n)\n",
        "for y in out_ys:\n",
        "    circ = Circle((x_out, y), fc_radius, facecolor=pastel(4, 0.36), edgecolor=None, lw=1.4, zorder=41)\n",
        "    ax.add_patch(circ)\n",
        "\n",
        "# Connections\n",
        "linecolor=\"#a1a1a6\"  # darker gray\n",
        "# Input-> Conv (center)\n",
        "ax.plot([x_input+boxw_input/2, x_conv-boxw_conv/2], [y_center, y_center], color=linecolor, lw=1.2, alpha=0.62, zorder=5)\n",
        "# Conv->Pool: left, center, right\n",
        "for idx in [0, 2, 4]:\n",
        "    x1 = x_conv-boxw_conv/2+0.18*idx+boxw_conv/2\n",
        "    y1 = y_center-boxh/2+0.13*idx+boxh/2\n",
        "    x2 = x_pool-boxw_pool/2+0.13*idx+boxw_pool/2\n",
        "    y2 = y_center-0.38+0.10*idx+0.75/2\n",
        "    ax.plot([x1, x2], [y1, y2], color=linecolor, lw=1.1, alpha=0.5, zorder=25)\n",
        "# Pool->FC: middle map to each FC node\n",
        "for yfc in fc_ys:\n",
        "    x1 = x_pool+boxw_pool/2+0.13*2\n",
        "    y1 = y_center-0.38+0.10*2+0.75/2\n",
        "    ax.plot([x1, x_fc-fc_radius], [y1, yfc], color=\"#bca0a4\", lw=1, alpha=0.47)\n",
        "# FC->Out: fully connect (thin, symmetric fanning)\n",
        "for yf in fc_ys:\n",
        "    for yo in out_ys:\n",
        "        ax.plot([x_fc+fc_radius, x_out-fc_radius], [yf, yo], color=linecolor, lw=0.9, alpha=0.35, zorder=60)\n",
        "\n",
        "# Headers / Labels\n",
        "t_y = y_center+2.0\n",
        "ax.text((x_input+x_pool)/2+0.11, t_y, \"Feature Extraction\", ha='center', va='center',\n",
        "        fontsize=20, fontweight='bold', color=\"#111827\")\n",
        "ax.text((x_fc+x_out)/2,        t_y, \"Classification\", ha='center', va='center',\n",
        "        fontsize=20, fontweight='bold', color=\"#111827\")\n",
        "y_label = y_center-1.65\n",
        "ax.text(x_input, y_label, \"Input\\n(image)\", ha='center', va='top', fontsize=14)\n",
        "ax.text(x_conv, y_label, \"Convolution\\n(feature maps)\", ha='center', va='top', fontsize=14)\n",
        "ax.text(x_pool, y_label, \"Pooling\", ha='center', va='top', fontsize=14)\n",
        "ax.text(x_fc, y_label, \"Fully\\nConnected\", ha='center', va='top', fontsize=14)\n",
        "ax.text(x_out, y_label, \"Output\\n(classes)\", ha='center', va='top', fontsize=14)\n",
        "\n",
        "ax.set_xlim(0.1, 9.4)\n",
        "ax.set_ylim(0.2, 5.01)\n",
        "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"cnn_schematic.pdf\", bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N_HHnfljP9Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rocket Model Visual"
      ],
      "metadata": {
        "id": "-4gklHhff4eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.colors import to_rgb, LinearSegmentedColormap\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(11.5, 3.2))\n",
        "ax.axis(\"off\")\n",
        "\n",
        "cnn_pallete = [\n",
        "    \"#3B82F6\",  # blue\n",
        "    \"#F97316\",  # orange\n",
        "    \"6B7280\"    # grey\n",
        "]\n",
        "nkernels = 11\n",
        "cmap = LinearSegmentedColormap.from_list(\"cnn_pallete\", [cnn_pallete[0], cnn_pallete[1]])\n",
        "kernel_colors = [cmap(i/(nkernels-1)) for i in range(nkernels)]\n",
        "\n",
        "# time series\n",
        "x_ts = np.linspace(0, 1, 60)\n",
        "y_ts = np.sin(2*np.pi*x_ts)*0.6 + 0.12*np.cos(6*np.pi*x_ts)\n",
        "x_ts_scaled = 1.18 + x_ts*1.68\n",
        "y_offset = 2.2\n",
        "ax.plot(x_ts_scaled, y_offset+y_ts*0.7, color='#88889c', lw=2.1, zorder=9)\n",
        "input_center_x = np.mean([x_ts_scaled[0], x_ts_scaled[-1]])\n",
        "label_y = y_offset - 1.13\n",
        "\n",
        "ax.text(input_center_x, label_y, \"Input time series\", fontsize=13, ha=\"center\", va=\"top\")\n",
        "\n",
        "kern_y_top = y_offset + 0.59\n",
        "kern_y_spacing = 0.162\n",
        "kern_x_left = 3.75\n",
        "kern_x_right = 5.65\n",
        "feature_vector_offset = 1.08\n",
        "\n",
        "fv_ys = []\n",
        "for i, c in enumerate(kernel_colors):\n",
        "    y = kern_y_top - i*kern_y_spacing\n",
        "    ax.plot([kern_x_left, kern_x_right], [y, y], lw=7.8, color=c, solid_capstyle=\"round\", zorder=7)\n",
        "    fv_ys.append(y)\n",
        "\n",
        "# arrows from time series to kernels\n",
        "for i, y in enumerate(fv_ys):\n",
        "    idx_start = int(46 + i*(len(x_ts_scaled)-1-46)/(nkernels-1))\n",
        "    ax.annotate('', xy=(kern_x_left-0.10, y), xytext=(x_ts_scaled[idx_start], y_offset+y_ts[idx_start]*0.7),\n",
        "                arrowprops=dict(arrowstyle=\"->\", lw=1.05, color=kernel_colors[i], alpha=0.50), zorder=6)\n",
        "\n",
        "# Feature vector\n",
        "fv_center_x = kern_x_right + feature_vector_offset\n",
        "for i, (y, c) in enumerate(zip(fv_ys, kernel_colors)):\n",
        "    ax.plot([fv_center_x], [y], 'o', c=c, markersize=10, markeredgewidth=0.8, markeredgecolor=None, zorder=8)\n",
        "\n",
        "# arrows from kernel to feature circle\n",
        "for i, y in enumerate(fv_ys):\n",
        "    ax.annotate('', xy=(fv_center_x-0.11, y), xytext=(kern_x_right+0.13, y),\n",
        "                arrowprops=dict(arrowstyle=\"->\", lw=0.95, color=kernel_colors[i], alpha=0.85), zorder=7)\n",
        "\n",
        "fv_vec_center_y = np.mean(fv_ys)\n",
        "ax.text((kern_x_left+kern_x_right)/2, label_y-0.08, \"Fixed random kernels\\n(feature extraction)\",\n",
        "        ha='center', va='top', fontsize=13)\n",
        "ax.text(fv_center_x, label_y-0.08, \"Feature vector\", ha=\"center\", va=\"top\", fontsize=13)\n",
        "\n",
        "clf_x = fv_center_x+1.12\n",
        "clf_y = fv_vec_center_y\n",
        "ax.annotate('', xy=(clf_x-0.12, clf_y), xytext=(fv_center_x+0.18, clf_y),\n",
        "            arrowprops=dict(facecolor='#707087', linewidth=1, arrowstyle='->'), zorder=10)\n",
        "ax.add_patch(plt.Rectangle((clf_x, clf_y-0.27), 0.72, 0.54,\n",
        "                          fc=\"#F97316\", ec=None, lw=1.6, zorder=11, alpha=0.22))\n",
        "ax.text(clf_x+0.36, label_y-0.08, \"Linear\\nclassifier\", ha='center', va='top', fontsize=13)\n",
        "\n",
        "ax.set_xlim(0, 9.1)\n",
        "ax.set_ylim(0.27, 3.18)\n",
        "#plt.suptitle(\"The Architecture of ROCKET\", fontsize=17, fontweight='bold', y=1.04)\n",
        "plt.tight_layout()\n",
        "plt.savefig('rocket_schematic.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eeFqoTCvP1Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot for per class accuracies"
      ],
      "metadata": {
        "id": "TWWkj3jzneT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# classes 0-9\n",
        "classes = np.arange(10)\n",
        "\n",
        "# Per-class accuracy Data\n",
        "accuracy_data = {\n",
        "    \"MNIST\": {\n",
        "        \"CNN\": {\n",
        "            \"per_class\": [0.9969, 0.9965, 0.9942, 0.9931, 0.9939, 0.9922, 0.9823, 0.9844, 0.9887, 0.9832]\n",
        "        },\n",
        "        \"ROCKET Minimal\": {\n",
        "            # Pure ROCKET 1D (bestes alpha aus Pure ROCKET 1D run: alpha=1000)\n",
        "            \"per_class\": [0.9938775510204082, 0.9911894273127754, 0.9864341085271318, 0.9851485148514851,\n",
        "                          0.9867617107942973, 0.9865470852017937, 0.9843423799582464, 0.9776264591439688,\n",
        "                          0.9897330595482546, 0.9762140733399405]\n",
        "        },\n",
        "        \"ROCKET Final\": {\n",
        "            # Final pipeline (bestes alpha aus Final run: alpha=1200)\n",
        "            \"per_class\": [0.9979591836734694, 0.9982378854625551, 0.9951550387596899, 0.9930693069306931,\n",
        "                          0.994908350305499, 0.9943946188340808, 0.9916492693110647, 0.9941634241245136,\n",
        "                          0.9948665297741273, 0.9861248761149654]\n",
        "        },\n",
        "        \"SVM\": {\n",
        "            \"per_class\": [0.9806, 0.9797, 0.8818, 0.9099, 0.9308, 0.8565, 0.9489, 0.9202, 0.8604, 0.885]\n",
        "        }\n",
        "    },\n",
        "    \"CIFAR-10\": {\n",
        "        \"CNN\": {\n",
        "            \"per_class\": [0.7120, 0.8440, 0.7080, 0.4480, 0.4390, 0.7130, 0.8120, 0.7710, 0.7660, 0.7490]\n",
        "        },\n",
        "        \"ROCKET Minimal\": {\n",
        "            # Pure ROCKET 1D (bestes alpha aus Pure ROCKET 1D run: alpha=1000)\n",
        "            \"per_class\": [0.665, 0.778, 0.473, 0.388, 0.509, 0.538, 0.746, 0.652, 0.78, 0.721]\n",
        "        },\n",
        "        \"ROCKET Final\": {\n",
        "            # Final pipeline (bestes alpha aus Final run: alpha=2400)\n",
        "            \"per_class\": [0.749, 0.858, 0.596, 0.527, 0.639, 0.646, 0.852, 0.797, 0.841, 0.838]\n",
        "        },\n",
        "        \"SVM\": {\n",
        "            \"per_class\": [0.471, 0.459, 0.235, 0.168, 0.252, 0.300, 0.475, 0.431, 0.542, 0.457]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "def plot_per_class_accuracy(dataset, save_pdf=True):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    for model, acc in accuracy_data[dataset].items():\n",
        "        plt.plot(classes, acc[\"per_class\"], marker='o', label=model)\n",
        "    plt.xticks(classes)\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Per-class Accuracy\")\n",
        "    plt.ylim(0,1.05)\n",
        "    plt.title(f\"Per-class Accuracy on {dataset}\")\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.legend()\n",
        "\n",
        "    if save_pdf:\n",
        "        pdf_name = f\"per_class_accuracy_{dataset.replace(' ','_').lower()}.pdf\"\n",
        "        plt.savefig(pdf_name, bbox_inches='tight')\n",
        "        print(f\"Saved plot as {pdf_name}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# MNIST plot\n",
        "plot_per_class_accuracy(\"MNIST\")\n",
        "\n",
        "# CIFAR-10 plot\n",
        "plot_per_class_accuracy(\"CIFAR-10\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "6pVhgnrBCARr",
        "outputId": "d3baf4a2-d486-468a-912e-1be1de8b29ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot as per_class_accuracy_mnist.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot as per_class_accuracy_cifar-10.pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KTH-TIPS Tests"
      ],
      "metadata": {
        "id": "P2x4iZbFaeX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First exploration on SVM and CNN Baselines, as well as run on final 2D Rocket Pipeline on KTH-TIPS. KTH TIPS represents a small structured image dataset."
      ],
      "metadata": {
        "id": "HTGBUUY70x3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "tar_path = \"/content/kth_tips_grey_200x200.tar\"\n",
        "with tarfile.open(tar_path, \"r\") as tar:\n",
        "    tar.extractall(\"/content\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJPR2XKRUcT8",
        "outputId": "bf5c1ca0-0916-404a-d428-39708cbc14de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-813561799.py:5: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(\"/content\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create deterministic train/test split\n",
        "# Result: content/KTH_TIPS/train/<class>/*  and content/KTH_TIPS/test/<class>/*\n",
        "\n",
        "import os, random, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = \"KTH_TIPS\"\n",
        "TRAIN_RATIO = 0.8           # 80% train / 20% test\n",
        "SEED = 42                   # deterministic split\n",
        "COPY_INSTEAD_OF_MOVE = True # True = copy, False = move\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "def make_splits(root_dir: str, train_ratio: float = 0.8, seed: int = 42, copy=True):\n",
        "    root = Path(root_dir)\n",
        "    assert root.exists(), f\"{root} nicht gefunden\"\n",
        "    classes = [p for p in root.iterdir() if p.is_dir()]\n",
        "    if not classes:\n",
        "        raise RuntimeError(f\"Keine Klassenordner in {root}. Erwartet content/KTH_TIPS/<class>/*\")\n",
        "    train_root = root.joinpath(\"train\")\n",
        "    test_root = root.joinpath(\"test\")\n",
        "    train_root.mkdir(parents=True, exist_ok=True)\n",
        "    test_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for cls in classes:\n",
        "        if cls.name in (\"train\", \"test\"):\n",
        "            continue\n",
        "        cls_files = [p for p in cls.glob(\"*\") if p.is_file()]\n",
        "        cls_files.sort()\n",
        "        random.Random(seed).shuffle(cls_files)\n",
        "        n_train = int(len(cls_files) * train_ratio)\n",
        "        train_files = cls_files[:n_train]\n",
        "        test_files = cls_files[n_train:]\n",
        "\n",
        "        dest_train_cls = train_root.joinpath(cls.name)\n",
        "        dest_test_cls = test_root.joinpath(cls.name)\n",
        "        dest_train_cls.mkdir(parents=True, exist_ok=True)\n",
        "        dest_test_cls.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for p in train_files:\n",
        "            if copy:\n",
        "                shutil.copy2(p, dest_train_cls.joinpath(p.name))\n",
        "            else:\n",
        "                shutil.move(p, dest_train_cls.joinpath(p.name))\n",
        "        for p in test_files:\n",
        "            if copy:\n",
        "                shutil.copy2(p, dest_test_cls.joinpath(p.name))\n",
        "            else:\n",
        "                shutil.move(p, dest_test_cls.joinpath(p.name))\n",
        "        print(f\"Klasse {cls.name}: {len(train_files)} train / {len(test_files)} test\")\n",
        "\n",
        "    print(f\"Done. Train dir: {train_root} | Test dir: {test_root}\")\n",
        "\n",
        "make_splits(ROOT, train_ratio=TRAIN_RATIO, seed=SEED, copy=COPY_INSTEAD_OF_MOVE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUM9nUOKx42H",
        "outputId": "0556d878-6f93-4961-f288-47d3dc223f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Klasse brown_bread: 64 train / 17 test\n",
            "Klasse styrofoam: 64 train / 17 test\n",
            "Klasse aluminium_foil: 64 train / 17 test\n",
            "Klasse cotton: 64 train / 17 test\n",
            "Klasse orange_peel: 64 train / 17 test\n",
            "Klasse sandpaper: 64 train / 17 test\n",
            "Klasse corduroy: 64 train / 17 test\n",
            "Klasse linen: 64 train / 17 test\n",
            "Klasse sponge: 64 train / 17 test\n",
            "Klasse cracker: 64 train / 17 test\n",
            "Done. Train dir: KTH_TIPS/train | Test dir: KTH_TIPS/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Mean and Std for KTH-TIPS"
      ],
      "metadata": {
        "id": "R5s679gv0j2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean/std for kthtips (Grayscale -> 1 channel), images scaled to 32x32.\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import math\n",
        "\n",
        "root = \"KTH_TIPS\"\n",
        "which_split = \"train\"\n",
        "dataset_dir = os.path.join(root, which_split)\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "    raise FileNotFoundError(f\"{dataset_dir} nicht gefunden. Erwartet: {root}/train und {root}/test oder passe path an.\")\n",
        "\n",
        "# Transform: Resize -> Grayscale(1) -> ToTensor (range [0,1])\n",
        "tf = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "ds = datasets.ImageFolder(dataset_dir, transform=tf)\n",
        "loader = DataLoader(ds, batch_size=512, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# mean/std (per-channel)\n",
        "n_pixels = 0\n",
        "sum_ = 0.0\n",
        "sumsq = 0.0\n",
        "device = \"cpu\"\n",
        "\n",
        "for xb, _ in loader:\n",
        "    xb = xb.to(device)          # shape (B,1,H,W)\n",
        "    B, C, H, W = xb.shape\n",
        "    nb = B * H * W\n",
        "    # Sum per all pixels (channel dims preserved)\n",
        "    sum_ += xb.sum().item()\n",
        "    sumsq += (xb * xb).sum().item()\n",
        "    n_pixels += nb\n",
        "\n",
        "mean = sum_ / n_pixels\n",
        "var = (sumsq / n_pixels) - (mean * mean)\n",
        "std = math.sqrt(max(var, 1e-12))\n",
        "\n",
        "print(f\"kthtips ({which_split}) mean: {mean:.6f}, std: {std:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8ssi0-Ov4VD",
        "outputId": "6c82e65b-ff25-4bd2-b0fc-1f7be5599fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kthtips (train) mean: 0.490255, std: 0.114054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loader for KTH-TIPS"
      ],
      "metadata": {
        "id": "3ETMl6vk0fze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import config\n",
        "\n",
        "DATA_ROOT = os.environ.get(\"THREE_DATA_ROOT\", \"KTH_TIPS\")\n",
        "\n",
        "# Standard transform: Resize -> Grayscale -> ToTensor -> dataset-normalize\n",
        "# take calculated mean and std\n",
        "tf = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.490255, 0.114054),\n",
        "])\n",
        "\n",
        "train_root = os.path.join(DATA_ROOT, \"train\")\n",
        "test_root  = os.path.join(DATA_ROOT, \"test\")\n",
        "\n",
        "if not os.path.isdir(train_root) or not os.path.isdir(test_root):\n",
        "    raise FileNotFoundError(f\"Erwarte train/ und test/-Ordner unter {DATA_ROOT}. Gefunden: {os.listdir(DATA_ROOT) if os.path.isdir(DATA_ROOT) else 'keine ordner'}\")\n",
        "\n",
        "train_ds = datasets.ImageFolder(train_root, transform=tf)\n",
        "test_ds  = datasets.ImageFolder(test_root,  transform=tf)\n",
        "\n",
        "# loader params from config.py\n",
        "batch_cfg = config.get_batch_config()\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_cfg[\"batch_size_train\"], shuffle=True,\n",
        "                          num_workers=batch_cfg[\"num_workers\"], pin_memory=batch_cfg[\"pin_memory\"],\n",
        "                          generator=None)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=batch_cfg[\"batch_size_test\"], shuffle=False,\n",
        "                          num_workers=batch_cfg[\"num_workers\"], pin_memory=batch_cfg[\"pin_memory\"])\n",
        "\n",
        "in_channels = 1\n",
        "image_hw = (32, 32)\n",
        "seq_len = image_hw[0] * image_hw[1]\n",
        "\n",
        "print(f\"Loaded dataset from {DATA_ROOT}: classes={train_ds.classes}, train={len(train_ds)}, test={len(test_ds)}\")\n",
        "print(\"Batch config:\", batch_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw_l62vNu5NK",
        "outputId": "512aace0-37b7-48bc-fcbf-082b96df2147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset from KTH_TIPS: classes=['aluminium_foil', 'brown_bread', 'corduroy', 'cotton', 'cracker', 'linen', 'orange_peel', 'sandpaper', 'sponge', 'styrofoam'], train=640, test=170\n",
            "Batch config: {'batch_size_train': 512, 'batch_size_test': 512, 'num_workers': 2, 'pin_memory': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM Baseline on KTH-TIPS"
      ],
      "metadata": {
        "id": "6EWq5vsjzybb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "import config\n",
        "config.set_seed(config.SEED)\n",
        "config.set_deterministic()\n",
        "\n",
        "# SVM params\n",
        "C_grid = [0.1]\n",
        "rp_dim = 1024 * 2  # set None to disable projection\n",
        "max_iter = 1000\n",
        "\n",
        "# Use loaders from previous cells\n",
        "train_loader = globals().get(\"train_loader\", None)\n",
        "test_loader  = globals().get(\"test_loader\", None)\n",
        "if train_loader is None or test_loader is None:\n",
        "    raise RuntimeError(\"train_loader/test_loader nicht gefunden. Bitte zuerst die DataLoader-Zelle ausführen.\")\n",
        "\n",
        "def loader_to_numpy(loader, flatten=True):\n",
        "    xs, ys = [], []\n",
        "    for xb, yb in loader:\n",
        "        x = xb.numpy()\n",
        "        if flatten:\n",
        "            x = x.reshape(x.shape[0], -1)\n",
        "        xs.append(x); ys.append(yb.numpy())\n",
        "    return np.concatenate(xs, axis=0), np.concatenate(ys, axis=0)\n",
        "\n",
        "X_tr, y_tr = loader_to_numpy(train_loader, flatten=True)\n",
        "X_te, y_te = loader_to_numpy(test_loader,  flatten=True)\n",
        "\n",
        "scaler = StandardScaler().fit(X_tr)\n",
        "Xtr_s = scaler.transform(X_tr); Xte_s = scaler.transform(X_te)\n",
        "\n",
        "if rp_dim is not None:\n",
        "    # Guard: don't request more components than features\n",
        "    rp = GaussianRandomProjection(n_components=min(rp_dim, Xtr_s.shape[1]), random_state=config.SEED)\n",
        "    Xtr_s = rp.fit_transform(Xtr_s); Xte_s = rp.transform(Xte_s)\n",
        "\n",
        "best = {\"acc\": -1}\n",
        "results = []\n",
        "for C in C_grid:\n",
        "    t_start = time.time()\n",
        "    clf = LinearSVC(C=C, max_iter=max_iter, random_state=config.SEED)\n",
        "    clf.fit(Xtr_s, y_tr)\n",
        "    train_time_C = time.time() - t_start\n",
        "    y_pred = clf.predict(Xte_s)\n",
        "    acc = float((y_pred == y_te).mean())\n",
        "    conf = confusion_matrix(y_te, y_pred)\n",
        "    per_class_acc = (conf.diagonal() / conf.sum(axis=1)).tolist()\n",
        "    print(f\"[custom_three][SVM-raw+RP] C={C} | acc={acc:.4f} | train_time={train_time_C:.2f}s\")\n",
        "    print(f\"Per-class accuracy: {np.round(per_class_acc,4)}\")\n",
        "    results.append({\"dataset\":\"custom_three\",\"classifier\":\"linear_svm_rp\",\"C\":C,\"acc\":acc,\"train_time\":train_time_C,\"feature_dim\":Xtr_s.shape[1],\"per_class_acc\":per_class_acc})\n",
        "    if acc > best[\"acc\"]:\n",
        "        best.update({\"acc\": acc, \"C\": C, \"ypred\": y_pred, \"train_time\": train_time_C, \"per_class_acc\": per_class_acc})\n",
        "\n",
        "csv_name = f\"./svm_baseline_results_custom_three.csv\"\n",
        "pd.DataFrame(results).to_csv(csv_name, index=False)\n",
        "print(\"Best SVM result saved to\", csv_name)\n",
        "print(\"Summary: \", best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vVBtRafvDLC",
        "outputId": "10b79c68-30e7-420b-c35b-87b290422136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[custom_three][SVM-raw+RP] C=0.1 | acc=0.3941 | train_time=7.63s\n",
            "Per-class accuracy: [0.     0.4706 0.7059 0.4118 0.4118 0.4706 0.2941 0.2941 0.4706 0.4118]\n",
            "Best SVM result saved to ./svm_baseline_results_custom_three.csv\n",
            "Summary:  {'acc': 0.3941176470588235, 'C': 0.1, 'ypred': array([2, 7, 9, 9, 9, 1, 9, 1, 3, 7, 3, 2, 9, 6, 7, 9, 5, 8, 9, 1, 9, 5,\n",
            "       5, 1, 1, 3, 8, 9, 1, 1, 1, 1, 1, 8, 2, 9, 9, 2, 3, 9, 2, 2, 2, 2,\n",
            "       9, 2, 2, 2, 2, 2, 2, 7, 2, 7, 7, 7, 3, 3, 3, 5, 9, 7, 3, 9, 7, 3,\n",
            "       3, 3, 8, 3, 3, 4, 9, 1, 7, 7, 7, 6, 8, 4, 4, 4, 4, 4, 4, 9, 9, 5,\n",
            "       3, 9, 3, 5, 8, 3, 9, 7, 5, 5, 5, 5, 5, 5, 7, 7, 8, 7, 7, 3, 7, 5,\n",
            "       3, 3, 6, 5, 6, 6, 6, 6, 5, 2, 3, 8, 3, 7, 9, 7, 7, 7, 7, 9, 5, 3,\n",
            "       3, 3, 3, 3, 7, 3, 5, 8, 8, 8, 5, 7, 5, 3, 2, 8, 8, 8, 8, 3, 8, 7,\n",
            "       7, 5, 8, 7, 3, 9, 9, 9, 2, 7, 7, 7, 9, 9, 9, 9]), 'train_time': 7.632181167602539, 'per_class_acc': [0.0, 0.47058823529411764, 0.7058823529411765, 0.4117647058823529, 0.4117647058823529, 0.47058823529411764, 0.29411764705882354, 0.29411764705882354, 0.47058823529411764, 0.4117647058823529]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Baseline on KTH-TIPS"
      ],
      "metadata": {
        "id": "iMWCr70O0bsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, os\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "import pandas as pd\n",
        "\n",
        "import config\n",
        "from utils.eval import evaluate_and_report\n",
        "\n",
        "# reproducibility\n",
        "config.set_seed(config.SEED)\n",
        "config.set_deterministic()\n",
        "\n",
        "device = config.DEVICE\n",
        "batch_cfg = config.get_batch_config()\n",
        "print(\"Using batch config:\", batch_cfg)\n",
        "print(\"Using stride config:\", config.get_stride_config())\n",
        "\n",
        "# SmallCNN\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, in_channels: int, img_size: int, num_classes: int = None):\n",
        "        super().__init__()\n",
        "        if num_classes is None:\n",
        "            # get number of classes from the dataset; assume train loader exists\n",
        "            ds = globals().get(\"train_loader\").dataset if globals().get(\"train_loader\") is not None else None\n",
        "            num_classes = len(ds.classes) if ds is not None else 10\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        feat = img_size // 4\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*feat*feat, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x): return self.classifier(self.features(x))\n",
        "\n",
        "# prepare loaders: assume train_loader/test_loader from loader cell exist\n",
        "train_loader = globals().get(\"train_loader\", None)\n",
        "test_loader  = globals().get(\"test_loader\", None)\n",
        "if train_loader is None or test_loader is None:\n",
        "    raise RuntimeError(\"train_loader/test_loader nicht gefunden. Bitte zuerst die DataLoader-Zelle ausführen.\")\n",
        "\n",
        "in_channels = globals().get(\"in_channels\", 1)\n",
        "img_sz = globals().get(\"image_hw\", (32,32))[0]\n",
        "num_classes = len(train_loader.dataset.classes)\n",
        "\n",
        "epochs = int(os.environ.get(\"EPOCHS\", \"10\"))\n",
        "\n",
        "model = SmallCNN(in_channels, img_sz, num_classes=num_classes).to(device)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "\n",
        "def eval_loader(model, loader, device):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    logits_list, y_list = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "        logits_list.append(logits.detach().cpu().numpy()); y_list.append(yb.detach().cpu().numpy())\n",
        "    logits = np.concatenate(logits_list, axis=0) if logits_list else np.zeros((0,num_classes))\n",
        "    y_true = np.concatenate(y_list, axis=0) if y_list else np.zeros((0,), dtype=int)\n",
        "    y_pred = logits.argmax(axis=1) if logits_list else np.zeros((0,), dtype=int)\n",
        "    return (correct/total if total>0 else 0.0), y_true, y_pred, logits\n",
        "\n",
        "t0_all = time.time()\n",
        "for ep in range(1, epochs+1):\n",
        "    model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = crit(model(xb), yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    acc_val, _, _, _ = eval_loader(model, test_loader, device)\n",
        "    print(f\"[cnn_small_custom] epoch {ep:02d} | test acc {acc_val:.4f}\")\n",
        "\n",
        "train_time = time.time() - t0_all\n",
        "acc, y_true, y_pred, logits = eval_loader(model, test_loader, device)\n",
        "evaluate_and_report(\"cnn_small_custom\", \"custom_three\", config.SEED, y_true, y_pred, scores=logits, train_time=train_time)\n",
        "\n",
        "# save simple results CSV\n",
        "CACHE_DIR = os.path.join(os.environ.get(\"CACHE_DIR\", \"/content\"), \"cnn_custom_cache\")\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "RESULTS_CSV = os.path.join(CACHE_DIR, \"cnn_results_custom.csv\")\n",
        "pd.DataFrame([{\"dataset\":\"custom_three\",\"model\":\"cnn_small\",\"seed\":config.SEED,\"accuracy\":acc,\"train_time\":train_time}]).to_csv(RESULTS_CSV, index=False)\n",
        "print(\"CNN results saved to:\", RESULTS_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzakwi6IvDVc",
        "outputId": "40963e59-7b58-4451-a805-b1ba0c126544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using batch config: {'batch_size_train': 512, 'batch_size_test': 512, 'num_workers': 2, 'pin_memory': True}\n",
            "Using stride config: {'stride_1d': 1, 'stride_2d': 1}\n",
            "[cnn_small_custom] epoch 01 | test acc 0.1471\n",
            "[cnn_small_custom] epoch 02 | test acc 0.2059\n",
            "[cnn_small_custom] epoch 03 | test acc 0.2294\n",
            "[cnn_small_custom] epoch 04 | test acc 0.3059\n",
            "[cnn_small_custom] epoch 05 | test acc 0.3471\n",
            "[cnn_small_custom] epoch 06 | test acc 0.4059\n",
            "[cnn_small_custom] epoch 07 | test acc 0.4176\n",
            "[cnn_small_custom] epoch 08 | test acc 0.4412\n",
            "[cnn_small_custom] epoch 09 | test acc 0.4353\n",
            "[cnn_small_custom] epoch 10 | test acc 0.4588\n",
            "[cnn_small_custom][custom_three][seed=42] acc=0.4588 | train_time=11.97427487373352s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.4118    0.5833        17\n",
            "           1     0.6923    0.5294    0.6000        17\n",
            "           2     0.5000    0.5882    0.5405        17\n",
            "           3     0.0000    0.0000    0.0000        17\n",
            "           4     0.4815    0.7647    0.5909        17\n",
            "           5     0.6111    0.6471    0.6286        17\n",
            "           6     0.8571    0.3529    0.5000        17\n",
            "           7     0.2000    0.0588    0.0909        17\n",
            "           8     0.3171    0.7647    0.4483        17\n",
            "           9     0.2857    0.4706    0.3556        17\n",
            "\n",
            "    accuracy                         0.4588       170\n",
            "   macro avg     0.4945    0.4588    0.4338       170\n",
            "weighted avg     0.4945    0.4588    0.4338       170\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 7  2  0  0  7  0  1  0  0  0]\n",
            " [ 0  9  1  0  4  0  0  0  2  1]\n",
            " [ 0  0 10  0  2  0  0  0  5  0]\n",
            " [ 0  0  1  0  0  0  0  1  5 10]\n",
            " [ 0  2  0  0 13  0  0  0  2  0]\n",
            " [ 0  0  1  0  0 11  0  0  5  0]\n",
            " [ 0  0  0  0  0  4  6  3  0  4]\n",
            " [ 0  0  5  0  0  1  0  1  5  5]\n",
            " [ 0  0  1  2  1  0  0  0 13  0]\n",
            " [ 0  0  1  2  0  2  0  0  4  8]]\n",
            "CNN results saved to: /content/cnn_custom_cache/cnn_results_custom.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final ROCKET Pipeline on KTH-TIPS"
      ],
      "metadata": {
        "id": "3mJpt4ug0Xcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final ROCKET pipeline for den kth-tips grayscale-32x32 dataset\n",
        "# takes same settings as final ROCKET pipeline\n",
        "\n",
        "import time, os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import config\n",
        "from utils.kernels import make_random_kernels_2d, count_kernels, kernel_hash\n",
        "from utils.features import extract_features_2d\n",
        "from utils.eval import per_class_accuracy\n",
        "from utils.sanity import estimate_feature_bytes\n",
        "from utils.settings import get_cache_dir\n",
        "from utils.constants import FEATURE_TYPES_2D as FEATURE_TYPES, PREPROC_IMAGE_NORM\n",
        "\n",
        "# reproducibility\n",
        "config.set_seed(config.SEED)\n",
        "config.set_deterministic()\n",
        "\n",
        "# experiment level defaults\n",
        "N_KERNELS_FINAL = int(os.environ.get(\"N_KERNELS_FINAL\", \"5000\"))\n",
        "BEST_CONFIGS = {\n",
        "    # fallback\n",
        "    \"default\": {\"name\":\"mixed_moderate\",\"k_choices\":[3,5,7,9],\"d_choices\":[1,2],\"description\":\"mixed moderate\"}\n",
        "}\n",
        "cfg = BEST_CONFIGS[\"default\"]\n",
        "\n",
        "# Cache / results\n",
        "CACHE_DIR = get_cache_dir(\"rocket_final_custom_cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_CSV = str(Path(CACHE_DIR).joinpath(\"final_kernel_results_customdataset.csv\"))\n",
        "\n",
        "try:\n",
        "    train_loader, test_loader, in_channels_var, image_hw_var, seq_len_var\n",
        "    # If objects not defined, the above will raise NameError; but we don't want to crash here:\n",
        "except Exception:\n",
        "    # If the variables aren't in globals, try to import or expect user to run data loader cell\n",
        "    pass\n",
        "\n",
        "# Use the train_loader/test_loader variables created by the loader cell:\n",
        "# If those names are not bound in this cell's scope, assume user ran the loader cell which defined them globally.\n",
        "train_loader = globals().get(\"train_loader\", None)\n",
        "test_loader = globals().get(\"test_loader\", None)\n",
        "in_channels = globals().get(\"in_channels\", 1)\n",
        "image_hw = globals().get(\"image_hw\", (32,32))\n",
        "seq_len = globals().get(\"seq_len\", 32*32)\n",
        "\n",
        "if train_loader is None or test_loader is None:\n",
        "    raise RuntimeError(\"train_loader/test_loader nicht gefunden. Bitte vorher die DataLoader-Zelle ausführen.\")\n",
        "\n",
        "print(f\"Running ROCKET final on custom dataset: N_KERNELS={N_KERNELS_FINAL}, config={cfg['name']}, in_channels={in_channels}, image_hw={image_hw}\")\n",
        "\n",
        "kernels = make_random_kernels_2d(\n",
        "    N_KERNELS_FINAL, in_channels,\n",
        "    cfg[\"k_choices\"], cfg[\"d_choices\"],\n",
        "    seed=config.SEED\n",
        ")\n",
        "\n",
        "kh = kernel_hash(kernels)\n",
        "cnt = count_kernels(kernels)\n",
        "print(\"kernel hash:\", kh, \"count:\", cnt)\n",
        "\n",
        "# Features extraction (valid padding)\n",
        "X_train, y_train = extract_features_2d(\n",
        "    train_loader, kernels, FEATURE_TYPES,\n",
        "    image_hw=image_hw,\n",
        "    padding_mode=\"valid\",\n",
        "    stride=config.STRIDE_2D,\n",
        "    seed=config.SEED\n",
        ")\n",
        "\n",
        "X_test, y_test = extract_features_2d(\n",
        "    test_loader, kernels, FEATURE_TYPES,\n",
        "    image_hw=image_hw,\n",
        "    padding_mode=\"valid\",\n",
        "    stride=config.STRIDE_2D,\n",
        "    seed=config.SEED\n",
        ")\n",
        "\n",
        "print(f\"Features: train={X_train.shape} test={X_test.shape}\")\n",
        "\n",
        "if X_train.shape[1] == 0:\n",
        "    print(\"No features -> skip\")\n",
        "else:\n",
        "    print(\"Estimated feature size (GiB):\", estimate_feature_bytes(len(train_loader.dataset), X_train.shape[1]) / (1024**3))\n",
        "\n",
        "from config import build_ridge\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "results = []\n",
        "for alpha in config.ALPHAS:\n",
        "    pipe = build_ridge(alpha=alpha, scale=True)\n",
        "    t0 = time.time()\n",
        "    pipe.fit(X_train, y_train)\n",
        "    tt = time.time() - t0\n",
        "    ypred = pipe.predict(X_test)\n",
        "    acc = accuracy_score(y_test, ypred)\n",
        "    per_class_acc = per_class_accuracy(y_test, ypred)\n",
        "    print(f\"[custom_dataset] ridge alpha={alpha} acc={acc:.4f} time={tt:.1f}s\")\n",
        "    print(\"Per-class acc:\", per_class_acc)\n",
        "    results.append({\n",
        "        \"dataset\": \"custom_three\",\n",
        "        \"classifier\": \"ridge\",\n",
        "        \"alpha\": alpha,\n",
        "        \"acc\": acc,\n",
        "        \"train_time\": tt,\n",
        "        \"feature_dim\": X_train.shape[1],\n",
        "        \"n_kernels\": N_KERNELS_FINAL,\n",
        "        \"per_class_acc\": per_class_acc\n",
        "    })\n",
        "\n",
        "pd.DataFrame(results).to_csv(RESULTS_CSV, index=False)\n",
        "print(\"Saved:\", RESULTS_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDxta6IavDfn",
        "outputId": "9d08a82d-7777-486e-8fd8-9ad0d84d9312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running ROCKET final on custom dataset: N_KERNELS=5000, config=mixed_moderate, in_channels=1, image_hw=(32, 32)\n",
            "kernel hash: bce6afe94f6fc60da8617ccf777c3e5f count: 5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: train=(640, 25000) test=(170, 25000)\n",
            "Estimated feature size (GiB): 0.059604644775390625\n",
            "[custom_dataset] ridge alpha=1000 acc=0.8471 time=0.4s\n",
            "Per-class acc: {'0': 1.0, '1': 1.0, '2': 1.0, '3': 0.7647058823529411, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.6470588235294118, '8': 0.9411764705882353, '9': 0.5882352941176471}\n",
            "[custom_dataset] ridge alpha=1200 acc=0.8529 time=0.5s\n",
            "Per-class acc: {'0': 1.0, '1': 1.0, '2': 1.0, '3': 0.8235294117647058, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.6470588235294118, '8': 0.9411764705882353, '9': 0.5882352941176471}\n",
            "[custom_dataset] ridge alpha=1400 acc=0.8529 time=0.5s\n",
            "Per-class acc: {'0': 1.0, '1': 1.0, '2': 1.0, '3': 0.8235294117647058, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.6470588235294118, '8': 0.9411764705882353, '9': 0.5882352941176471}\n",
            "[custom_dataset] ridge alpha=1600 acc=0.8529 time=0.5s\n",
            "Per-class acc: {'0': 1.0, '1': 1.0, '2': 1.0, '3': 0.8235294117647058, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.6470588235294118, '8': 0.9411764705882353, '9': 0.5882352941176471}\n",
            "[custom_dataset] ridge alpha=1800 acc=0.8471 time=0.4s\n",
            "Per-class acc: {'0': 1.0, '1': 1.0, '2': 1.0, '3': 0.8235294117647058, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.5882352941176471, '8': 0.9411764705882353, '9': 0.5882352941176471}\n",
            "[custom_dataset] ridge alpha=2000 acc=0.8353 time=0.5s\n",
            "Per-class acc: {'0': 1.0, '1': 0.9411764705882353, '2': 1.0, '3': 0.7647058823529411, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.5882352941176471, '8': 0.9411764705882353, '9': 0.5882352941176471}\n",
            "[custom_dataset] ridge alpha=2200 acc=0.8353 time=0.6s\n",
            "Per-class acc: {'0': 1.0, '1': 0.8823529411764706, '2': 1.0, '3': 0.7647058823529411, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.5882352941176471, '8': 1.0, '9': 0.5882352941176471}\n",
            "[custom_dataset] ridge alpha=2400 acc=0.8353 time=0.4s\n",
            "Per-class acc: {'0': 1.0, '1': 0.8823529411764706, '2': 1.0, '3': 0.7647058823529411, '4': 1.0, '5': 0.6470588235294118, '6': 0.8823529411764706, '7': 0.5882352941176471, '8': 1.0, '9': 0.5882352941176471}\n",
            "Saved: /content/rocket_final_custom_cache/final_kernel_results_customdataset.csv\n"
          ]
        }
      ]
    }
  ]
}